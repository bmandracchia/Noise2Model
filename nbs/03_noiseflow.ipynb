{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NoiseFlow\n",
    "\n",
    "> noiseflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp noiseflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from IPython.display import clear_output, DisplayHandle\n",
    "\n",
    "def update_patch(self, obj):\n",
    "    clear_output(wait=True)\n",
    "    self.display(obj)\n",
    "DisplayHandle.update = update_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " #| export\n",
    "\n",
    "from fastai.vision.all import nn, torch, np, Path, get_image_files, Image \n",
    "import normflows as nf\n",
    "from Noise2Model.utils import attributesFromDict\n",
    "# from Noise2Model.models import DnCNN, UNet\n",
    "from Noise2Model.utils import gaussian_diag #, batch_PSNR, weights_init_orthogonal #, weights_init_kaiming\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise Flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from Noise2Model.layers import Unconditional, Gain, AffineSdn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class NoiseFlow(nn.Module):\n",
    "\n",
    "    def __init__(self, x_shape, arch, device='cuda'): # device may be removed\n",
    "        super(NoiseFlow, self).__init__()\n",
    "        attributesFromDict(locals( ))\n",
    "        self.model = nn.ModuleList(self.noise_flow_arch(x_shape))\n",
    "\n",
    "    def noise_flow_arch(self, x_shape):\n",
    "        arch_lyrs = self.arch.split('|')  # e.g., unc|sdn|unc|gain|unc\n",
    "        bijectors = []\n",
    "        for i, lyr in enumerate(arch_lyrs):\n",
    "            # is_last_layer = False\n",
    "\n",
    "            if lyr == 'unc':\n",
    "                print('|-AffineCoupling')\n",
    "                print(self.device)\n",
    "                bijectors.append(\n",
    "                    Unconditional(\n",
    "                        channels=x_shape[1],\n",
    "                        hidden_channels = 16,\n",
    "                        split_mode='channel' if x_shape[1] != 1 else 'checkerboard'\n",
    "                    )#.to(self.device)\n",
    "                )\n",
    "            elif lyr == 'sdn':\n",
    "                print('|-SignalDependant')\n",
    "                bijectors.append(\n",
    "                    AffineSdn(x_shape[1:])#.to(self.device)\n",
    "                )\n",
    "            elif lyr == 'gain':\n",
    "                print('|-Gain')\n",
    "                bijectors.append(\n",
    "                    Gain(x_shape[1:])#.to(self.device)    # Gain and offset\n",
    "                )\n",
    "\n",
    "        return bijectors\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        z = x\n",
    "        objective = torch.zeros(x.shape[0], dtype=torch.float32, device=self.device)\n",
    "        for bijector in self.model:\n",
    "            z, log_abs_det_J_inv = bijector.forward(z, **kwargs)\n",
    "            objective += log_abs_det_J_inv\n",
    "\n",
    "            if 'writer' in kwargs.keys():\n",
    "                kwargs['writer'].add_scalar('model/' + bijector.name, torch.mean(log_abs_det_J_inv), kwargs['step'])\n",
    "        return z#, objective\n",
    "\n",
    "    def _loss(self, x, **kwargs):\n",
    "        z, objective = self.forward(x, **kwargs)\n",
    "        # base measure\n",
    "        logp, _ = self.prior(\"prior\", x)\n",
    "\n",
    "        log_z = logp(z)\n",
    "        objective += log_z\n",
    "\n",
    "        if 'writer' in kwargs.keys():\n",
    "            kwargs['writer'].add_scalar('model/log_z', torch.mean(log_z), kwargs['step'])\n",
    "            kwargs['writer'].add_scalar('model/z', torch.mean(z), kwargs['step'])\n",
    "        nobj = - objective\n",
    "        # std. dev. of z\n",
    "        # mu_z = torch.mean(x, dim=[1, 2, 3])\n",
    "        var_z = torch.var(x, dim=[1, 2, 3])\n",
    "        sd_z = torch.mean(torch.sqrt(var_z))\n",
    "\n",
    "        return nobj, sd_z\n",
    "\n",
    "    def loss(self, x, **kwargs):\n",
    "        \n",
    "        # if 'writer' in kwargs.keys():\n",
    "        #     batch_average = torch.mean(x, dim=0)\n",
    "        #     kwargs['writer'].add_histogram('real_noise', batch_average, kwargs['step'])\n",
    "        #     kwargs['writer'].add_scalar('real_noise_std', torch.std(batch_average), kwargs['step'])\n",
    "\n",
    "        nll, sd_z = self._loss(x=x, **kwargs)\n",
    "        nll_dim = torch.mean(nll) / np.prod(x.shape[1:])\n",
    "        # nll_dim = torch.mean(nll)      # The above line should be uncommented\n",
    "\n",
    "        return nll_dim, sd_z\n",
    "\n",
    "    def inverse(self, z, **kwargs):\n",
    "        x = z\n",
    "        for bijector in reversed(self.model):\n",
    "            x = bijector._inverse(x, **kwargs)\n",
    "        return x\n",
    "    \n",
    "    def sample(self, eps_std=None, **kwargs):\n",
    "        _, sample = self.prior(\"prior\", kwargs['clean'])\n",
    "        z = sample(eps_std)\n",
    "        x = self.inverse(z, **kwargs)\n",
    "        batch_average = torch.mean(x, dim=0)\n",
    "        if 'writer' in kwargs.keys():\n",
    "            kwargs['writer'].add_histogram('sample_noise', batch_average, kwargs['step'])\n",
    "            kwargs['writer'].add_scalar('sample_noise_std', torch.std(batch_average), kwargs['step'])\n",
    "\n",
    "        return x\n",
    "\n",
    "    def prior(self, name, x):\n",
    "        n_z = x.shape[1]\n",
    "        h = torch.zeros([x.shape[0]] +  [2 * n_z] + list(x.shape[2:4]), device=x.device)\n",
    "        pz = gaussian_diag(h[:, :n_z, :, :], h[:, n_z:, :, :])\n",
    "\n",
    "        def logp(z1):\n",
    "            objective = pz.logp(z1)\n",
    "            return objective\n",
    "\n",
    "        def sample(eps_std=None):\n",
    "            if eps_std is not None:\n",
    "                z = pz.sample2(pz.eps * torch.reshape(eps_std, [-1, 1, 1, 1]))\n",
    "            else:\n",
    "                z = pz.sample\n",
    "            return z\n",
    "\n",
    "        return logp, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import randn as torch_randn\n",
    "from fastai.vision.all import test_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-AffineCoupling\n",
      "cuda\n",
      "[ModuleList(\n",
      "  (0): Unconditional(\n",
      "    (glow): GlowBlock(\n",
      "      (flows): ModuleList(\n",
      "        (0): AffineCouplingBlock(\n",
      "          (flows): ModuleList(\n",
      "            (0): Split()\n",
      "            (1): AffineCoupling(\n",
      "              (param_map): ConvNet2d(\n",
      "                (net): Sequential(\n",
      "                  (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                  (1): LeakyReLU(negative_slope=0.0)\n",
      "                  (2): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "                  (3): LeakyReLU(negative_slope=0.0)\n",
      "                  (4): Conv2d(16, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (2): Merge()\n",
      "          )\n",
      "        )\n",
      "        (1): ActNorm()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")]\n",
      "torch.Size([16, 1, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "x = torch_randn(16,1,64,64).to('cuda')\n",
    "xdim = len(x.shape)-2\n",
    "\n",
    "tst = NoiseFlow(x.shape, arch='unc').to('cuda')\n",
    "mods = list(tst.children())\n",
    "print(mods)\n",
    "# test_eq(tst(x.cuda()).shape, [16, 1, 32, 64, 64])\n",
    "logp = tst(x, clean=x)\n",
    "print(logp.shape)\n",
    "test_eq(logp.shape, x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 65536])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(x.size(1), -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
