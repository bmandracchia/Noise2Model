{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "> Data handling functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random, os\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io import savemat\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from Noise2Model.utils import rot_hflip_img, tensor2np, np2tensor, mean_conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "dataset_class_dict = {}\n",
    "\n",
    "def regist_dataset(dataset_class):\n",
    "    dataset_name = dataset_class.__name__.lower()\n",
    "    assert not dataset_name in dataset_class_dict, 'there is already registered dataset: %s in dataset_class_dict.' % dataset_name\n",
    "    dataset_class_dict[dataset_name] = dataset_class\n",
    "    return dataset_class\n",
    "\n",
    "def get_dataset_class(dataset_name):\n",
    "    dataset_name = dataset_name.lower()\n",
    "    return dataset_class_dict[dataset_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_FMD_img_paths(base_path):\n",
    "    file_paths = list()\n",
    "    for _ , dirs, _ in os.walk(base_path):\n",
    "        for dir in dirs:\n",
    "            for full_path, _, file_names in os.walk(os.path.join(base_path,dir, 'raw')):\n",
    "                for file_name in file_names:\n",
    "                    if 'png' in file_name:\n",
    "                        raw_path = os.path.join(full_path, file_name)\n",
    "                        gt_path = os.path.join(full_path.replace('raw','gt'), 'avg50.png')\n",
    "                        if os.path.exists(gt_path):\n",
    "                            file_paths.append({'GT':gt_path,'NOISY': raw_path})\n",
    "    return file_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_FMD_img_paths('../_data/Confocal'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def convert_setup_code(model_name):\n",
    "    models = ['100x', '060x']\n",
    "    for idx, model in enumerate(models):\n",
    "        if model == model_name: return idx\n",
    "    assert False, \"Invalid setup code.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def convert_camera_code(model_name):\n",
    "    models = ['sCMOS', 'EMCCD', 'PMT']\n",
    "    for idx, model in enumerate(models):\n",
    "        if model == model_name: return idx\n",
    "    assert False, \"Invalid setup code.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def convert_sample_code(model_name):\n",
    "    models = ['nothing', 'siemens_star', 'USAF', 'DAPI']\n",
    "    for idx, model in enumerate(models):\n",
    "        if model == model_name: return idx\n",
    "    assert False, \"Invalid setup code.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO: add code similar to next cell that can read info from metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def parse_dir_name(dir_name):\n",
    "    tokens = dir_name.split('_')\n",
    "    return {\n",
    "        'scene-instance-number': int(tokens[0]),\n",
    "        'scene-number': int('001'),\n",
    "        'optical-setup': int(convert_setup_code('060x')),\n",
    "        'camera': int(convert_camera_code('PMT')), \n",
    "        'exposure-time': int('00060'), # ms\n",
    "        'wavelength': int('600'), # nm\n",
    "        'sample-code':int(convert_sample_code('nothing')) \n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop\n",
    "\n",
    "Crop whole image into patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def crop(img, size, overlap):\n",
    "    crops = list()\n",
    "    img = img.transpose(2,0,1)\n",
    "    _,h,w = img.shape\n",
    "    i,j = 0, 0\n",
    "    while i < h:\n",
    "        while j < w:\n",
    "            roi_x, roi_y = j, i\n",
    "            if i + size > h: roi_y = h - size \n",
    "            if j + size > w: roi_x = w - size\n",
    "            # crops.append(img[:,roi_y:roi_y+size,roi_x:roi_x+size])\n",
    "            crops.append(img[:1,roi_y:roi_y+size,roi_x:roi_x+size])\n",
    "            j+=overlap\n",
    "        j=0\n",
    "        i+=overlap\n",
    "    i=0\n",
    "    return crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def preprocessing(data_path,\n",
    "                    patch_size = 96,\n",
    "                    overlap = 8,\n",
    "                    mode = 'NOISE_GEN', # ['NOISE_GEN', 'DENOISER', 'ALL']\n",
    "                    output_base_path = '../_data/HDF5_confocal_s96_o08',\n",
    "                    train_noisegen_idx = [1], #[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
    "                    train_denoiser_idx = [2],\n",
    "                    train_all_idx = [1],\n",
    "                    test_idx = [19],\n",
    "                    ):\n",
    "    \n",
    "    img_paths = get_FMD_img_paths(data_path) #load paths\n",
    "    \n",
    "    for img_idx, img_path in enumerate(tqdm(img_paths)):\n",
    "        img_gt = cv2.imread(img_path['GT'], cv2.IMREAD_COLOR) # read gt images\n",
    "        img_noisy = cv2.imread(img_path['NOISY'], cv2.IMREAD_COLOR) # read noisy images\n",
    "        config = parse_dir_name(img_path['GT'].split('/')[-2])\n",
    "        \n",
    "        img_gt_crops = crop(img_gt, patch_size, overlap)\n",
    "        img_noisy_crops = crop(img_noisy, patch_size, overlap)\n",
    "        assert len(img_gt_crops) == len(img_noisy_crops)\n",
    "\n",
    "        output_dir_path  = output_base_path\n",
    "        if mode == 'NOISE_GEN':\n",
    "            if config['scene-instance-number'] in train_noisegen_idx:\n",
    "                output_dir_path += '/noise_gen/train/'\n",
    "            elif config['scene-instance-number'] in test_idx:\n",
    "                output_dir_path += '/noise_gen/test/'\n",
    "            else:\n",
    "                continue\n",
    "        elif mode == 'DENOISER':\n",
    "            if config['scene-instance-number'] in train_denoiser_idx:\n",
    "                output_dir_path += '/denoiser/'\n",
    "            else:\n",
    "                continue\n",
    "        elif mode == 'ALL':\n",
    "            if config['scene-instance-number'] in train_all_idx:\n",
    "                output_dir_path += '/all/'\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "        os.makedirs(output_dir_path, exist_ok=True)\n",
    "        output_file_name = '%04d_%s.hdf5'%(img_idx, img_path['GT'].split('/')[-2])\n",
    "        hdf_file_path = os.path.join(output_dir_path, output_file_name)\n",
    "        with h5py.File(hdf_file_path, \"w\") as f:\n",
    "            for patch_idx, (gt, noisy) in enumerate(zip(img_gt_crops, img_noisy_crops)):\n",
    "                f.create_dataset(f'clean/{patch_idx}', data=gt)\n",
    "                f.create_dataset(f'noisy/{patch_idx}', data=noisy)\n",
    "            hdf5_config = f.create_group('config')\n",
    "            for key in config:\n",
    "                hdf5_config.attrs[key] = config[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [04:18<00:00, 11.60it/s] \n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "\n",
    "preprocessing('../_data/Confocal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def find_support_scene(img_paths, current_path):\n",
    "    random.shuffle(img_paths) # shuffling\n",
    "    current_config = parse_dir_name(current_path['GT'].split('/')[-2])\n",
    "    for img_path in img_paths:\n",
    "        target_config = parse_dir_name(img_path['GT'].split('/')[-2])\n",
    "        if target_config['optical-setup'] == current_config['optical-setup'] and \\\n",
    "        target_config['camera'] == current_config['camera'] and \\\n",
    "        target_config['scene-instance-number'] != current_config['scene-instance-number']:\n",
    "            return img_path\n",
    "    assert False, \"There is no matching scene.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def load_and_display_hdf5_image(file_path, dataset_name='clean', patch_num=20, slice=0):\n",
    "    with h5py.File(file_path, 'r') as file:\n",
    "        image_data = file[dataset_name + '/' + '%d'%(patch_num)][:] \n",
    "        print(image_data.shape)\n",
    "    plt.imshow(image_data[slice], cmap='gray')  # Adjust cmap as per your image format\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../_data/HDF5_confocal_s96_o08/noise_gen/test/0500_19.hdf5\n",
      "(1, 96, 96)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example usage:\n",
    "output_base_path = '../_data/HDF5_confocal_s96_o08'\n",
    "file_path = output_base_path + '/noise_gen/test/0500_19.hdf5'\n",
    "print(file_path)\n",
    "load_and_display_hdf5_image(file_path, dataset_name='clean', patch_num=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['camera', 'exposure-time', 'optical-setup', 'sample-code', 'scene-instance-number', 'scene-number', 'wavelength']\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(file_path, 'r') as file:\n",
    "        image_data = file\n",
    "        print(list(image_data['config'].attrs.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "    \n",
    "class BaseDataset(Dataset):\n",
    "    def __init__(self, path=None, add_noise:str=None, crop_size:list=None, aug:list=None, n_repeat:int=1, n_data:int=None, ratio_data:float=None, step:int=None, scale=None) -> None:\n",
    "        '''\n",
    "        Base denoising dataset class for various dataset.\n",
    "\n",
    "        to build custom dataset class, below functions must be implemented in the inherited class. (or see other dataset class already implemented.)\n",
    "            - self._scan(self) : scan image data & save its paths. (saved to self.img_paths)\n",
    "            - self._load_data(self, data_idx) : load single paired data from idx as a form of dictionary.\n",
    "\n",
    "        Args:\n",
    "            add_noise (str)     : configuration of additive noise to synthesize noisy image. (see _add_noise() for more details.)\n",
    "            crop_size (list)    : crop size, e.g. [W] or [H, W] and no crop if None\n",
    "            aug (list)          : list of data augmentations (see _augmentation() for more details.)\n",
    "            n_repeat (int)      : number of repeat for each data.\n",
    "            n_data (int)        : number of data to be used. (default: None = all data)\n",
    "            ratio_data (float)  : ratio of data to be used. (activated when n_data=None, default: None = all data)\n",
    "        '''\n",
    "       \n",
    "        # parse additive noise argument\n",
    "        self.add_noise_type, self.add_noise_opt, self.add_noise_clamp = self._parse_add_noise(add_noise)\n",
    "\n",
    "        # set parameters for dataset.\n",
    "        self.crop_size = crop_size\n",
    "        self.scale = scale\n",
    "        self.aug = aug\n",
    "        self.n_repeat = n_repeat\n",
    "\n",
    "        self._get_img_paths(path)\n",
    "        self._apply_step(step)\n",
    "\n",
    "        # set data amount\n",
    "        if n_data is not None:       self.n_data = n_data\n",
    "        elif ratio_data is not None: self.n_data = int(ratio_data * len(self.img_paths))\n",
    "        else:                        self.n_data = len(self.img_paths)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_data * self.n_repeat\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        final dictionary shape of data:\n",
    "        {'clean', 'syn_noisy', 'real_noisy', 'noisy (any of real[first priority] and syn)', etc}\n",
    "        '''\n",
    "        # calculate data index\n",
    "        data_idx = idx % self.n_data\n",
    "\n",
    "        # load data\n",
    "        data = self._load_data(data_idx)\n",
    "\n",
    "        # pre-processing (currently only crop)\n",
    "        data = self._pre_processing(data)\n",
    "\n",
    "        # synthesize additive noise \n",
    "        if self.add_noise_type is not None:\n",
    "            if 'clean' in data:\n",
    "                syn_noisy_img, nlf = self._add_noise(data['clean'], self.add_noise_type, self.add_noise_opt, self.add_noise_clamp)\n",
    "                data['syn_noisy'] = syn_noisy_img\n",
    "                data['nlf'] = nlf\n",
    "            elif 'real_noisy' in data:\n",
    "                syn_noisy_img, nlf = self._add_noise(data['real_noisy'], self.add_noise_type, self.add_noise_opt, self.add_noise_clamp)\n",
    "                data['syn_noisy'] = syn_noisy_img\n",
    "                data['nlf'] = nlf\n",
    "            else:\n",
    "                raise RuntimeError('there is no clean or real image to synthesize. (synthetic noise type: %s)'%self.add_noise_type)\n",
    "\n",
    "        # data augmentation\n",
    "        if self.aug is not None:\n",
    "            data = self._augmentation(data, self.aug)\n",
    "\n",
    "        # add general label 'noisy' to use any of real_noisy or syn_noisy (real first)\n",
    "        if 'real_noisy' in data or 'syn_noisy' in data:\n",
    "            data['noisy'] = data['real_noisy'] if 'real_noisy' in data else data['syn_noisy']\n",
    "\n",
    "        return data\n",
    "\n",
    "    def _get_img_paths(self, dataset_path):\n",
    "        if dataset_path is None:\n",
    "            self.dataset_dir = './dataset'\n",
    "        else:\n",
    "            self.dataset_dir = dataset_path\n",
    "        if not os.path.isdir(self.dataset_dir):\n",
    "            raise Exception('dataset directory is not exist')\n",
    "        \n",
    "        # scan all data and fill in self.img_paths\n",
    "        self.img_paths = []\n",
    "        self._scan()\n",
    "        if len(self.img_paths) > 0:\n",
    "            if self.img_paths[0].__class__.__name__ in ['int', 'str', 'float']:\n",
    "                self.img_paths.sort()\n",
    "\n",
    "    def _apply_step(self, step):\n",
    "        step_paths = list()\n",
    "        for idx, path in enumerate(self.img_paths):\n",
    "            if idx % step == 0:\n",
    "                step_paths.append(path)\n",
    "        self.img_paths = step_paths\n",
    "\n",
    "    def _scan(self):\n",
    "        raise NotImplementedError\n",
    "        # TODO fill in self.img_paths (include path from project directory)\n",
    "\n",
    "    def _load_data(self, data_idx):\n",
    "        raise NotImplementedError\n",
    "        # TODO load possible data as dictionary\n",
    "        # dictionary key list :\n",
    "        #   'clean' : clean image without noise (gt or anything).\n",
    "        #   'real_noisy' : real noisy image or already synthesized noisy image.\n",
    "        #   'instances' : any other information of capturing situation.\n",
    "\n",
    "    #----------------------------#\n",
    "    #  Image handling functions  #\n",
    "    #----------------------------#\n",
    "    def _load_img(self, img_name, as_gray=False):\n",
    "        img = cv2.imread(img_name, 1)\n",
    "        assert img is not None, \"failure on loading image - %s\"%img_name\n",
    "        return self._load_img_from_np(img, as_gray, RGBflip=True)\n",
    "\n",
    "    def _load_img_from_np(self, img, as_gray=False, RGBflip=False):\n",
    "        # if color\n",
    "        if len(img.shape) != 2:\n",
    "            if as_gray:\n",
    "                # follows definition of sRBG in terms of the CIE 1931 linear luminance.\n",
    "                # because calculation opencv color conversion and imread grayscale mode is a bit different.\n",
    "                # https://en.wikipedia.org/wiki/Grayscale\n",
    "                img = np.average(img, axis=2, weights=[0.0722, 0.7152, 0.2126])\n",
    "                img = np.expand_dims(img, axis=0)\n",
    "            else:\n",
    "                if RGBflip:\n",
    "                    img = np.flip(img, axis=2)\n",
    "                img = np.transpose(img, (2,0,1))\n",
    "        # if gray\n",
    "        else:                   \n",
    "            img = np.expand_dims(img, axis=0)\n",
    "        return torch.from_numpy(np.ascontiguousarray(img).astype(np.float32))\n",
    "\n",
    "    def _pre_processing(self, data):\n",
    "        # get a patch from image data\n",
    "        if self.crop_size != None:\n",
    "            data = self._get_patch(self.crop_size, data)\n",
    "        if self.scale != None:\n",
    "            for x in data:\n",
    "                data[x] *= self.scale\n",
    "        return data\n",
    "\n",
    "    def _get_patch(self, crop_size, data, rnd=True):\n",
    "        # check all image size is same\n",
    "        if 'clean' in data and 'real_noisy' in data:\n",
    "            assert data['clean'].shape[1] == data['clean'].shape[1] and data['real_noisy'].shape[2] == data['real_noisy'].shape[2], \\\n",
    "            'img shape should be same. (%d, %d) != (%d, %d)' % (data['clean'].shape[1], data['clean'].shape[1], data['real_noisy'].shape[2], data['real_noisy'].shape[2])\n",
    "\n",
    "        # get image shape and select random crop location\n",
    "        if 'clean' in data:\n",
    "            max_x = data['clean'].shape[2] - crop_size[0]\n",
    "            max_y = data['clean'].shape[1] - crop_size[1]\n",
    "        else:\n",
    "            max_x = data['real_noisy'].shape[2] - crop_size[0]\n",
    "            max_y = data['real_noisy'].shape[1] - crop_size[1]\n",
    "\n",
    "        assert max_x >= 0\n",
    "        assert max_y >= 0\n",
    "\n",
    "        if rnd and max_x>0 and max_y>0:\n",
    "            x = np.random.randint(0, max_x)\n",
    "            y = np.random.randint(0, max_y)\n",
    "        else:\n",
    "            x, y = 0, 0\n",
    "\n",
    "        # crop\n",
    "        if 'clean' in data:\n",
    "            data['clean'] = data['clean'][:, y:y+crop_size[1], x:x+crop_size[0]]\n",
    "        if 'real_noisy' in data:\n",
    "            data['real_noisy'] = data['real_noisy'][:, y:y+crop_size[1], x:x+crop_size[0]]\n",
    "        \n",
    "        return data\n",
    "\n",
    "    def normalize_data(self, data, cuda=False):\n",
    "        # for all image\n",
    "        for key in data:\n",
    "            if self._is_image_tensor(data[key]):\n",
    "                data[key] = self.normalize(data[key], cuda)\n",
    "        return data\n",
    "\n",
    "    def inverse_normalize_data(self, data, cuda=False):\n",
    "        # for all image\n",
    "        for key in data:\n",
    "            # is image \n",
    "            if self._is_image_tensor(data[key]):\n",
    "                data[key] = self.inverse_normalize(data[key], cuda)\n",
    "        return data\n",
    "\n",
    "    def normalize(self, img, cuda=False):\n",
    "        if img.shape[0] == 1:\n",
    "            stds = self.gray_stds\n",
    "            means = self.gray_means\n",
    "        elif img.shape[0] == 3:\n",
    "            stds = self.color_stds\n",
    "            means = self.color_means\n",
    "        else:\n",
    "            raise RuntimeError('undefined image channel length : %d'%img.shape[0])\n",
    "        \n",
    "        if cuda:\n",
    "            means, stds = means.cuda(), stds.cuda() \n",
    "\n",
    "        return (img-means) / stds\n",
    "\n",
    "    def inverse_normalize(self, img, cuda=False):\n",
    "        if img.shape[0] == 1:\n",
    "            stds = self.gray_stds\n",
    "            means = self.gray_means\n",
    "        elif img.shape[0] == 3:\n",
    "            stds = self.color_stds\n",
    "            means = self.color_means\n",
    "        else:\n",
    "            raise RuntimeError('undefined image channel length : %d'%img.shape[0])\n",
    "        \n",
    "        if cuda:\n",
    "            means, stds = means.cuda(), stds.cuda() \n",
    "\n",
    "        return (img*stds) + means\n",
    "\n",
    "    def _parse_add_noise(self, add_noise_str:str):\n",
    "        '''\n",
    "        noise_type-opt0:opt1:opt2-clamp\n",
    "        '''\n",
    "        if add_noise_str == 'bypass':\n",
    "            return 'bypass', None, None\n",
    "        elif add_noise_str != None:\n",
    "            add_noise_type = add_noise_str.split('-')[0]\n",
    "            add_noise_opt = [float(v) for v in add_noise_str.split('-')[1].split(':')]\n",
    "            add_noise_clamp = len(add_noise_str.split('-'))>2 and add_noise_str.split('-')[2] == 'clamp'\n",
    "            return add_noise_type, add_noise_opt, add_noise_clamp\n",
    "        else:\n",
    "            return None, None, None\n",
    "\n",
    "    def _add_noise(self, clean_img:torch.Tensor, add_noise_type:str, opt:list, clamp:bool=False) -> torch.Tensor:\n",
    "        '''\n",
    "        add various noise to clean image.\n",
    "        Args:\n",
    "            clean_img (Tensor) : clean image to synthesize on\n",
    "            add_noise_type : below types are available\n",
    "            opt (list) : args for synthsize noise\n",
    "            clamp (bool) : optional, clamp noisy image into [0,255]\n",
    "        Return:\n",
    "            synthesized_img\n",
    "        Noise_types\n",
    "            - bypass : bypass clean image\n",
    "            - uni : uniform distribution noise from -opt[0] ~ opt[0]\n",
    "            - gau : gaussian distribution noise with zero-mean & opt[0] variance\n",
    "            - gau_blind : blind gaussian distribution with zero-mean, variance is uniformly selected from opt[0] ~ opt[1]\n",
    "            - struc_gau : structured gaussian noise. gaussian filter is applied to above gaussian noise. opt[0] is variance of gaussian, opt[1] is window size and opt[2] is sigma of gaussian filter.\n",
    "            - het_gau : heteroscedastic gaussian noise with indep weight:opt[0], dep weight:opt[1]\n",
    "        '''\n",
    "        nlf = None\n",
    "\n",
    "        if add_noise_type == 'bypass':\n",
    "            # bypass clean image\n",
    "            synthesized_img = clean_img\n",
    "        elif add_noise_type == 'uni':\n",
    "            # add uniform noise\n",
    "            synthesized_img = clean_img + 2*opt[0] * torch.rand(clean_img.shape) - opt[0]\n",
    "        elif add_noise_type == 'gau':\n",
    "            # add AWGN\n",
    "            nlf = opt[0]\n",
    "            synthesized_img = clean_img + torch.normal(mean=0., std=nlf, size=clean_img.shape)\n",
    "        elif add_noise_type == 'gau_blind':\n",
    "            # add blind gaussian noise\n",
    "            nlf = random.uniform(opt[0], opt[1])\n",
    "            synthesized_img = clean_img + torch.normal(mean=0., std=nlf, size=clean_img.shape)\n",
    "        elif add_noise_type == 'struc_gau':\n",
    "            # add structured gaussian noise (used in the paper \"Noiser2Noise\": https://arxiv.org/pdf/1910.11908.pdf)\n",
    "            nlf = opt[0]\n",
    "            gau_noise = torch.normal(mean=0., std=opt[0], size=clean_img.shape)\n",
    "            struc_gau = mean_conv2d(gau_noise,  window_size=int(opt[1]), sigma=opt[2], keep_sigma=True)\n",
    "            synthesized_img = clean_img + struc_gau\n",
    "        elif add_noise_type == 'het_gau':\n",
    "            # add heteroscedastic  guassian noise\n",
    "            het_gau_std = (clean_img * (opt[0]**2) + torch.ones(clean_img.shape) * (opt[1]**2)).sqrt()\n",
    "            nlf = het_gau_std\n",
    "            synthesized_img = clean_img + torch.normal(mean=0., std=nlf)\n",
    "        else:\n",
    "            raise RuntimeError('undefined additive noise type : %s'%add_noise_type)\n",
    "\n",
    "        if clamp:\n",
    "            synthesized_img = torch.clamp(synthesized_img, 0, 255)\n",
    "\n",
    "        return synthesized_img, nlf\n",
    "\n",
    "    def _augmentation(self, data:dict, aug:list):\n",
    "        '''\n",
    "        Parsing augmentation list and apply it to the data images.\n",
    "        '''\n",
    "        # parsign augmentation\n",
    "        rot, hflip = 0, 0\n",
    "        for aug_name in aug:\n",
    "            # aug : random rotation\n",
    "            if aug_name == 'rot':\n",
    "                rot = random.randint(0,3)\n",
    "            # aug : random flip\n",
    "            elif aug_name == 'hflip':\n",
    "                hflip = random.randint(0,1)\n",
    "            else:\n",
    "                raise RuntimeError('undefined augmentation option : %s'%aug_name)\n",
    "        \n",
    "        # for every data(only image), apply rotation and flipping augmentation.\n",
    "        for key in data:\n",
    "            if self._is_image_tensor(data[key]):\n",
    "                # random rotation and flip\n",
    "                if rot != 0 or hflip != 0:\n",
    "                    data[key] = rot_hflip_img(data[key], rot, hflip)\n",
    "            \n",
    "        return data\n",
    "\n",
    "    #----------------------------#\n",
    "    #   Image saving functions   #\n",
    "    #----------------------------#\n",
    "    def save_all_image(self, dir, clean=False, syn_noisy=False, real_noisy=False):\n",
    "        for idx in range(len(self.img_paths)):\n",
    "            data = self.__getitem__(idx)\n",
    "\n",
    "            if clean and 'clean' in data:\n",
    "                cv2.imwrite(os.path.join(dir, '%05d_CL.png'%idx), tensor2np(data['clean']))\n",
    "            if syn_noisy and 'syn_noisy' in data:\n",
    "                cv2.imwrite(os.path.join(dir, '%05d_SN.png'%idx), tensor2np(data['syn_noisy']))\n",
    "            if real_noisy and 'real_noisy' in data:\n",
    "                cv2.imwrite(os.path.join(dir, '%05d_RN.png'%idx), tensor2np(data['real_noisy']))\n",
    "\n",
    "            print('image %05d saved!'%idx)\n",
    "\n",
    "    def prep_save(self, img_idx:int, img_size:int, overlap:int, clean:bool=False, syn_noisy:bool=False, real_noisy:bool=False):\n",
    "        '''\n",
    "        cropping am image into mini-size patches for efficient training.\n",
    "        Args:\n",
    "            img_idx (int) : index of image\n",
    "            img_size (int) : size of image\n",
    "            overlap (int) : overlap between patches\n",
    "            clean (bool) : save clean image (default: False)\n",
    "            syn_noisy (bool) : save synthesized noisy image (default: False)\n",
    "            real_noisy (bool) : save real noisy image (default: False)\n",
    "        '''\n",
    "        d_name = '%s_s%d_o%d'%(self.__class__.__name__, img_size, overlap)\n",
    "        os.makedirs(os.path.join(self.dataset_dir, 'prep', d_name), exist_ok=True)\n",
    "\n",
    "        assert overlap < img_size\n",
    "        stride = img_size - overlap\n",
    "\n",
    "        if clean:\n",
    "            clean_dir = os.path.join(self.dataset_dir, 'prep', d_name, 'CL')\n",
    "            os.makedirs(clean_dir, exist_ok=True)\n",
    "        if syn_noisy: \n",
    "            syn_noisy_dir = os.path.join(self.dataset_dir, 'prep', d_name, 'SN')\n",
    "            os.makedirs(syn_noisy_dir, exist_ok=True)\n",
    "        if real_noisy:\n",
    "            real_noisy_dir = os.path.join(self.dataset_dir, 'prep', d_name, 'RN')\n",
    "            os.makedirs(real_noisy_dir, exist_ok=True)\n",
    "\n",
    "        data = self.__getitem__(img_idx)\n",
    "\n",
    "        c,h,w = data['clean'].shape if 'clean' in data else data['real_noisy'].shape\n",
    "        for h_idx in range((h-img_size)//stride + 1):\n",
    "            for w_idx in range((w-img_size+1)//stride + 1):\n",
    "                hl, hr = h_idx*stride, h_idx*stride+img_size\n",
    "                wl, wr = w_idx*stride, w_idx*stride+img_size\n",
    "                if clean:      cv2.imwrite(os.path.join(clean_dir,      '%d_%d_%d.png'%(img_idx, h_idx, w_idx)), tensor2np(data['clean'][:,hl:hr,wl:wr])) \n",
    "                if syn_noisy:  cv2.imwrite(os.path.join(syn_noisy_dir,  '%d_%d_%d.png'%(img_idx, h_idx, w_idx)), tensor2np(data['syn_noisy'][:,hl:hr,wl:wr])) \n",
    "                if real_noisy: cv2.imwrite(os.path.join(real_noisy_dir, '%d_%d_%d.png'%(img_idx, h_idx, w_idx)), tensor2np(data['real_noisy'][:,hl:hr,wl:wr])) \n",
    "\n",
    "        print('Cropped image %d / %d'%(img_idx, self.__len__()))\n",
    "        \n",
    "\n",
    "    #----------------------------#\n",
    "    #            etc             #\n",
    "    #----------------------------#\n",
    "    def _is_image_tensor(self, x):\n",
    "        '''\n",
    "        return input tensor has image shape. (include batched image)\n",
    "        '''\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            if len(x.shape) == 3 or len(x.shape) == 4:\n",
    "                if x.dtype != torch.bool:\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIDD (to be changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@regist_dataset\n",
    "class SIDD_HDF(BaseDataset):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    def _get_img_paths(self, dataset_path):\n",
    "        assert os.path.exists(dataset_path), f\"Invalid dataset path: {dataset_path}\"\n",
    "        self.dataset_path = dataset_path\n",
    "        self.dataset_dir = dataset_path\n",
    "        # scan all data and fill in self.img_paths\n",
    "        self.img_paths = []\n",
    "        self._scan()\n",
    "\n",
    "    def iterate_hdf5_objects(self, obj, prefix=\"\"):\n",
    "        \"\"\"\n",
    "        Recursively iterate over all objects in HDF5 file.\n",
    "        Returns tuple of (name, object).\n",
    "        \"\"\"\n",
    "        for name, obj in obj.items():\n",
    "            if isinstance(obj, h5py.Dataset):\n",
    "                yield f\"{prefix}/{name}\", obj\n",
    "            elif isinstance(obj, h5py.Group):\n",
    "                yield from self.iterate_hdf5_objects(obj, f\"{prefix}/{name}\")\n",
    "\n",
    "    def _scan(self):\n",
    "        file_paths = self._get_file_paths(self.dataset_dir, \".hdf5\")\n",
    "        for file_path in tqdm(file_paths):\n",
    "            with h5py.File(file_path, 'r') as hf:\n",
    "                assert len(hf['clean']) == len(hf['noisy'])\n",
    "                for name, obj in self.iterate_hdf5_objects(hf['clean']):\n",
    "                    h, w,_ = obj.shape\n",
    "                    self.img_paths.append({'clean': f\"clean{name}\", 'noisy': f\"noisy{name}\", 'width': w, 'height': h, 'file_path':file_path}) \n",
    "            \n",
    "    def _load_data(self, data_idx):\n",
    "        with h5py.File(self.img_paths[data_idx]['file_path'], 'r') as hf:\n",
    "            clean_img = hf[self.img_paths[data_idx]['clean']][...].astype(np.float32)\n",
    "            noisy_img = hf[self.img_paths[data_idx]['noisy']][...].astype(np.float32)\n",
    "        \n",
    "            if len(clean_img.shape) == 2: clean_img = np.expand_dims(clean_img, axis=0)\n",
    "            if len(noisy_img.shape) == 2: noisy_img = np.expand_dims(noisy_img, axis=0)\n",
    "            kwargs = dict()\n",
    "            for key in hf['config'].attrs.keys():\n",
    "                kwargs[key] = hf['config'].attrs[key]\n",
    "        \n",
    "        return {'clean': clean_img, 'real_noisy': noisy_img, 'kwargs':kwargs}\n",
    "        \n",
    "        \n",
    "    def _get_file_paths(self, path, force_extension=\".raw\"):\n",
    "        assert os.path.exists(path), f\"{path} dosen't exist.\"\n",
    "        assert os.path.isdir(path), f\"{path} is not directory.\"\n",
    "        \n",
    "        file_paths = list()\n",
    "        for r, d, f in os.walk(path):\n",
    "            for file in f:\n",
    "                if force_extension is not None:\n",
    "                    if force_extension in file:\n",
    "                        file_paths.append(os.path.join(r, file))\n",
    "                else:\n",
    "                    file_paths.append(os.path.join(r, file))\n",
    "        file_paths.sort()\n",
    "        return file_paths\n",
    "    \n",
    "\n",
    "@regist_dataset\n",
    "class SIDD_val(BaseDataset):\n",
    "    '''\n",
    "    SIDD validation dataset class \n",
    "    '''\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def _scan(self):\n",
    "        dataset_path = self.dataset_dir\n",
    "        assert os.path.exists(dataset_path), 'There is no dataset %s'%dataset_path\n",
    "\n",
    "        clean_mat_file_path = os.path.join(dataset_path, 'ValidationGtBlocksSrgb.mat')\n",
    "        noisy_mat_file_path = os.path.join(dataset_path, 'ValidationNoisyBlocksSrgb.mat')\n",
    "\n",
    "        self.clean_patches = np.array(scipy.io.loadmat(clean_mat_file_path, appendmat=False)['ValidationGtBlocksSrgb'])\n",
    "        self.noisy_patches = np.array(scipy.io.loadmat(noisy_mat_file_path, appendmat=False)['ValidationNoisyBlocksSrgb'])\n",
    "\n",
    "        # for __len__(), make img_paths have same length\n",
    "        # number of all possible patch is 1280\n",
    "        for _ in range(1280):\n",
    "            self.img_paths.append(None)\n",
    "\n",
    "    def _load_data(self, data_idx):\n",
    "        img_id   = data_idx // 32\n",
    "        patch_id = data_idx  % 32\n",
    "\n",
    "        clean_img = self.clean_patches[img_id, patch_id, :].astype(float)\n",
    "        noisy_img = self.noisy_patches[img_id, patch_id, :].astype(float)\n",
    "\n",
    "        clean_img = self._load_img_from_np(clean_img)\n",
    "        noisy_img = self._load_img_from_np(noisy_img)\n",
    "\n",
    "        return {'clean': clean_img, 'real_noisy': noisy_img }\n",
    "\n",
    "@regist_dataset\n",
    "class SIDD_benchmark(BaseDataset):\n",
    "    '''\n",
    "    SIDD benchmark dataset class\n",
    "    '''\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def _scan(self):\n",
    "        dataset_path = self.dataset_dir\n",
    "        assert os.path.exists(dataset_path), 'There is no dataset %s'%dataset_path\n",
    "\n",
    "        mat_file_path = os.path.join(dataset_path, 'BenchmarkNoisyBlocksSrgb.mat')\n",
    "\n",
    "        self.noisy_patches = np.array(scipy.io.loadmat(mat_file_path, appendmat=False)['BenchmarkNoisyBlocksSrgb'])\n",
    "\n",
    "        # for __len__(), make img_paths have same length\n",
    "        # number of all possible patch is 1280\n",
    "        for _ in range(1280):\n",
    "            self.img_paths.append(None)\n",
    "\n",
    "    def _load_data(self, data_idx):\n",
    "        img_id   = data_idx // 32\n",
    "        patch_id = data_idx  % 32\n",
    "\n",
    "        noisy_img = self.noisy_patches[img_id, patch_id, :].astype(float)\n",
    "\n",
    "        noisy_img = self._load_img_from_np(noisy_img)\n",
    "\n",
    "        return {'real_noisy': noisy_img}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:19<00:00,  7.86it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'clean': array([[[3., 3., 3., ..., 6., 6., 6.],\n",
       "         [3., 3., 3., ..., 6., 6., 6.],\n",
       "         [3., 3., 3., ..., 6., 6., 7.],\n",
       "         ...,\n",
       "         [3., 3., 3., ..., 3., 3., 3.],\n",
       "         [3., 3., 3., ..., 3., 3., 3.],\n",
       "         [3., 3., 3., ..., 3., 3., 3.]]], dtype=float32),\n",
       " 'real_noisy': array([[[ 3.,  3.,  3., ...,  4.,  4.,  5.],\n",
       "         [ 3.,  3.,  3., ...,  6.,  5.,  7.],\n",
       "         [ 3.,  3.,  3., ...,  3., 10.,  7.],\n",
       "         ...,\n",
       "         [ 6.,  3.,  6., ...,  3.,  3.,  3.],\n",
       "         [ 3.,  3.,  3., ...,  3.,  3.,  3.],\n",
       "         [ 3.,  3.,  3., ...,  3.,  3.,  3.]]], dtype=float32),\n",
       " 'kwargs': {'camera': 2,\n",
       "  'exposure-time': 60,\n",
       "  'optical-setup': 1,\n",
       "  'sample-code': 0,\n",
       "  'scene-instance-number': 1,\n",
       "  'scene-number': 1,\n",
       "  'wavelength': 600}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path = '../_data/HDF5_confocal_s96_o08/noise_gen/train/'\n",
    "\n",
    "data = SIDD_HDF(dir_path, n_data=1, step=1)\n",
    "data._load_data(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "n2m",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
