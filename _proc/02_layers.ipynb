{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: normalizing flow layers\n",
    "output-file: layers.html\n",
    "title: Layers\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from fastai.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/layers.py#L22){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### regist_layer\n",
       "\n",
       ">      regist_layer (layer_class)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/layers.py#L22){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### regist_layer\n",
       "\n",
       ">      regist_layer (layer_class)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(regist_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/layers.py#L31){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### get_flow_layer\n",
       "\n",
       ">      get_flow_layer (layer_name:str)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/layers.py#L31){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### get_flow_layer\n",
       "\n",
       ">      get_flow_layer (layer_name:str)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(get_flow_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pointwise Convs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/layers.py#L38){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### PointwiseConvs\n",
       "\n",
       ">      PointwiseConvs (in_features=1, out_features=1, feats=32, device='cpu',\n",
       ">                      name='pointwise_convs')\n",
       "\n",
       "Pointwise convolutional module for neural networks.\n",
       "\n",
       "This module consists of a series of pointwise convolutions with instance normalization\n",
       "and LeakyReLU activation functions.\n",
       "\n",
       "Attributes:\n",
       "    name (str): Name of the module.\n",
       "    device (str): Device to run computations on.\n",
       "    body (nn.Sequential): Sequential module containing the layers.\n",
       "\n",
       "Methods:\n",
       "    _get_basic_module(in_ch, out_ch, k_size=1, stride=1, padding=1, negative_slope=0.2):\n",
       "        Returns a basic convolutional module with instance normalization and LeakyReLU activation.\n",
       "\n",
       "    forward(x):\n",
       "        Performs forward pass through the module."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/layers.py#L38){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### PointwiseConvs\n",
       "\n",
       ">      PointwiseConvs (in_features=1, out_features=1, feats=32, device='cpu',\n",
       ">                      name='pointwise_convs')\n",
       "\n",
       "Pointwise convolutional module for neural networks.\n",
       "\n",
       "This module consists of a series of pointwise convolutions with instance normalization\n",
       "and LeakyReLU activation functions.\n",
       "\n",
       "Attributes:\n",
       "    name (str): Name of the module.\n",
       "    device (str): Device to run computations on.\n",
       "    body (nn.Sequential): Sequential module containing the layers.\n",
       "\n",
       "Methods:\n",
       "    _get_basic_module(in_ch, out_ch, k_size=1, stride=1, padding=1, negative_slope=0.2):\n",
       "        Returns a basic convolutional module with instance normalization and LeakyReLU activation.\n",
       "\n",
       "    forward(x):\n",
       "        Performs forward pass through the module."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(PointwiseConvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "channels = 1\n",
    "height = 2\n",
    "width = 2\n",
    "device = 'cuda'\n",
    "\n",
    "x = torch.randn(batch_size, channels, height, width).to(device)\n",
    "y = PointwiseConvs(in_features=channels, out_features=channels, feats=32, device=device)(x)\n",
    "\n",
    "assert y.size() == x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial Convs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/layers.py#L116){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SpatialConvs\n",
       "\n",
       ">      SpatialConvs (in_features=1, out_features=1, feats=32, receptive_field=9,\n",
       ">                    device='cpu', name='spatial_convs')\n",
       "\n",
       "Spatial convolutional module for neural networks.\n",
       "\n",
       "This module consists of a series of spatial convolutions with ReLU activation functions.\n",
       "\n",
       "Attributes:\n",
       "    name (str): Name of the module.\n",
       "    device (str): Device to run computations on.\n",
       "    receptive_field (int): Size of the receptive field for spatial convolutions.\n",
       "    body (nn.Sequential): Sequential module containing the layers.\n",
       "\n",
       "Methods:\n",
       "    _get_basic_module(in_ch, out_ch, k_size=1, stride=1, padding=1, negative_slope=0.2):\n",
       "        Returns a basic convolutional module with instance normalization and LeakyReLU activation.\n",
       "\n",
       "    forward(x):\n",
       "        Performs forward pass through the module."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/layers.py#L116){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SpatialConvs\n",
       "\n",
       ">      SpatialConvs (in_features=1, out_features=1, feats=32, receptive_field=9,\n",
       ">                    device='cpu', name='spatial_convs')\n",
       "\n",
       "Spatial convolutional module for neural networks.\n",
       "\n",
       "This module consists of a series of spatial convolutions with ReLU activation functions.\n",
       "\n",
       "Attributes:\n",
       "    name (str): Name of the module.\n",
       "    device (str): Device to run computations on.\n",
       "    receptive_field (int): Size of the receptive field for spatial convolutions.\n",
       "    body (nn.Sequential): Sequential module containing the layers.\n",
       "\n",
       "Methods:\n",
       "    _get_basic_module(in_ch, out_ch, k_size=1, stride=1, padding=1, negative_slope=0.2):\n",
       "        Returns a basic convolutional module with instance normalization and LeakyReLU activation.\n",
       "\n",
       "    forward(x):\n",
       "        Performs forward pass through the module."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(SpatialConvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "channels = 1\n",
    "height = 2\n",
    "width = 2\n",
    "device = 'cuda'\n",
    "\n",
    "x = torch.randn(batch_size, channels, height, width).to(device)\n",
    "y = SpatialConvs(in_features=channels, out_features=channels, feats=32, device=device)(x)\n",
    "\n",
    "assert y.size() == x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Flows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dequantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uniform Dequantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/layers.py#L201){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### UniformDequantization\n",
       "\n",
       ">      UniformDequantization (alpha=1e-05, num_bits=8, device='cpu',\n",
       ">                             name='uniform_dequantization')\n",
       "\n",
       "Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/layers.py#L201){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### UniformDequantization\n",
       "\n",
       ">      UniformDequantization (alpha=1e-05, num_bits=8, device='cpu',\n",
       ">                             name='uniform_dequantization')\n",
       "\n",
       "Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(UniformDequantization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[104, 161,  55, 237],\n",
      "        [118, 240, 207, 226],\n",
      "        [176, 207, 213, 247],\n",
      "        [241,  86, 108, 181]])\n",
      "tensor([[0.4095, 0.6310, 0.2175, 0.9286],\n",
      "        [0.4627, 0.9413, 0.8123, 0.8858],\n",
      "        [0.6902, 0.8096, 0.8325, 0.9685],\n",
      "        [0.9422, 0.3367, 0.4233, 0.7083]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randint(256,[4, 4])\n",
    "b, _ = UniformDequantization()._forward_and_log_det_jacobian(a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[104., 161.,  55., 237.],\n",
      "        [118., 240., 207., 226.],\n",
      "        [176., 207., 213., 247.],\n",
      "        [241.,  86., 108., 181.]])\n"
     ]
    }
   ],
   "source": [
    "c = UniformDequantization()._inverse(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variational Dequantization (TO DO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/layers.py#L381){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ConditionalLinear\n",
       "\n",
       ">      ConditionalLinear (device='cpu', name='linear_transformation',\n",
       ">                         codes={'code': [1, 2, 3]})\n",
       "\n",
       "Conditional linear transformation module.\n",
       "\n",
       "Applies different scales and biases based on average pixel size and camera values provided\n",
       "in the input. Supports both forward and inverse transformations.\n",
       "\n",
       "Attributes:\n",
       "    name (str): Name of the transformation.\n",
       "    setup_code (torch.Tensor): Predefined set of pixel sizes.\n",
       "    exp_times (torch.Tensor): Predefined set of camera values.\n",
       "    log_scale (torch.nn.Parameter): Learnable log-scale parameters.\n",
       "    bias (torch.nn.Parameter): Learnable bias parameters.\n",
       "\n",
       "Methods:\n",
       "    _inverse(z, **kwargs):\n",
       "        Performs the inverse transformation based on the input 'z' and conditionals.\n",
       "\n",
       "    _forward_and_log_det_jacobian(x, **kwargs):\n",
       "        Performs the forward transformation and computes the log determinant of the Jacobian."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/layers.py#L381){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ConditionalLinear\n",
       "\n",
       ">      ConditionalLinear (device='cpu', name='linear_transformation',\n",
       ">                         codes={'code': [1, 2, 3]})\n",
       "\n",
       "Conditional linear transformation module.\n",
       "\n",
       "Applies different scales and biases based on average pixel size and camera values provided\n",
       "in the input. Supports both forward and inverse transformations.\n",
       "\n",
       "Attributes:\n",
       "    name (str): Name of the transformation.\n",
       "    setup_code (torch.Tensor): Predefined set of pixel sizes.\n",
       "    exp_times (torch.Tensor): Predefined set of camera values.\n",
       "    log_scale (torch.nn.Parameter): Learnable log-scale parameters.\n",
       "    bias (torch.nn.Parameter): Learnable bias parameters.\n",
       "\n",
       "Methods:\n",
       "    _inverse(z, **kwargs):\n",
       "        Performs the inverse transformation based on the input 'z' and conditionals.\n",
       "\n",
       "    _forward_and_log_det_jacobian(x, **kwargs):\n",
       "        Performs the forward transformation and computes the log determinant of the Jacobian."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(ConditionalLinear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "channels = 1\n",
    "height = 2\n",
    "width = 2\n",
    "device = 'cuda'\n",
    "\n",
    "codes = {\n",
    "        'exposure-time': torch.tensor([10, 50, 100], dtype=torch.float32, device=device),\n",
    "        'optical-setup': torch.tensor([0, 1], dtype=torch.float32).to(device),\n",
    "        # 'camera': torch.tensor([0, 1], dtype=torch.float32).to(device)\n",
    "    }\n",
    "\n",
    "x = torch.randn(batch_size, channels, height, width).to(device)\n",
    "setup_idx = torch.tensor([1] * batch_size, dtype=torch.float32).to(device)\n",
    "time_idx = torch.tensor([10] * batch_size, dtype=torch.float32).to(device)\n",
    "\n",
    "kwargs = {'optical-setup': setup_idx, 'exposure-time': time_idx}\n",
    "\n",
    "print(ComputeIndex(codes)(batch_size, **kwargs))\n",
    "\n",
    "# Forward transformation\n",
    "z, log_det_jacobian = ConditionalLinear(device=device, codes=codes)._forward_and_log_det_jacobian(x, **kwargs)\n",
    "assert z.shape == x.shape\n",
    "assert log_det_jacobian.shape == torch.Size([batch_size])\n",
    "\n",
    "# Inverse transformation\n",
    "x_reconstructed = ConditionalLinear(device=device, codes=codes)._inverse(z, **kwargs)\n",
    "assert x_reconstructed.shape == x.shape\n",
    "\n",
    "# Check if the reconstructed input is close to the original input\n",
    "assert torch.allclose(x, x_reconstructed, atol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Linear $e^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/layers.py#L479){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ConditionalLinearExp2\n",
       "\n",
       ">      ConditionalLinearExp2 (in_ch=1, device='cpu',\n",
       ">                             name='linear_transformation_exp2', codes={'code':\n",
       ">                             [1, 2, 3]})\n",
       "\n",
       "Conditional linear transformation layer for flows, conditioned on specific ISO levels and setup codes.\n",
       "\n",
       "This module applies a linear transformation to the input tensor, where the transformation parameters\n",
       "(log scale and bias) are conditioned based on the pixel size and setup code provided as input. \n",
       "The module supports both forward and inverse transformations.\n",
       "\n",
       "Attributes:\n",
       "    name (str): Name of the module.\n",
       "    device (str): Device to run computations on.\n",
       "    pixel_size (tensor): pixel size used for conditioning.\n",
       "    cam_vals (tensor): Predefined setup codes used for conditioning.\n",
       "    log_scale (nn.Parameter): Learnable log scale parameters for the transformation.\n",
       "    bias (nn.Parameter): Learnable bias parameters for the transformation.\n",
       "\n",
       "Methods:\n",
       "    _inverse(z, **kwargs):\n",
       "        Applies the inverse transformation to the input tensor z.\n",
       "\n",
       "    _forward_and_log_det_jacobian(x, **kwargs):\n",
       "        Applies the forward transformation to the input tensor x and computes the log determinant\n",
       "        of the Jacobian of the transformation."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/layers.py#L479){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ConditionalLinearExp2\n",
       "\n",
       ">      ConditionalLinearExp2 (in_ch=1, device='cpu',\n",
       ">                             name='linear_transformation_exp2', codes={'code':\n",
       ">                             [1, 2, 3]})\n",
       "\n",
       "Conditional linear transformation layer for flows, conditioned on specific ISO levels and setup codes.\n",
       "\n",
       "This module applies a linear transformation to the input tensor, where the transformation parameters\n",
       "(log scale and bias) are conditioned based on the pixel size and setup code provided as input. \n",
       "The module supports both forward and inverse transformations.\n",
       "\n",
       "Attributes:\n",
       "    name (str): Name of the module.\n",
       "    device (str): Device to run computations on.\n",
       "    pixel_size (tensor): pixel size used for conditioning.\n",
       "    cam_vals (tensor): Predefined setup codes used for conditioning.\n",
       "    log_scale (nn.Parameter): Learnable log scale parameters for the transformation.\n",
       "    bias (nn.Parameter): Learnable bias parameters for the transformation.\n",
       "\n",
       "Methods:\n",
       "    _inverse(z, **kwargs):\n",
       "        Applies the inverse transformation to the input tensor z.\n",
       "\n",
       "    _forward_and_log_det_jacobian(x, **kwargs):\n",
       "        Applies the forward transformation to the input tensor x and computes the log determinant\n",
       "        of the Jacobian of the transformation."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(ConditionalLinearExp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "channels = 1\n",
    "height = 2\n",
    "width = 2\n",
    "device = 'cuda'\n",
    "\n",
    "codes = {\n",
    "        'exposure-time': torch.tensor([10, 50, 100], dtype=torch.float32, device=device),\n",
    "        'optical-setup': torch.tensor([0, 1], dtype=torch.float32).to(device),\n",
    "        # 'camera': torch.tensor([0, 1], dtype=torch.float32).to(device)\n",
    "    }\n",
    "\n",
    "x = torch.randn(batch_size, channels, height, width).to(device)\n",
    "\n",
    "kwargs = {\n",
    "        'exposure-time': torch.tensor([50], dtype=torch.float32).to(device),\n",
    "        'optical-setup': torch.tensor([0], dtype=torch.float32).to(device)\n",
    "    }\n",
    "\n",
    " # Forward transformation\n",
    "z, log_det_jacobian = ConditionalLinearExp2(device=device, in_ch=x.shape[1], codes=codes)._forward_and_log_det_jacobian(x, **kwargs)\n",
    "assert z.shape == x.shape\n",
    "assert log_det_jacobian.shape == torch.Size([batch_size])\n",
    "\n",
    "# Inverse transformation\n",
    "x_reconstructed = ConditionalLinearExp2(device=device, in_ch=x.shape[1], codes=codes)._inverse(z, **kwargs)\n",
    "assert x_reconstructed.shape == x.shape\n",
    "\n",
    "# Check if the reconstructed input is close to the original input\n",
    "assert torch.allclose(x, x_reconstructed, atol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal Dependent Conditional Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/layers.py#L581){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SignalDependentConditionalLinear\n",
       "\n",
       ">      SignalDependentConditionalLinear (meta_encoder, scale_and_bias, in_ch=1,\n",
       ">                                        device='cpu', name='signal_dependent_co\n",
       ">                                        ndition_linear', codes={'code': [1, 2,\n",
       ">                                        3]}, encode_ch=3)\n",
       "\n",
       "Signal-dependent conditional linear transformation layer for flows.\n",
       "\n",
       "This module applies a linear transformation to the input tensor, where the transformation parameters\n",
       "(log scale and bias) are conditioned on ISO levels and smartphone codes provided as input features.\n",
       "The conditioning is performed using embeddings generated from meta encoders and scale-and-bias modules.\n",
       "\n",
       "Attributes:\n",
       "    name (str): Name of the module.\n",
       "    device (str): Device to run computations on.\n",
       "    in_ch (int): Number of input channels.\n",
       "    setup_codes (tensor): Predefined ISO levels used for conditioning.\n",
       "    exp_times (tensor): Predefined smartphone codes used for conditioning.\n",
       "    encode_ch (int): Number of channels in the embeddings generated by the meta encoder.\n",
       "    meta_encoder (nn.Module): Meta encoder module to generate embeddings from ISO and camera inputs.\n",
       "    scale_and_bias (nn.Module): Module to compute scale and bias parameters based on embeddings and input features.\n",
       "\n",
       "Methods:\n",
       "    _get_embeddings(x, **kwargs):\n",
       "        Generates embeddings from ISO-level and smartphone-code inputs and concatenates them with additional features.\n",
       "\n",
       "    _inverse(z, **kwargs):\n",
       "        Applies the inverse transformation to the input tensor z.\n",
       "\n",
       "    _forward_and_log_det_jacobian(x, **kwargs):\n",
       "        Applies the forward transformation to the input tensor x and computes the log determinant of the Jacobian."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/layers.py#L581){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SignalDependentConditionalLinear\n",
       "\n",
       ">      SignalDependentConditionalLinear (meta_encoder, scale_and_bias, in_ch=1,\n",
       ">                                        device='cpu', name='signal_dependent_co\n",
       ">                                        ndition_linear', codes={'code': [1, 2,\n",
       ">                                        3]}, encode_ch=3)\n",
       "\n",
       "Signal-dependent conditional linear transformation layer for flows.\n",
       "\n",
       "This module applies a linear transformation to the input tensor, where the transformation parameters\n",
       "(log scale and bias) are conditioned on ISO levels and smartphone codes provided as input features.\n",
       "The conditioning is performed using embeddings generated from meta encoders and scale-and-bias modules.\n",
       "\n",
       "Attributes:\n",
       "    name (str): Name of the module.\n",
       "    device (str): Device to run computations on.\n",
       "    in_ch (int): Number of input channels.\n",
       "    setup_codes (tensor): Predefined ISO levels used for conditioning.\n",
       "    exp_times (tensor): Predefined smartphone codes used for conditioning.\n",
       "    encode_ch (int): Number of channels in the embeddings generated by the meta encoder.\n",
       "    meta_encoder (nn.Module): Meta encoder module to generate embeddings from ISO and camera inputs.\n",
       "    scale_and_bias (nn.Module): Module to compute scale and bias parameters based on embeddings and input features.\n",
       "\n",
       "Methods:\n",
       "    _get_embeddings(x, **kwargs):\n",
       "        Generates embeddings from ISO-level and smartphone-code inputs and concatenates them with additional features.\n",
       "\n",
       "    _inverse(z, **kwargs):\n",
       "        Applies the inverse transformation to the input tensor z.\n",
       "\n",
       "    _forward_and_log_det_jacobian(x, **kwargs):\n",
       "        Applies the forward transformation to the input tensor x and computes the log determinant of the Jacobian."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(SignalDependentConditionalLinear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from Noise2Model.networks import ResidualNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "x = torch.randn(batch_size, channels, height, width).to(device)\n",
    "\n",
    "kwargs = {\n",
    "        'exposure-time': torch.tensor([50], dtype=torch.float32).to(device),\n",
    "        'optical-setup': torch.tensor([0], dtype=torch.float32).to(device),\n",
    "        'clean': x,\n",
    "    }\n",
    "codes = {\n",
    "        'exposure-time': torch.tensor([10, 50, 100], dtype=torch.float32, device=device),\n",
    "        'optical-setup': torch.tensor([0, 1], dtype=torch.float32).to(device),\n",
    "        # 'camera': torch.tensor([0, 1], dtype=torch.float32).to(device)\n",
    "    }\n",
    "\n",
    "layer = SignalDependentConditionalLinear(lambda feats_in, feats_out: ResidualNet(in_features=feats_in,\n",
    "                        out_features=feats_out,\n",
    "                        hidden_features=1,\n",
    "                        num_blocks=3,\n",
    "                        use_batch_norm=True,\n",
    "                        dropout_probability=0.0).to(device), lambda feats_in, feats_out: PointwiseConvs(in_features=feats_in,\n",
    "                        out_features=feats_out, device=device,\n",
    "                        feats=1), device=device, in_ch=x.shape[1], codes=codes)\n",
    "\n",
    "z, log_abs_det_J_inv = layer._forward_and_log_det_jacobian(x, **kwargs)\n",
    "\n",
    "assert z.device == x.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure-Aware Conditional Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/layers.py#L705){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### StructureAwareConditionalLinearLayer\n",
       "\n",
       ">      StructureAwareConditionalLinearLayer (meta_encoder, structure_encoder,\n",
       ">                                            in_ch=1, device='cpu', name='struct\n",
       ">                                            ure_aware_condition_linear',\n",
       ">                                            codes={'code': [1, 2, 3]})\n",
       "\n",
       "Structure-aware conditional linear transformation layer for flows.\n",
       "\n",
       "This module applies a linear transformation to the input tensor, where the transformation parameters\n",
       "(log scale and bias) are conditioned on ISO levels and smartphone codes provided as input features.\n",
       "The conditioning involves both meta encoding and structure encoding of input features.\n",
       "\n",
       "Attributes:\n",
       "    in_ch (int): Number of input channels.\n",
       "    iso_vals (tensor): Predefined ISO levels used for conditioning.\n",
       "    cam_vals (tensor): Predefined smartphone codes used for conditioning.\n",
       "    meta_encoder (nn.Module): Meta encoder module to generate embeddings from ISO and camera inputs.\n",
       "    structure_encoder (nn.Module): Structure encoder module to generate embeddings from input features.\n",
       "\n",
       "Methods:\n",
       "    _get_embeddings(x, **kwargs):\n",
       "        Generates embeddings from ISO-level and smartphone-code inputs and combines them using structure encoding.\n",
       "\n",
       "    _inverse(z, **kwargs):\n",
       "        Applies the inverse transformation to the input tensor z.\n",
       "\n",
       "    _forward_and_log_det_jacobian(x, **kwargs):\n",
       "        Applies the forward transformation to the input tensor x and computes the log determinant of the Jacobian."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/layers.py#L705){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### StructureAwareConditionalLinearLayer\n",
       "\n",
       ">      StructureAwareConditionalLinearLayer (meta_encoder, structure_encoder,\n",
       ">                                            in_ch=1, device='cpu', name='struct\n",
       ">                                            ure_aware_condition_linear',\n",
       ">                                            codes={'code': [1, 2, 3]})\n",
       "\n",
       "Structure-aware conditional linear transformation layer for flows.\n",
       "\n",
       "This module applies a linear transformation to the input tensor, where the transformation parameters\n",
       "(log scale and bias) are conditioned on ISO levels and smartphone codes provided as input features.\n",
       "The conditioning involves both meta encoding and structure encoding of input features.\n",
       "\n",
       "Attributes:\n",
       "    in_ch (int): Number of input channels.\n",
       "    iso_vals (tensor): Predefined ISO levels used for conditioning.\n",
       "    cam_vals (tensor): Predefined smartphone codes used for conditioning.\n",
       "    meta_encoder (nn.Module): Meta encoder module to generate embeddings from ISO and camera inputs.\n",
       "    structure_encoder (nn.Module): Structure encoder module to generate embeddings from input features.\n",
       "\n",
       "Methods:\n",
       "    _get_embeddings(x, **kwargs):\n",
       "        Generates embeddings from ISO-level and smartphone-code inputs and combines them using structure encoding.\n",
       "\n",
       "    _inverse(z, **kwargs):\n",
       "        Applies the inverse transformation to the input tensor z.\n",
       "\n",
       "    _forward_and_log_det_jacobian(x, **kwargs):\n",
       "        Applies the forward transformation to the input tensor x and computes the log determinant of the Jacobian."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(StructureAwareConditionalLinearLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from Noise2Model.networks import ResidualNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "x = torch.randn(batch_size, channels, height, width).to(device)\n",
    "\n",
    "kwargs = {\n",
    "        'exposure-time': torch.tensor([50], dtype=torch.float32).to(device),\n",
    "        'optical-setup': torch.tensor([0], dtype=torch.float32).to(device),\n",
    "        'clean': x,\n",
    "    }\n",
    "codes = {\n",
    "        'exposure-time': torch.tensor([10, 50, 100], dtype=torch.float32, device=device),\n",
    "        'optical-setup': torch.tensor([0, 1], dtype=torch.float32).to(device),\n",
    "        # 'camera': torch.tensor([0, 1], dtype=torch.float32).to(device)\n",
    "    }\n",
    "\n",
    "layer = StructureAwareConditionalLinearLayer(lambda feats_in, feats_out: ResidualNet(in_features=feats_in,\n",
    "                        out_features=feats_out,\n",
    "                        hidden_features=1,\n",
    "                        num_blocks=3,\n",
    "                        use_batch_norm=True,\n",
    "                        dropout_probability=0.0).to(device), lambda feats_in, feats_out: SpatialConvs(in_features=feats_in,\n",
    "                        out_features=feats_out, device=device,\n",
    "                        feats=1), device=device, in_ch=x.shape[1], codes=codes)\n",
    "\n",
    "z, log_abs_det_J_inv = layer._forward_and_log_det_jacobian(x, **kwargs)\n",
    "\n",
    "assert z.device == x.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/layers.py#L820){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### NoiseExtraction\n",
       "\n",
       ">      NoiseExtraction (device='cpu', name='noise_extraction')\n",
       "\n",
       "Module for noise extraction in neural networks.\n",
       "\n",
       "This module extracts noise by adding or subtracting the clean signal from the input.\n",
       "\n",
       "Attributes:\n",
       "    name (str): Name of the module.\n",
       "    device (str): Device to run computations on.\n",
       "\n",
       "Methods:\n",
       "    _inverse(z, **kwargs):\n",
       "        Computes the inverse operation by adding the clean signal to z.\n",
       "\n",
       "    _forward_and_log_det_jacobian(x, **kwargs):\n",
       "        Computes forward operation by subtracting the clean signal from x and returns a zero log determinant Jacobian."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/layers.py#L820){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### NoiseExtraction\n",
       "\n",
       ">      NoiseExtraction (device='cpu', name='noise_extraction')\n",
       "\n",
       "Module for noise extraction in neural networks.\n",
       "\n",
       "This module extracts noise by adding or subtracting the clean signal from the input.\n",
       "\n",
       "Attributes:\n",
       "    name (str): Name of the module.\n",
       "    device (str): Device to run computations on.\n",
       "\n",
       "Methods:\n",
       "    _inverse(z, **kwargs):\n",
       "        Computes the inverse operation by adding the clean signal to z.\n",
       "\n",
       "    _forward_and_log_det_jacobian(x, **kwargs):\n",
       "        Computes forward operation by subtracting the clean signal from x and returns a zero log determinant Jacobian."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(NoiseExtraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[[[0.9044, 0.5942],\n",
      "          [0.6439, 0.8483]]],\n",
      "\n",
      "\n",
      "        [[[0.7072, 0.7334],\n",
      "          [0.7445, 0.8308]]]], device='cuda:0')\n",
      "clean: tensor([[[[0.3914, 0.9923],\n",
      "          [0.3723, 0.7225]]],\n",
      "\n",
      "\n",
      "        [[[0.9459, 0.6627],\n",
      "          [0.8506, 0.3440]]]], device='cuda:0')\n",
      "\n",
      "\n",
      " z: tensor([[[[ 0.5130, -0.3981],\n",
      "          [ 0.2717,  0.1258]]],\n",
      "\n",
      "\n",
      "        [[[-0.2387,  0.0707],\n",
      "          [-0.1061,  0.4868]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "x = torch.rand(batch_size, channels, height, width).to(device)\n",
    "print('x:', x)\n",
    "\n",
    "kwargs = {\n",
    "        'exposure-time': torch.tensor([50], dtype=torch.float32).to(device),\n",
    "        'optical-setup': torch.tensor([0], dtype=torch.float32).to(device),\n",
    "        'clean': torch.rand(batch_size, channels, height, width).to(device),\n",
    "    }\n",
    "\n",
    "print('clean:', kwargs['clean'])\n",
    "\n",
    "layer = NoiseExtraction(device=device)\n",
    "\n",
    "z, _ = layer._forward_and_log_det_jacobian(x, **kwargs)\n",
    "print('\\n\\n z:', z)\n",
    "\n",
    "assert z.device == x.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise Flow Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# channels = 1\n",
    "# hidden_channels = 16\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# x = torch_randn(1, channels, 16, 16).to(device)\n",
    "# print(x.device)\n",
    "\n",
    "# # tst =  AffineSdn(x.shape[1:]).to(device)\n",
    "# tst = Unconditional(channels=x.shape[1],hidden_channels = 16,split_mode='channel' if x.shape[1] != 1 else 'checkerboard').to(device)\n",
    "# # tst = Gain(x.shape[1:]).to(device)  \n",
    "# print(tst)\n",
    "# kwargs = {}; kwargs['clean'] = x\n",
    "# y, _ = tst(x,**kwargs)\n",
    "# test_eq(y.shape, x.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
