{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\n",
    "\n",
    "> Utility functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from math import log10, exp\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch \n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchmetrics.functional.image import structural_similarity_index_measure as structural_similarity\n",
    "from torchmetrics.functional.image import peak_signal_noise_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def attributesFromDict(d):\n",
    "    self = d.pop('self')\n",
    "    for n, v in d.items():\n",
    "        setattr(self, n, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute attribute index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class compute_index():\n",
    "    def __init__(self, codes, device='cpu') -> None:\n",
    "        attributesFromDict(locals( ))\n",
    "      \n",
    "    def _compute_index(self, b, **kwargs):\n",
    "        idx = torch.zeros([b], device=self.device, dtype=torch.float32)\n",
    "        for key, value in self.codes.items():\n",
    "            idx = idx * len(value)\n",
    "            for i, v in enumerate(value):\n",
    "                idx += torch.where(kwargs[key] == v, i, 0.0)\n",
    "\n",
    "        return idx\n",
    "    \n",
    "    def __call__(self, b, **kwargs):\n",
    "        return self._compute_index(b, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:  tensor([10.])\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "codes = {\n",
    "        'exposure-time': torch.tensor([10, 50, 100], dtype=torch.float32, device=device),\n",
    "        'optical-setup': torch.tensor([0, 1], dtype=torch.float32).to(device),\n",
    "        'camera': torch.tensor([0, 1], dtype=torch.float32).to(device)\n",
    "    }\n",
    "kwargs = {\n",
    "        'exposure-time': torch.tensor([100], dtype=torch.float32).to(device),\n",
    "        'optical-setup': torch.tensor([1], dtype=torch.float32).to(device),\n",
    "        'camera': torch.tensor([0], dtype=torch.float32).to(device)\n",
    "    }\n",
    "\n",
    "fn = compute_index(codes)\n",
    "\n",
    "print('index: ', fn(1, **kwargs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class compute_one_hot():\n",
    "    def __init__(self, codes, device='cpu') -> None:\n",
    "        attributesFromDict(locals( ))\n",
    "      \n",
    "    def _compute_one_hot(self, b, **kwargs):\n",
    "        embedding = torch.tensor([])\n",
    "        for key, value in self.codes.items():\n",
    "            idx = torch.zeros([b], device=self.device, dtype=torch.float32)\n",
    "            for i, v in enumerate(value):\n",
    "                idx += torch.where(kwargs[key] == v, i, 0.0)\n",
    "            idx_one_hot = F.one_hot(idx.to(torch.int64), num_classes=value.shape[0]).to(torch.float32)\n",
    "            print(key, ': ', idx_one_hot)\n",
    "            embedding = torch.cat((embedding, idx_one_hot), dim=1)\n",
    "\n",
    "        return embedding\n",
    "    \n",
    "    def __call__(self, b, **kwargs):\n",
    "        return self._compute_one_hot(b, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exposure-time :  tensor([[0., 0., 1.]])\n",
      "optical-setup :  tensor([[0., 1.]])\n",
      "camera :  tensor([[1., 0.]])\n",
      "one hot encoding:  tensor([[0., 0., 1., 0., 1., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "fn1hot = compute_one_hot(codes)\n",
    "\n",
    "print('one hot encoding: ', fn1hot(1, **kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class StandardNormal(nn.Module):\n",
    "    \"\"\"A multivariate Normal with zero mean and unit covariance.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(StandardNormal, self).__init__()\n",
    "        self.register_buffer('buffer', torch.zeros(1))\n",
    "\n",
    "    def log_prob(self, x):\n",
    "        # https://www.statlect.com/fundamentals-of-statistics/normal-distribution-maximum-likelihood\n",
    "        log_base =  - 0.5 * math.log(2 * math.pi)\n",
    "        log_inner = - 0.5 * x**2\n",
    "        return sum_except_batch(log_base+log_inner)\n",
    "\n",
    "    def sample(self, shape):\n",
    "        return torch.randn(*shape, device=self.buffer.device, dtype=self.buffer.dtype)\n",
    "\n",
    "def sum_except_batch(x, num_dims=1):\n",
    "    '''\n",
    "    Sums all dimensions except the first.\n",
    "    Args:\n",
    "        x: Tensor, shape (batch_size, ...)\n",
    "        num_dims: int, number of batch dims (default=1)\n",
    "    Returns:\n",
    "        x_sum: Tensor, shape (batch_size,)\n",
    "    '''\n",
    "    return x.reshape(*x.shape[:num_dims], -1).sum(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def np2tensor(n:np.array):\n",
    "    '''\n",
    "    transform numpy array (image) to torch Tensor\n",
    "    BGR -> RGB\n",
    "    (h,w,c) -> (c,h,w)\n",
    "    '''\n",
    "    # gray\n",
    "    if len(n.shape) == 2:\n",
    "        n = np.expand_dims(n, axis=2)\n",
    "        return torch.from_numpy(np.ascontiguousarray(np.transpose(n, (2,0,1))))\n",
    "    # RGB -> BGR\n",
    "    elif len(n.shape) == 3:\n",
    "        return torch.from_numpy(np.ascontiguousarray(np.transpose(np.flip(n, axis=2), (2,0,1))))\n",
    "    else:\n",
    "        raise RuntimeError('wrong numpy dimensions : %s'%(n.shape,))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(4, 4)\n",
    "assert np2tensor(a).type() == 'torch.DoubleTensor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(0, high=255, size=(4,4))\n",
    "assert np2tensor(a).type() == 'torch.LongTensor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def np2tensor_multi(n:np.array):\n",
    "    t = None\n",
    "    if len(n) <= 1: # single stacked image\n",
    "        t = np2tensor(n[0].astype(np.float32)).unsqueeze(0).float()\n",
    "    else: # multi stacked image\n",
    "        for mat in n:\n",
    "            if t is None: t = np2tensor(mat.astype(np.float32)).unsqueeze(0).float()\n",
    "            else: t = torch.cat([t, np2tensor(mat.astype(np.float32)).unsqueeze(0).float()], dim=0)\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def tensor2np(t:torch.Tensor):\n",
    "    '''\n",
    "    transform torch Tensor to numpy having opencv image form.\n",
    "    RGB -> BGR\n",
    "    (c,h,w) -> (h,w,c)\n",
    "    '''\n",
    "    t = t.cpu().detach()\n",
    "\n",
    "    # gray\n",
    "    if len(t.shape) == 2:\n",
    "        return t.permute(1,2,0).numpy()\n",
    "    # RGB -> BGR\n",
    "    elif len(t.shape) == 3:\n",
    "        return np.flip(t.permute(1,2,0).numpy(), axis=2)\n",
    "    # image batch\n",
    "    elif len(t.shape) == 4:\n",
    "        return np.flip(t.permute(0,2,3,1).numpy(), axis=3)\n",
    "    else:\n",
    "        raise RuntimeError('wrong tensor dimensions : %s'%(t.shape,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def imwrite_tensor(t, name='test.png'):\n",
    "    cv2.imwrite('./%s'%name, tensor2np(t.cpu()))\n",
    "\n",
    "def imread_tensor(name='test'):\n",
    "    return np2tensor(cv2.imread('./%s'%name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def rot_hflip_img(img:torch.Tensor, rot_times:int=0, hflip:int=0):\n",
    "    '''\n",
    "    rotate '90 x times degree' & horizontal flip image \n",
    "    (shape of img: b,c,h,w or c,h,w)\n",
    "    '''\n",
    "    b=0 if len(img.shape)==3 else 1\n",
    "    # no flip\n",
    "    if hflip % 2 == 0:\n",
    "        # 0 degrees\n",
    "        if rot_times % 4 == 0:    \n",
    "            return img\n",
    "        # 90 degrees\n",
    "        elif rot_times % 4 == 1:  \n",
    "            return img.flip(b+1).transpose(b+1,b+2)\n",
    "        # 180 degrees\n",
    "        elif rot_times % 4 == 2:  \n",
    "            return img.flip(b+2).flip(b+1)\n",
    "        # 270 degrees\n",
    "        else:               \n",
    "            return img.flip(b+2).transpose(b+1,b+2)\n",
    "    # horizontal flip\n",
    "    else:\n",
    "        # 0 degrees\n",
    "        if rot_times % 4 == 0:    \n",
    "            return img.flip(b+2)\n",
    "        # 90 degrees\n",
    "        elif rot_times % 4 == 1:  \n",
    "            return img.flip(b+1).flip(b+2).transpose(b+1,b+2)\n",
    "        # 180 degrees\n",
    "        elif rot_times % 4 == 2:  \n",
    "            return img.flip(b+1)\n",
    "        # 270 degrees\n",
    "        else:               \n",
    "            return img.transpose(b+1,b+2)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "     \n",
    "def psnr(x, y, mask=None, max_val=1.):\n",
    "    if max_val is None : max_val = 1.\n",
    "    if mask is None:\n",
    "        mse = torch.mean((x - y) ** 2)\n",
    "    else:\n",
    "        mse = torch.sum(((x - y) ** 2) * mask) / mask.sum() \n",
    "    return 10 * log10(max_val**2 / mse.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def ssim(img1, img2, data_range):\n",
    "    '''\n",
    "    image value range : [0 - data_range]\n",
    "    clipping for model output\n",
    "    '''\n",
    "    if len(img1.shape) == 4:\n",
    "        img1 = img1[0]\n",
    "    if len(img2.shape) == 4:\n",
    "        img2 = img2[0]\n",
    "\n",
    "    # tensor to numpy\n",
    "    if isinstance(img1, torch.Tensor):\n",
    "        img1 = tensor2np(img1)\n",
    "    if isinstance(img2, torch.Tensor):\n",
    "        img2 = tensor2np(img2)\n",
    "\n",
    "    # numpy value cliping\n",
    "    img2 = np.clip(img2, 0, data_range)\n",
    "    img1 = np.clip(img1, 0, data_range)\n",
    "\n",
    "    # https://forum.image.sc/t/how-to-calculate-ssim-of-muti-channel-images-since-the-function-structural-similarity-deprecate-the-parameter-multichannel/79693\n",
    "    return structural_similarity(img1, img2, channel_axis=-1, data_range=data_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"\n",
    "    Computes and stores the average and current value.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def setup_determinism(seed):\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_gaussian_2d_filter(window_size, sigma, channel=1, device=torch.device('cpu')):\n",
    "    '''\n",
    "    return 2d gaussian filter window as tensor form\n",
    "    Arg:\n",
    "        window_size : filter window size\n",
    "        sigma : standard deviation\n",
    "    '''\n",
    "    gauss = torch.ones(window_size, device=device)\n",
    "    for x in range(window_size): gauss[x] = exp(-(x - window_size//2)**2/float(2*sigma**2))\n",
    "    gauss = gauss.unsqueeze(1)\n",
    "    #gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)], device=device).unsqueeze(1)\n",
    "    filter2d = gauss.mm(gauss.t()).float()\n",
    "    filter2d = (filter2d/filter2d.sum()).unsqueeze(0).unsqueeze(0)\n",
    "    return filter2d.expand(channel, 1, window_size, window_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_mean_2d_filter(window_size, channel=1, device=torch.device('cpu')):\n",
    "    '''\n",
    "    return 2d mean filter as tensor form\n",
    "    Args:\n",
    "        window_size : filter window size\n",
    "    '''\n",
    "    window = torch.ones((window_size, window_size), device=device)\n",
    "    window = (window/window.sum()).unsqueeze(0).unsqueeze(0)\n",
    "    return window.expand(channel, 1, window_size, window_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def mean_conv2d(x, window_size=None, window=None, filter_type='gau', sigma=None, keep_sigma=False, padd=True):\n",
    "    '''\n",
    "    color channel-wise 2d mean or gaussian convolution\n",
    "    Args:\n",
    "        x : input image\n",
    "        window_size : filter window size\n",
    "        filter_type(opt) : 'gau' or 'mean'\n",
    "        sigma : standard deviation of gaussian filter\n",
    "    '''\n",
    "    b_x = x.unsqueeze(0) if len(x.shape) == 3 else x\n",
    "\n",
    "    if window is None:\n",
    "        if sigma is None: sigma = (window_size-1)/6\n",
    "        if filter_type == 'gau':\n",
    "            window = get_gaussian_2d_filter(window_size, sigma=sigma, channel=b_x.shape[1], device=x.device)\n",
    "        else:\n",
    "            window = get_mean_2d_filter(window_size, channel=b_x.shape[1], device=x.device)\n",
    "    else:\n",
    "        window_size = window.shape[-1]\n",
    "\n",
    "    if padd:\n",
    "        pl = (window_size-1)//2\n",
    "        b_x = F.pad(b_x, (pl,pl,pl,pl), 'reflect')\n",
    "\n",
    "    m_b_x = F.conv2d(b_x, window, groups=b_x.shape[1])\n",
    "\n",
    "    if keep_sigma:\n",
    "        m_b_x /= (window**2).sum().sqrt()\n",
    "\n",
    "    if len(x.shape) == 4:\n",
    "        return m_b_x\n",
    "    elif len(x.shape) == 3:\n",
    "        return m_b_x.squeeze(0)\n",
    "    else:\n",
    "        raise ValueError('input image shape is not correct')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_file_name_from_path(path):\n",
    "    if '/' in path : name = path.split('/')[-1].split('.')[:-1]\n",
    "    elif '\\\\' in path: name = path.split('\\\\')[-1].split('.')[:-1]\n",
    "    else: assert False, f'Invalid path: {path}'\n",
    "\n",
    "    if isinstance(name, list):\n",
    "        merged = \"\"\n",
    "        for token in name[:-1]: \n",
    "            merged += token + '.'\n",
    "        merged += name[-1]\n",
    "        name = merged\n",
    "    return name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_histogram(data, bin_edges=None, cnt_regr=1):\n",
    "    n = np.prod(data.shape)\t\n",
    "    hist, _ = np.histogram(data, bin_edges)\t\n",
    "    return (hist + cnt_regr)/(n + cnt_regr * len(hist))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def kl_div_forward(p, q):\n",
    "    assert (~(np.isnan(p) | np.isinf(p) | np.isnan(q) | np.isinf(q))).all()\t\n",
    "    idx = (p > 0)\n",
    "    p = p[idx]\n",
    "    q = q[idx]\n",
    "    return np.sum(p * np.log(p / q))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def kl_div_3_data(real_noise, gen_noise, bin_edges=None, left_edge=0.0, right_edge=1.0):\n",
    "    # Kousha, Shayan, et al. \"Modeling srgb camera noise with normalizing flows.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022.\n",
    "    # ref) https://github.com/SamsungLabs/Noise2NoiseFlow\n",
    "    noise_pats = (gen_noise, real_noise)\t\n",
    "\n",
    "    # histograms\n",
    "    bw = 4\n",
    "    bin_edges = np.arange(left_edge, right_edge, bw)\n",
    "\n",
    "    cnt_regr = 1\n",
    "    hists = [None] * len(noise_pats)\t\n",
    "    klds = np.ndarray([len(noise_pats)])\t\n",
    "    klds[:] = 0.0\n",
    "\n",
    "    for h in reversed(range(len(noise_pats))):\n",
    "        hists[h] = get_histogram(noise_pats[h], bin_edges=bin_edges, cnt_regr=cnt_regr)\n",
    "        klds[h] = kl_div_forward(hists[-1], hists[h])\t\n",
    "\n",
    "    return klds[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def load_numpy_from_raw(path, dtype='float32'):\n",
    "    fid = open(path, \"rb\")\n",
    "    return np.fromfile(fid, dtype=dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def make_predefiend_1d_to_2d(arr):\n",
    "    predefined_sizes = [(3072,2560), (3072,3072), (9216,3072), (6144,3072)] # H, W\n",
    "    assert len(arr.shape) == 1\n",
    "    for predefined_size in predefined_sizes:\n",
    "        if arr.shape[0] == (predefined_size[0] * predefined_size[1]):\n",
    "            arr = np.reshape(arr, predefined_size)\n",
    "    assert len(arr.shape) == 2, \"Error: No matching predefined size exists.\"\n",
    "    return arr \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def save_img(dir_name, file_name, img):\n",
    "    path = os.path.join(dir_name, file_name)\n",
    "    if 'raw' in path[-3:]:\n",
    "        os.makedirs(dir_name, exist_ok=True)\n",
    "        with open(path, 'w') as fid:\n",
    "            img.tofile(fid)\n",
    "    else:\n",
    "        if len(img.shape) == 3 and img.shape[-1] != 3 and img.shape[-1] > 1:\n",
    "            cv2.imwritemulti(path, img.transpose([2,0,1])) # multi stack image, convert to CHW\n",
    "        elif len(img.shape) == 4 and img.shape[0] > 1: # batch image, only grey image is available\n",
    "            img = img.squeeze(-1)\n",
    "            cv2.imwritemulti(path, img) \n",
    "        elif len(img.shape) == 4 and img.shape[0] <= 1: # single batch image\n",
    "            img = img.squeeze(0)\n",
    "            cv2.imwrite(path, img)\n",
    "        else:\n",
    "            cv2.imwrite(path, img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class FileManager:\n",
    "    def __init__(self, session_name, output_path=None):\n",
    "        if output_path is None:\n",
    "            self.output_folder = \"./output\"\n",
    "        else:\n",
    "            self.output_folder = output_path\n",
    "            \n",
    "        if not os.path.isdir(self.output_folder):\n",
    "            os.makedirs(self.output_folder)\n",
    "            print(\"[WARNING] output folder is not exist, create new one\")\n",
    "\n",
    "        # init session\n",
    "        self.session_name = session_name\n",
    "        os.makedirs(os.path.join(self.output_folder, self.session_name), exist_ok=True)\n",
    "\n",
    "        # mkdir\n",
    "        for directory in ['checkpoint', 'img']:\n",
    "            self.make_dir(directory)\n",
    "\n",
    "    def is_dir_exist(self, dir_name:str) -> bool:\n",
    "        return os.path.isdir(os.path.join(self.output_folder, self.session_name, dir_name))\n",
    "\n",
    "    def make_dir(self, dir_name:str) -> str:\n",
    "        os.makedirs(os.path.join(self.output_folder, self.session_name, dir_name), exist_ok=True) \n",
    "\n",
    "    def get_dir(self, dir_name:str) -> str:\n",
    "        # -> './output/<session_name>/dir_name'\n",
    "        return os.path.join(self.output_folder, self.session_name, dir_name)\n",
    "\n",
    "    def save_img_tensor(self, dir_name:str, file_name:str, img:torch.Tensor, ext='png'):\n",
    "        self.save_img_numpy(dir_name, file_name, tensor2np(img), ext)\n",
    "\n",
    "    def save_img_numpy(self, dir_name:str, file_name:str, img:np.array, ext='png'):\n",
    "        if np.shape(img)[2] == 1:\n",
    "            save_img(self.get_dir(dir_name), '%s.%s'%(file_name, ext), np.squeeze(img, 2))\n",
    "        else:\n",
    "            save_img(self.get_dir(dir_name), '%s.%s'%(file_name, ext), img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
