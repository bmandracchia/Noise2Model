{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers\n",
    "\n",
    "> normalizing flow layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #| export\n",
    "\n",
    "import os\n",
    "from importlib import import_module\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from Noise2Model.utils import store_attr, ComputeIndex, ComputeOneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #| export\n",
    " \n",
    "flow_layer_class_dict = {}\n",
    "\n",
    "def regist_layer(layer_class):\n",
    "    layer_name = layer_class.__name__.lower()\n",
    "    assert not layer_name in flow_layer_class_dict, 'there is already registered layer: %s in flow_layer_class_dict.' % layer_name\n",
    "    flow_layer_class_dict[layer_name] = layer_class\n",
    "    return layer_class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #| export\n",
    " \n",
    "def get_flow_layer(layer_name:str):\n",
    "    layer_name = layer_name.lower()\n",
    "    return flow_layer_class_dict[layer_name]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pointwise Convs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@regist_layer\n",
    "class PointwiseConvs(nn.Module):\n",
    "    \"\"\"\n",
    "    Pointwise convolutional module for neural networks.\n",
    "\n",
    "    This module consists of a series of pointwise convolutions with instance normalization\n",
    "    and LeakyReLU activation functions.\n",
    "\n",
    "    Attributes:\n",
    "        name (str): Name of the module.\n",
    "        device (str): Device to run computations on.\n",
    "        body (nn.Sequential): Sequential module containing the layers.\n",
    "\n",
    "    Methods:\n",
    "        _get_basic_module(in_ch, out_ch, k_size=1, stride=1, padding=1, negative_slope=0.2):\n",
    "            Returns a basic convolutional module with instance normalization and LeakyReLU activation.\n",
    "\n",
    "        forward(x):\n",
    "            Performs forward pass through the module.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features=1, out_features=1, feats=32, device='cpu', name='pointwise_convs'):\n",
    "        \"\"\"\n",
    "        Initializes the PointwiseConvs module with specified parameters.\n",
    "\n",
    "        Args:\n",
    "            in_features (int): Number of input features/channels. Default is 3.\n",
    "            out_features (int): Number of output features/channels. Default is 3.\n",
    "            feats (int): Number of features in intermediate layers. Default is 32.\n",
    "            device (str): Device to run computations on (default: 'cpu').\n",
    "            name (str): Name of the module (default: 'pointwise_convs').\n",
    "        \"\"\"\n",
    "        super(PointwiseConvs, self).__init__()\n",
    "        self.name = name\n",
    "        self.device = device \n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(in_features, feats, kernel_size=1, stride=1, padding=0),\n",
    "            self._get_basic_module(feats, feats*2, k_size=1, stride=1, padding=0),\n",
    "            self._get_basic_module(feats*2, feats*2, k_size=1, stride=1, padding=0),\n",
    "            self._get_basic_module(feats*2, feats, k_size=1, stride=1, padding=0),\n",
    "            nn.Conv2d(feats, out_features, kernel_size=1, stride=1, padding=0),\n",
    "            nn.Tanh()\n",
    "        ).to(device)\n",
    "\n",
    "    def _get_basic_module(self, in_ch, out_ch, k_size=1, stride=1, padding=1, negative_slope=0.2):\n",
    "        \"\"\"\n",
    "        Returns a basic convolutional module with instance normalization and LeakyReLU activation.\n",
    "\n",
    "        Args:\n",
    "            in_ch (int): Number of input channels.\n",
    "            out_ch (int): Number of output channels.\n",
    "            k_size (int): Kernel size of the convolution. Default is 1.\n",
    "            stride (int): Stride of the convolution. Default is 1.\n",
    "            padding (int): Padding of the convolution. Default is 1.\n",
    "            negative_slope (float): Slope of the LeakyReLU activation function. Default is 0.2.\n",
    "\n",
    "        Returns:\n",
    "            nn.Sequential: Sequential module containing Conv2d, InstanceNorm2d, and LeakyReLU layers.\n",
    "        \"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=k_size, stride=stride, padding=padding),\n",
    "            nn.InstanceNorm2d(out_ch, affine=True),  # Instance normalization\n",
    "            nn.LeakyReLU(negative_slope, inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Performs forward pass through the PointwiseConvs module.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, in_features, height, width).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor after passing through the module.\n",
    "        \"\"\"\n",
    "        return self.body(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "channels = 1\n",
    "height = 2\n",
    "width = 2\n",
    "device = 'cuda'\n",
    "\n",
    "x = torch.randn(batch_size, channels, height, width).to(device)\n",
    "y = PointwiseConvs(in_features=channels, out_features=channels, feats=32, device=device)(x)\n",
    "\n",
    "assert y.size() == x.size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial Convs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@regist_layer\n",
    "class SpatialConvs(nn.Module):\n",
    "    \"\"\"\n",
    "    Spatial convolutional module for neural networks.\n",
    "\n",
    "    This module consists of a series of spatial convolutions with ReLU activation functions.\n",
    "\n",
    "    Attributes:\n",
    "        name (str): Name of the module.\n",
    "        device (str): Device to run computations on.\n",
    "        receptive_field (int): Size of the receptive field for spatial convolutions.\n",
    "        body (nn.Sequential): Sequential module containing the layers.\n",
    "\n",
    "    Methods:\n",
    "        _get_basic_module(in_ch, out_ch, k_size=1, stride=1, padding=1, negative_slope=0.2):\n",
    "            Returns a basic convolutional module with instance normalization and LeakyReLU activation.\n",
    "\n",
    "        forward(x):\n",
    "            Performs forward pass through the module.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features=1, out_features=1, feats=32, receptive_field=9, device='cpu', name='spatial_convs'):\n",
    "        \"\"\"\n",
    "        Initializes the SpatialConvs module with specified parameters.\n",
    "\n",
    "        Args:\n",
    "            in_features (int): Number of input features/channels. Default is 3.\n",
    "            out_features (int): Number of output features/channels. Default is 3.\n",
    "            feats (int): Number of features in intermediate layers. Default is 32.\n",
    "            receptive_field (int): Size of the receptive field for spatial convolutions. Default is 9.\n",
    "            device (str): Device to run computations on (default: 'cpu').\n",
    "            name (str): Name of the module (default: 'spatial_convs').\n",
    "        \"\"\"\n",
    "        super(SpatialConvs, self).__init__()\n",
    "        self.name = name\n",
    "        self.device = device \n",
    "        self.receptive_field = receptive_field\n",
    "\n",
    "        self.body = nn.Sequential()\n",
    "        self.body.add_module('conv_in', nn.Conv2d(in_features, feats, kernel_size=1, stride=1, padding=0))\n",
    "        self.body.add_module('relu_in', nn.ReLU(inplace=True))\n",
    "\n",
    "        # Add spatial convolutions with ReLU activations\n",
    "        for _ in range(self.receptive_field // 2):\n",
    "            self.body.add_module('conv', nn.Conv2d(feats, feats, kernel_size=3, stride=1, padding=1))\n",
    "            self.body.add_module('relu', nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.body.add_module('conv_out', nn.Conv2d(feats, out_features, kernel_size=1, stride=1, padding=0))\n",
    "        self.body.add_module('tanh_out', nn.Tanh())\n",
    "        self.body.to(device)\n",
    "\n",
    "    def _get_basic_module(self, in_ch, out_ch, k_size=1, stride=1, padding=1, negative_slope=0.2):\n",
    "        \"\"\"\n",
    "        Returns a basic convolutional module with instance normalization and LeakyReLU activation.\n",
    "\n",
    "        Args:\n",
    "            in_ch (int): Number of input channels.\n",
    "            out_ch (int): Number of output channels.\n",
    "            k_size (int): Kernel size of the convolution. Default is 1.\n",
    "            stride (int): Stride of the convolution. Default is 1.\n",
    "            padding (int): Padding of the convolution. Default is 1.\n",
    "            negative_slope (float): Slope of the LeakyReLU activation function. Default is 0.2.\n",
    "\n",
    "        Returns:\n",
    "            nn.Sequential: Sequential module containing Conv2d, InstanceNorm2d, and LeakyReLU layers.\n",
    "        \"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=k_size, stride=stride, padding=padding),\n",
    "            nn.InstanceNorm2d(out_ch, affine=True),  # Instance normalization\n",
    "            nn.LeakyReLU(negative_slope, inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Performs forward pass through the SpatialConvs module.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, in_features, height, width).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor after passing through the module.\n",
    "        \"\"\"\n",
    "        return self.body(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "channels = 1\n",
    "height = 2\n",
    "width = 2\n",
    "device = 'cuda'\n",
    "\n",
    "x = torch.randn(batch_size, channels, height, width).to(device)\n",
    "y = SpatialConvs(in_features=channels, out_features=channels, feats=32, device=device)(x)\n",
    "\n",
    "assert y.size() == x.size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Flows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dequantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uniform Dequantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@regist_layer\n",
    "class UniformDequantization(nn.Module):\n",
    "    def __init__(self, alpha=1e-5, num_bits=8, device='cpu', name='uniform_dequantization'):\n",
    "        \"\"\"\n",
    "        Uniform dequantization layer for flows.\n",
    "        \n",
    "        Args:\n",
    "            alpha (float): Small constant used to scale the input to avoid boundary values (default: 1e-5).\n",
    "            num_bits (int): Number of bits used for quantization (default: 8).\n",
    "            device (str): Device to run computations on (default: 'cpu').\n",
    "            name (str): Name of the module (default: 'uniform_dequantization').\n",
    "        \"\"\"\n",
    "        super(UniformDequantization, self).__init__()\n",
    "        store_attr() # stores all the input parameters in self\n",
    "        \n",
    "        self.quantization_bins = 2 ** num_bits\n",
    "        # Precompute the log-determinant of the Jacobian per dimension\n",
    "        self.register_buffer(\n",
    "            'ldj_per_dim',\n",
    "            - num_bits * torch.log(torch.tensor(2.0, device=device, dtype=torch.float))\n",
    "        )\n",
    "        \n",
    "    def _ldj(self, shape):\n",
    "        \"\"\"\n",
    "        Computes the log-determinant of the Jacobian for a given shape.\n",
    "\n",
    "        Args:\n",
    "            shape (torch.Size): Shape of the input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Log-determinant of the Jacobian repeated for the batch size.\n",
    "        \"\"\"\n",
    "        batch_size = shape[0]\n",
    "        num_dims = shape[1:].numel()\n",
    "        ldj = self.ldj_per_dim * num_dims\n",
    "        return ldj.repeat(batch_size)\n",
    "\n",
    "    def _inverse(self, z, **kwargs):\n",
    "        \"\"\"\n",
    "        Applies the inverse dequantization transformation to the input.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): Input tensor to transform.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Dequantized tensor.\n",
    "        \"\"\"\n",
    "        # Apply the inverse sigmoid transformation to z\n",
    "        # z = self._sigmoid_inverse(z)\n",
    "        # Quantize the values to integer bins\n",
    "        z = (self.quantization_bins * z).floor().clamp(min=0, max=self.quantization_bins - 1)\n",
    "        return z\n",
    "\n",
    "    def _forward_and_log_det_jacobian(self, x, **kwargs):\n",
    "        \"\"\"\n",
    "        Applies the forward dequantization transformation and computes the log-determinant of the Jacobian.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor to transform.\n",
    "\n",
    "        Returns:\n",
    "            tuple: Transformed tensor and the log-determinant of the Jacobian.\n",
    "        \"\"\"\n",
    "        z, ldj = self._dequant(x.to(torch.float32))\n",
    "        # Uncomment the next line if an additional sigmoid transformation is needed\n",
    "        # z, ldj = self._sigmoid(z, ldj)\n",
    "        return z, ldj\n",
    "    \n",
    "    def _sigmoid(self, z, ldj):\n",
    "        \"\"\"\n",
    "        Applies an invertible sigmoid transformation to the input.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): Input tensor to transform.\n",
    "            ldj (torch.Tensor): Log-determinant of the Jacobian.\n",
    "\n",
    "        Returns:\n",
    "            tuple: Transformed tensor and updated log-determinant of the Jacobian.\n",
    "        \"\"\"\n",
    "        # Update ldj with the sigmoid transformation's contribution\n",
    "        # Support both 2D (batch, features) and 4D (batch, channels, height, width) tensors\n",
    "        if z.dim() == 4:\n",
    "            ldj += (-z - 2 * F.softplus(-z)).sum(dim=[1, 2, 3])\n",
    "        elif z.dim() == 2:\n",
    "            ldj += (-z - 2 * F.softplus(-z)).sum(dim=1)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported tensor shape for z: {z.shape}\")\n",
    "        z = torch.sigmoid(z)\n",
    "        # Adjust the log-determinant for the alpha scaling\n",
    "        ldj -= torch.log(torch.tensor(1.0 - self.alpha, device=z.device, dtype=z.dtype)) * z.flatten(1).shape[1]\n",
    "        # Scale z to avoid boundaries\n",
    "        z = (z - 0.5 * self.alpha) / (1 - self.alpha)\n",
    "        return z, ldj\n",
    "    \n",
    "    def _sigmoid_inverse(self, z):\n",
    "        \"\"\"\n",
    "        Applies the inverse of the sigmoid transformation to the input.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): Input tensor to transform.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Transformed tensor.\n",
    "        \"\"\"\n",
    "        # Scale z to avoid boundaries 0 and 1\n",
    "        z = z * (1 - self.alpha) + 0.5 * self.alpha\n",
    "        # Apply the logit function (inverse sigmoid)\n",
    "        z = torch.log(z) - torch.log(1 - z)\n",
    "        return z\n",
    "    \n",
    "    def _dequant(self, x):\n",
    "        \"\"\"\n",
    "        Transforms discrete values to continuous volumes for dequantization.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor with discrete values.\n",
    "\n",
    "        Returns:\n",
    "            tuple: Dequantized tensor and the log-determinant of the Jacobian.\n",
    "        \"\"\"\n",
    "        # Add uniform noise to dequantize\n",
    "        u = torch.rand(x.shape, device=x.device, dtype=x.dtype)\n",
    "        z = (x + u) / self.quantization_bins\n",
    "        # Compute the log-determinant of the Jacobian\n",
    "        ldj = self._ldj(z.shape)\n",
    "        return z, ldj\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[104, 161,  55, 237],\n",
      "        [118, 240, 207, 226],\n",
      "        [176, 207, 213, 247],\n",
      "        [241,  86, 108, 181]])\n",
      "tensor([[0.4095, 0.6310, 0.2175, 0.9286],\n",
      "        [0.4627, 0.9413, 0.8123, 0.8858],\n",
      "        [0.6902, 0.8096, 0.8325, 0.9685],\n",
      "        [0.9422, 0.3367, 0.4233, 0.7083]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randint(256,[4, 4])\n",
    "b, _ = UniformDequantization()._forward_and_log_det_jacobian(a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[104., 161.,  55., 237.],\n",
      "        [118., 240., 207., 226.],\n",
      "        [176., 207., 213., 247.],\n",
      "        [241.,  86., 108., 181.]])\n"
     ]
    }
   ],
   "source": [
    "c = UniformDequantization()._inverse(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variational Dequantization (TO DO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# class VariationalDequantization(UniformDequantization):\n",
    "\n",
    "#     def __init__(self, var_flows, alpha=1e-5, num_bits=8, device='cpu', name='variational_dequantization'):\n",
    "#         \"\"\"\n",
    "#         Variational dequantization layer inheriting from UniformDequantization.\n",
    "        \n",
    "#         Inputs:\n",
    "#             var_flows - A list of flow transformations to use for modeling q(u|x).\n",
    "#             alpha - Small constant used to scale the input to avoid very small and large values.\n",
    "#             num_bits - Number of bits used for quantization.\n",
    "#             device - Device to run computations on (default: 'cpu').\n",
    "#             name - Name of the module (default: 'variational_dequantization').\n",
    "#         \"\"\"\n",
    "#         super().__init__(alpha=alpha, num_bits=num_bits, device=device, name=name)\n",
    "#         self.flows = nn.ModuleList(var_flows)\n",
    "        \n",
    "#     def _dequant(self, x):\n",
    "#         # Transform discrete values to continuous volumes\n",
    "#         u = torch.rand(x.shape, device=x.device, dtype=x.dtype)\n",
    "#         img = (x / (self.quantization_bins - 1)) * 2 - 1 # We condition the flows on x, i.e. the original image\n",
    "        \n",
    "#         u = self._sigmoid_inverse(u)\n",
    "#         for flow in self.flows:\n",
    "#             u, ldj = flow(u, ldj, orig_img=img)\n",
    "#         u, ldj = self._sigmoid(u, ldj)\n",
    "        \n",
    "#         z = (x + u) / self.quantization_bins\n",
    "#         ldj = self._ldj(z.shape)\n",
    "#         return z, ldj\n",
    "\n",
    "#     # def dequant(self, z, ldj):\n",
    "#     #     z = z.to(torch.float32)\n",
    "#     #     img = (z / 255.0) * 2 - 1 # We condition the flows on x, i.e. the original image\n",
    "\n",
    "#     #     # Prior of u is a uniform distribution as before\n",
    "#     #     # As most flow transformations are defined on [-infinity,+infinity], we apply an inverse sigmoid first.\n",
    "#     #     deq_noise = torch.rand_like(z).detach()\n",
    "#     #     deq_noise, ldj = self.sigmoid(deq_noise, ldj, reverse=True)\n",
    "#     #     for flow in self.flows:\n",
    "#     #         deq_noise, ldj = flow(deq_noise, ldj, reverse=False, orig_img=img)\n",
    "#     #     deq_noise, ldj = self.sigmoid(deq_noise, ldj, reverse=False)\n",
    "\n",
    "#     #     # After the flows, apply u as in standard dequantization\n",
    "#     #     z = (z + deq_noise) / 256.0\n",
    "#     #     ldj -= np.log(256.0) * np.prod(z.shape[1:])\n",
    "#     #     return z, ldj\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@regist_layer\n",
    "class ConditionalLinear(nn.Module):\n",
    "    \"\"\"\n",
    "    Conditional linear transformation module.\n",
    "\n",
    "    Applies different scales and biases based on average pixel size and camera values provided\n",
    "    in the input. Supports both forward and inverse transformations.\n",
    "\n",
    "    Attributes:\n",
    "        name (str): Name of the transformation.\n",
    "        setup_code (torch.Tensor): Predefined set of pixel sizes.\n",
    "        exp_times (torch.Tensor): Predefined set of camera values.\n",
    "        log_scale (torch.nn.Parameter): Learnable log-scale parameters.\n",
    "        bias (torch.nn.Parameter): Learnable bias parameters.\n",
    "\n",
    "    Methods:\n",
    "        _inverse(z, **kwargs):\n",
    "            Performs the inverse transformation based on the input 'z' and conditionals.\n",
    "\n",
    "        _forward_and_log_det_jacobian(x, **kwargs):\n",
    "            Performs the forward transformation and computes the log determinant of the Jacobian.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device='cpu', name='linear_transformation', codes={'code': [1, 2, 3]}):\n",
    "        \"\"\"\n",
    "        Initializes the ConditionalLinear module.\n",
    "\n",
    "        Args:\n",
    "            device (str): Device to run computations on (default: 'cpu').\n",
    "            name (str): Name of the module (default: 'linear_transformation').\n",
    "        \"\"\"\n",
    "        super(ConditionalLinear, self).__init__()\n",
    "        store_attr() # stores all the input parameters in self\n",
    "\n",
    "        # Learnable parameters\n",
    "        self.par_num = 1\n",
    "        for k,v in codes.items():\n",
    "            self.par_num *= len(v)\n",
    "\n",
    "        self.log_scale = nn.Parameter(torch.zeros(self.par_num, device=device), requires_grad=True)\n",
    "        self.bias = nn.Parameter(torch.zeros(self.par_num, device=device), requires_grad=True)\n",
    "        \n",
    "        self._computeIndex = ComputeIndex(codes)\n",
    "        \n",
    "    def _inverse(self, z, **kwargs):\n",
    "        \"\"\"\n",
    "        Performs the inverse transformation based on the input 'z' and conditionals.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): Input tensor of shape (batch_size, channels, height, width).\n",
    "            **kwargs: Additional keyword arguments containing 'pixel' and 'cam' tensors.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor after applying the inverse transformation.\n",
    "        \"\"\"\n",
    "        batch_size = z.shape[0]\n",
    "        idx = self._computeIndex(batch_size,**kwargs)\n",
    "        idx = torch.arange(0, self.par_num).to(self.device) == idx.unsqueeze(1)\n",
    "\n",
    "        # Select corresponding log_scale and bias values based on idx indices\n",
    "        log_scale = self.log_scale.unsqueeze(0).repeat_interleave(z.shape[0], dim=0)[idx]\n",
    "        bias = self.bias.unsqueeze(0).repeat_interleave(z.shape[0], dim=0)[idx]\n",
    "\n",
    "        # Compute the inverse transformation\n",
    "        x = (z - bias.reshape((-1, 1, 1, 1))) / torch.exp(log_scale.reshape((-1, 1, 1, 1)))\n",
    "        return x\n",
    "\n",
    "    def _forward_and_log_det_jacobian(self, x, **kwargs):\n",
    "        \"\"\"\n",
    "        Performs the forward transformation and computes the log determinant of the Jacobian.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, channels, height, width).\n",
    "            **kwargs: Additional keyword arguments containing 'pixel' and 'cam' tensors.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor after applying the forward transformation.\n",
    "            torch.Tensor: Log determinant of the Jacobian.\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        idx = self._computeIndex(batch_size,**kwargs)\n",
    "        idx = torch.arange(0, self.par_num).to(self.device) == idx.unsqueeze(1)\n",
    "\n",
    "        # Select corresponding log_scale and bias values based on idx indices\n",
    "        log_scale = self.log_scale.unsqueeze(0).repeat_interleave(x.shape[0], dim=0)[idx]\n",
    "        bias = self.bias.unsqueeze(0).repeat_interleave(x.shape[0], dim=0)[idx]\n",
    "\n",
    "        # Compute the forward transformation\n",
    "        z = x * torch.exp(log_scale.reshape((-1, 1, 1, 1))) + bias.reshape((-1, 1, 1, 1))\n",
    "\n",
    "        # Compute the log determinant of the Jacobian\n",
    "        log_abs_det_J_inv = log_scale * np.prod(x.shape[1:])\n",
    "\n",
    "        return z, log_abs_det_J_inv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "channels = 1\n",
    "height = 2\n",
    "width = 2\n",
    "device = 'cuda'\n",
    "\n",
    "codes = {\n",
    "        'exposure-time': torch.tensor([10, 50, 100], dtype=torch.float32, device=device),\n",
    "        'optical-setup': torch.tensor([0, 1], dtype=torch.float32).to(device),\n",
    "        # 'camera': torch.tensor([0, 1], dtype=torch.float32).to(device)\n",
    "    }\n",
    "\n",
    "x = torch.randn(batch_size, channels, height, width).to(device)\n",
    "setup_idx = torch.tensor([1] * batch_size, dtype=torch.float32).to(device)\n",
    "time_idx = torch.tensor([10] * batch_size, dtype=torch.float32).to(device)\n",
    "\n",
    "kwargs = {'optical-setup': setup_idx, 'exposure-time': time_idx}\n",
    "\n",
    "print(ComputeIndex(codes)(batch_size, **kwargs))\n",
    "\n",
    "# Forward transformation\n",
    "z, log_det_jacobian = ConditionalLinear(device=device, codes=codes)._forward_and_log_det_jacobian(x, **kwargs)\n",
    "assert z.shape == x.shape\n",
    "assert log_det_jacobian.shape == torch.Size([batch_size])\n",
    "\n",
    "# Inverse transformation\n",
    "x_reconstructed = ConditionalLinear(device=device, codes=codes)._inverse(z, **kwargs)\n",
    "assert x_reconstructed.shape == x.shape\n",
    "\n",
    "# Check if the reconstructed input is close to the original input\n",
    "assert torch.allclose(x, x_reconstructed, atol=1e-5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Linear $e^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@regist_layer\n",
    "class ConditionalLinearExp2(nn.Module):\n",
    "    \"\"\"\n",
    "    Conditional linear transformation layer for flows, conditioned on specific ISO levels and setup codes.\n",
    "    \n",
    "    This module applies a linear transformation to the input tensor, where the transformation parameters\n",
    "    (log scale and bias) are conditioned based on the pixel size and setup code provided as input. \n",
    "    The module supports both forward and inverse transformations.\n",
    "\n",
    "    Attributes:\n",
    "        name (str): Name of the module.\n",
    "        device (str): Device to run computations on.\n",
    "        pixel_size (tensor): pixel size used for conditioning.\n",
    "        cam_vals (tensor): Predefined setup codes used for conditioning.\n",
    "        log_scale (nn.Parameter): Learnable log scale parameters for the transformation.\n",
    "        bias (nn.Parameter): Learnable bias parameters for the transformation.\n",
    "\n",
    "    Methods:\n",
    "        _inverse(z, **kwargs):\n",
    "            Applies the inverse transformation to the input tensor z.\n",
    "        \n",
    "        _forward_and_log_det_jacobian(x, **kwargs):\n",
    "            Applies the forward transformation to the input tensor x and computes the log determinant\n",
    "            of the Jacobian of the transformation.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch=1, device='cpu', name='linear_transformation_exp2', codes={'code': [1, 2, 3]}):\n",
    "        \"\"\"\n",
    "        Initializes the ConditionalLinearExp2 module with specified input channels, device, and name.\n",
    "\n",
    "        Args:\n",
    "            in_ch (int): Number of input channels. Default is 1.\n",
    "            device (str): Device to run computations on (default: 'cpu').\n",
    "            name (str): Name of the module (default: 'linear_transformation_exp2').\n",
    "        \"\"\"\n",
    "        super(ConditionalLinearExp2, self).__init__()\n",
    "        store_attr() # stores all the input parameters in self\n",
    "\n",
    "        # Learnable parameters\n",
    "        self.par_num = 1\n",
    "        for k,v in codes.items():\n",
    "            self.par_num *= len(v)\n",
    "\n",
    "        self.log_scale = nn.Parameter(torch.zeros(self.par_num, in_ch, device=device), requires_grad=True)\n",
    "        self.bias = nn.Parameter(torch.zeros(self.par_num, in_ch, device=device), requires_grad=True)\n",
    "        \n",
    "        self._computeIndex = ComputeIndex(codes)\n",
    "        \n",
    "    def _inverse(self, z, **kwargs):\n",
    "        \"\"\"\n",
    "        Applies the inverse transformation to the input tensor z.\n",
    "        \n",
    "        Args:\n",
    "            z (tensor): Input tensor to be inversely transformed.\n",
    "            kwargs: Additional keyword arguments containing 'ISO-level' and 'setup-code' for conditioning.\n",
    "        \n",
    "        Returns:\n",
    "            tensor: The inversely transformed tensor.\n",
    "        \"\"\"\n",
    "        batch_size = z.shape[0]\n",
    "        \n",
    "        # Combine pixel and camera indices to get a unique index for each combination\n",
    "        idx = self._computeIndex(batch_size,**kwargs)\n",
    "        idx = torch.arange(0, self.par_num).to(self.device) == idx.unsqueeze(1)\n",
    "\n",
    "        # Select log scale and bias parameters based on the unique index\n",
    "        log_scale = self.log_scale.unsqueeze(0).repeat_interleave(z.shape[0], dim=0)[idx]\n",
    "        bias = self.bias.unsqueeze(0).repeat_interleave(z.shape[0], dim=0)[idx]\n",
    "\n",
    "        # Apply the inverse transformation\n",
    "        x = (z - bias.reshape((-1, z.shape[1], 1, 1))) / torch.exp(log_scale.reshape((-1, z.shape[1], 1, 1)))\n",
    "        return x\n",
    "\n",
    "    def _forward_and_log_det_jacobian(self, x, **kwargs):\n",
    "        \"\"\"\n",
    "        Applies the forward transformation to the input tensor x and computes the log determinant of the Jacobian.\n",
    "        \n",
    "        Args:\n",
    "            x (tensor): Input tensor to be transformed.\n",
    "            kwargs: Additional keyword arguments containing 'ISO-level' and 'setup-code' for conditioning.\n",
    "        \n",
    "        Returns:\n",
    "            tensor: The transformed tensor.\n",
    "            tensor: The log determinant of the Jacobian of the transformation.\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        # Combine pixel and camera indices to get a unique index for each combination\n",
    "        idx = self._computeIndex(batch_size,**kwargs)\n",
    "        idx = torch.arange(0, self.par_num).to(self.device) == idx.unsqueeze(1)\n",
    "\n",
    "        # Select log scale and bias parameters based on the unique index\n",
    "        log_scale = self.log_scale.unsqueeze(0).repeat_interleave(x.shape[0], dim=0)[idx]\n",
    "        bias = self.bias.unsqueeze(0).repeat_interleave(x.shape[0], dim=0)[idx]\n",
    "\n",
    "        # Apply the forward transformation\n",
    "        z = x * torch.exp(log_scale.reshape((-1, x.shape[1], 1, 1))) + bias.reshape((-1, x.shape[1], 1, 1))\n",
    "        log_abs_det_J_inv = torch.sum(log_scale * np.prod(x.shape[2:]), dim=1)\n",
    "\n",
    "        return z, log_abs_det_J_inv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "channels = 1\n",
    "height = 2\n",
    "width = 2\n",
    "device = 'cuda'\n",
    "\n",
    "codes = {\n",
    "        'exposure-time': torch.tensor([10, 50, 100], dtype=torch.float32, device=device),\n",
    "        'optical-setup': torch.tensor([0, 1], dtype=torch.float32).to(device),\n",
    "        # 'camera': torch.tensor([0, 1], dtype=torch.float32).to(device)\n",
    "    }\n",
    "\n",
    "x = torch.randn(batch_size, channels, height, width).to(device)\n",
    "\n",
    "kwargs = {\n",
    "        'exposure-time': torch.tensor([50], dtype=torch.float32).to(device),\n",
    "        'optical-setup': torch.tensor([0], dtype=torch.float32).to(device)\n",
    "    }\n",
    "\n",
    " # Forward transformation\n",
    "z, log_det_jacobian = ConditionalLinearExp2(device=device, in_ch=x.shape[1], codes=codes)._forward_and_log_det_jacobian(x, **kwargs)\n",
    "assert z.shape == x.shape\n",
    "assert log_det_jacobian.shape == torch.Size([batch_size])\n",
    "\n",
    "# Inverse transformation\n",
    "x_reconstructed = ConditionalLinearExp2(device=device, in_ch=x.shape[1], codes=codes)._inverse(z, **kwargs)\n",
    "assert x_reconstructed.shape == x.shape\n",
    "\n",
    "# Check if the reconstructed input is close to the original input\n",
    "assert torch.allclose(x, x_reconstructed, atol=1e-5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal Dependent Conditional Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@regist_layer\n",
    "class SignalDependentConditionalLinear(nn.Module):\n",
    "    \"\"\"\n",
    "    Signal-dependent conditional linear transformation layer for flows.\n",
    "    \n",
    "    This module applies a linear transformation to the input tensor, where the transformation parameters\n",
    "    (log scale and bias) are conditioned on ISO levels and smartphone codes provided as input features.\n",
    "    The conditioning is performed using embeddings generated from meta encoders and scale-and-bias modules.\n",
    "\n",
    "    Attributes:\n",
    "        name (str): Name of the module.\n",
    "        device (str): Device to run computations on.\n",
    "        in_ch (int): Number of input channels.\n",
    "        setup_codes (tensor): Predefined ISO levels used for conditioning.\n",
    "        exp_times (tensor): Predefined smartphone codes used for conditioning.\n",
    "        encode_ch (int): Number of channels in the embeddings generated by the meta encoder.\n",
    "        meta_encoder (nn.Module): Meta encoder module to generate embeddings from ISO and camera inputs.\n",
    "        scale_and_bias (nn.Module): Module to compute scale and bias parameters based on embeddings and input features.\n",
    "\n",
    "    Methods:\n",
    "        _get_embeddings(x, **kwargs):\n",
    "            Generates embeddings from ISO-level and smartphone-code inputs and concatenates them with additional features.\n",
    "\n",
    "        _inverse(z, **kwargs):\n",
    "            Applies the inverse transformation to the input tensor z.\n",
    "\n",
    "        _forward_and_log_det_jacobian(x, **kwargs):\n",
    "            Applies the forward transformation to the input tensor x and computes the log determinant of the Jacobian.\n",
    "    \"\"\"\n",
    "    def __init__(self, meta_encoder, scale_and_bias, in_ch=1, device='cpu', name='signal_dependent_condition_linear', codes={'code': [1, 2, 3]}, encode_ch = 3):\n",
    "        \"\"\"\n",
    "        Initializes the SignalDependentConditionalLinear module with specified meta encoder, scale-and-bias module,\n",
    "        input channels, device, and name.\n",
    "\n",
    "        Args:\n",
    "            meta_encoder (nn.Module): Meta encoder module to generate embeddings from ISO and camera inputs.\n",
    "            scale_and_bias (nn.Module): Module to compute scale and bias parameters based on embeddings and input features.\n",
    "            in_ch (int): Number of input channels. Default is 1.\n",
    "            device (str): Device to run computations on (default: 'cpu').\n",
    "            name (str): Name of the module (default: 'signal_dependent_condition_linear').\n",
    "        \"\"\"\n",
    "        super(SignalDependentConditionalLinear, self).__init__()\n",
    "        self.name = name\n",
    "        self.device = device \n",
    "        self.codes = codes\n",
    "        self.in_ch = in_ch\n",
    "        self.encode_ch = encode_ch\n",
    "        self._computeOneHot = ComputeOneHot(codes)\n",
    "        \n",
    "        n = 0\n",
    "        for k,v in codes.items():\n",
    "            n += len(v)\n",
    "        self.meta_encoder = meta_encoder(n, self.encode_ch)\n",
    "        self.scale_and_bias = scale_and_bias(self.encode_ch+in_ch, in_ch*2) # scale, bias per channels\n",
    "        \n",
    "    def _get_embeddings(self, x, **kwargs):\n",
    "        \"\"\"\n",
    "        Generates embeddings from ISO-level and smartphone-code inputs and concatenates them with additional features.\n",
    "\n",
    "        Args:\n",
    "            x (tensor): Input tensor.\n",
    "            kwargs: Additional keyword arguments containing 'ISO-level', 'smartphone-code', and 'clean'.\n",
    "\n",
    "        Returns:\n",
    "            tensor: Embeddings concatenated with additional features.\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        # Generate embeddings using the meta encoder\n",
    "        oneh = self._computeOneHot(batch_size, **kwargs)\n",
    "        embedding = self.meta_encoder(oneh)\n",
    "        embedding = embedding.reshape((-1, self.encode_ch, 1, 1))\n",
    "        embedding = torch.repeat_interleave(embedding, x.shape[-2], dim=-2)\n",
    "        embedding = torch.repeat_interleave(embedding, x.shape[-1], dim=-1)\n",
    "\n",
    "        # Concatenate embeddings with additional features\n",
    "        embedding = torch.cat((embedding, kwargs['clean']), dim=1)\n",
    "\n",
    "        # Compute scale and bias parameters\n",
    "        embedding = self.scale_and_bias(embedding)\n",
    "        return embedding\n",
    "    \n",
    "    def _inverse(self, z, **kwargs):\n",
    "        \"\"\"\n",
    "        Applies the inverse transformation to the input tensor z.\n",
    "\n",
    "        Args:\n",
    "            z (tensor): Input tensor to be inversely transformed.\n",
    "            kwargs: Additional keyword arguments containing 'ISO-level', 'smartphone-code', and 'clean'.\n",
    "\n",
    "        Returns:\n",
    "            tensor: The inversely transformed tensor.\n",
    "        \"\"\"\n",
    "        embedding = self._get_embeddings(z, **kwargs)\n",
    "\n",
    "        log_scale = embedding[:, :self.in_ch, ...]\n",
    "        bias = embedding[:, self.in_ch:, ...]\n",
    "\n",
    "        z = (z - bias) / torch.exp(log_scale)\n",
    "        return z\n",
    "\n",
    "    def _forward_and_log_det_jacobian(self, x, **kwargs):\n",
    "        \"\"\"\n",
    "        Applies the forward transformation to the input tensor x and computes the log determinant of the Jacobian.\n",
    "\n",
    "        Args:\n",
    "            x (tensor): Input tensor to be transformed.\n",
    "            kwargs: Additional keyword arguments containing 'ISO-level', 'smartphone-code', and 'clean'.\n",
    "\n",
    "        Returns:\n",
    "            tensor: The transformed tensor.\n",
    "            tensor: The log determinant of the Jacobian of the transformation.\n",
    "        \"\"\"\n",
    "        embedding = self._get_embeddings(x, **kwargs)\n",
    "\n",
    "        log_scale = embedding[:, :self.in_ch, ...]\n",
    "        bias = embedding[:, self.in_ch:, ...]\n",
    "        \n",
    "        z = torch.exp(log_scale) * x + bias\n",
    "        log_abs_det_J_inv = torch.sum(log_scale, dim=[1, 2, 3])\n",
    "        return z, log_abs_det_J_inv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Noise2Model.networks import ResidualNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "x = torch.randn(batch_size, channels, height, width).to(device)\n",
    "\n",
    "kwargs = {\n",
    "        'exposure-time': torch.tensor([50], dtype=torch.float32).to(device),\n",
    "        'optical-setup': torch.tensor([0], dtype=torch.float32).to(device),\n",
    "        'clean': x,\n",
    "    }\n",
    "codes = {\n",
    "        'exposure-time': torch.tensor([10, 50, 100], dtype=torch.float32, device=device),\n",
    "        'optical-setup': torch.tensor([0, 1], dtype=torch.float32).to(device),\n",
    "        # 'camera': torch.tensor([0, 1], dtype=torch.float32).to(device)\n",
    "    }\n",
    "\n",
    "layer = SignalDependentConditionalLinear(lambda feats_in, feats_out: ResidualNet(in_features=feats_in,\n",
    "                        out_features=feats_out,\n",
    "                        hidden_features=1,\n",
    "                        num_blocks=3,\n",
    "                        use_batch_norm=True,\n",
    "                        dropout_probability=0.0).to(device), lambda feats_in, feats_out: PointwiseConvs(in_features=feats_in,\n",
    "                        out_features=feats_out, device=device,\n",
    "                        feats=1), device=device, in_ch=x.shape[1], codes=codes)\n",
    "\n",
    "z, log_abs_det_J_inv = layer._forward_and_log_det_jacobian(x, **kwargs)\n",
    "\n",
    "assert z.device == x.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure-Aware Conditional Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@regist_layer\n",
    "class StructureAwareConditionalLinearLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Structure-aware conditional linear transformation layer for flows.\n",
    "    \n",
    "    This module applies a linear transformation to the input tensor, where the transformation parameters\n",
    "    (log scale and bias) are conditioned on ISO levels and smartphone codes provided as input features.\n",
    "    The conditioning involves both meta encoding and structure encoding of input features.\n",
    "\n",
    "    Attributes:\n",
    "        in_ch (int): Number of input channels.\n",
    "        iso_vals (tensor): Predefined ISO levels used for conditioning.\n",
    "        cam_vals (tensor): Predefined smartphone codes used for conditioning.\n",
    "        meta_encoder (nn.Module): Meta encoder module to generate embeddings from ISO and camera inputs.\n",
    "        structure_encoder (nn.Module): Structure encoder module to generate embeddings from input features.\n",
    "\n",
    "    Methods:\n",
    "        _get_embeddings(x, **kwargs):\n",
    "            Generates embeddings from ISO-level and smartphone-code inputs and combines them using structure encoding.\n",
    "\n",
    "        _inverse(z, **kwargs):\n",
    "            Applies the inverse transformation to the input tensor z.\n",
    "\n",
    "        _forward_and_log_det_jacobian(x, **kwargs):\n",
    "            Applies the forward transformation to the input tensor x and computes the log determinant of the Jacobian.\n",
    "    \"\"\"\n",
    "    def __init__(self, meta_encoder, structure_encoder, in_ch=1, device='cpu', name='structure_aware_condition_linear', codes={'code': [1, 2, 3]}):\n",
    "        \"\"\"\n",
    "        Initializes the StructureAwareConditionalLinearLayer module with specified meta encoder, structure encoder,\n",
    "        input channels, device, and name.\n",
    "\n",
    "        Args:\n",
    "            meta_encoder (nn.Module): Meta encoder module to generate embeddings from ISO and camera inputs.\n",
    "            structure_encoder (nn.Module): Structure encoder module to generate embeddings from input features.\n",
    "            in_ch (int): Number of input channels. Default is 3.\n",
    "            device (str): Device to run computations on (default: 'cpu').\n",
    "            name (str): Name of the module (default: 'structure_aware_condition_linear').\n",
    "        \"\"\"\n",
    "        super(StructureAwareConditionalLinearLayer, self).__init__()\n",
    "        self.name = name\n",
    "        self.device = device \n",
    "        self.in_ch = in_ch\n",
    "        self.codes = codes\n",
    "        self._computeOneHot = ComputeOneHot(codes)\n",
    "\n",
    "        n = 0\n",
    "        for k,v in codes.items():\n",
    "            n += len(v)\n",
    "        self.meta_encoder = meta_encoder(n, in_ch * 2)\n",
    "        self.structure_encoder = structure_encoder(in_ch, in_ch * 2)\n",
    "\n",
    "    def _get_embeddings(self, x, **kwargs):\n",
    "        \"\"\"\n",
    "        Generates embeddings from ISO-level and smartphone-code inputs and combines them using structure encoding.\n",
    "\n",
    "        Args:\n",
    "            x (tensor): Input tensor.\n",
    "            kwargs: Additional keyword arguments containing 'ISO-level', 'smartphone-code', and 'clean'.\n",
    "\n",
    "        Returns:\n",
    "            tensor: Combined embeddings from meta and structure encodings.\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        # Generate embeddings using the meta encoder\n",
    "        meta_embedding = self.meta_encoder(self._computeOneHot(batch_size,**kwargs))\n",
    "        meta_embedding = meta_embedding.reshape((-1, self.in_ch * 2, 1, 1))\n",
    "\n",
    "        # Generate structure embeddings and combine with meta embeddings\n",
    "        structure_embedding = self.structure_encoder(kwargs['clean'])\n",
    "        embedding = structure_embedding * meta_embedding\n",
    "        return embedding\n",
    "    \n",
    "    def _inverse(self, z, **kwargs):\n",
    "        \"\"\"\n",
    "        Applies the inverse transformation to the input tensor z.\n",
    "\n",
    "        Args:\n",
    "            z (tensor): Input tensor to be inversely transformed.\n",
    "            kwargs: Additional keyword arguments containing 'ISO-level', 'smartphone-code', and 'clean'.\n",
    "\n",
    "        Returns:\n",
    "            tensor: The inversely transformed tensor.\n",
    "        \"\"\"\n",
    "        embedding = self._get_embeddings(z, **kwargs)\n",
    "\n",
    "        log_scale = embedding[:, :self.in_ch, ...]\n",
    "        bias = embedding[:, self.in_ch:, ...]\n",
    "        z = (z - bias) / torch.exp(log_scale)\n",
    "        return z\n",
    "\n",
    "    def _forward_and_log_det_jacobian(self, x, **kwargs):\n",
    "        \"\"\"\n",
    "        Applies the forward transformation to the input tensor x and computes the log determinant of the Jacobian.\n",
    "\n",
    "        Args:\n",
    "            x (tensor): Input tensor to be transformed.\n",
    "            kwargs: Additional keyword arguments containing 'ISO-level', 'smartphone-code', and 'clean'.\n",
    "\n",
    "        Returns:\n",
    "            tensor: The transformed tensor.\n",
    "            tensor: The log determinant of the Jacobian of the transformation.\n",
    "        \"\"\"\n",
    "        embedding = self._get_embeddings(x, **kwargs)\n",
    "\n",
    "        log_scale = embedding[:, :self.in_ch, ...]\n",
    "        bias = embedding[:, self.in_ch:, ...]\n",
    "        \n",
    "        z = torch.exp(log_scale) * x + bias\n",
    "        log_abs_det_J_inv = torch.sum(log_scale, dim=[1, 2, 3])\n",
    "        return z, log_abs_det_J_inv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Noise2Model.networks import ResidualNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "x = torch.randn(batch_size, channels, height, width).to(device)\n",
    "\n",
    "kwargs = {\n",
    "        'exposure-time': torch.tensor([50], dtype=torch.float32).to(device),\n",
    "        'optical-setup': torch.tensor([0], dtype=torch.float32).to(device),\n",
    "        'clean': x,\n",
    "    }\n",
    "codes = {\n",
    "        'exposure-time': torch.tensor([10, 50, 100], dtype=torch.float32, device=device),\n",
    "        'optical-setup': torch.tensor([0, 1], dtype=torch.float32).to(device),\n",
    "        # 'camera': torch.tensor([0, 1], dtype=torch.float32).to(device)\n",
    "    }\n",
    "\n",
    "layer = StructureAwareConditionalLinearLayer(lambda feats_in, feats_out: ResidualNet(in_features=feats_in,\n",
    "                        out_features=feats_out,\n",
    "                        hidden_features=1,\n",
    "                        num_blocks=3,\n",
    "                        use_batch_norm=True,\n",
    "                        dropout_probability=0.0).to(device), lambda feats_in, feats_out: SpatialConvs(in_features=feats_in,\n",
    "                        out_features=feats_out, device=device,\n",
    "                        feats=1), device=device, in_ch=x.shape[1], codes=codes)\n",
    "\n",
    "z, log_abs_det_J_inv = layer._forward_and_log_det_jacobian(x, **kwargs)\n",
    "\n",
    "assert z.device == x.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@regist_layer\n",
    "class NoiseExtraction(nn.Module):\n",
    "    \"\"\"\n",
    "    Module for noise extraction in neural networks.\n",
    "\n",
    "    This module extracts noise by adding or subtracting the clean signal from the input.\n",
    "\n",
    "    Attributes:\n",
    "        name (str): Name of the module.\n",
    "        device (str): Device to run computations on.\n",
    "\n",
    "    Methods:\n",
    "        _inverse(z, **kwargs):\n",
    "            Computes the inverse operation by adding the clean signal to z.\n",
    "\n",
    "        _forward_and_log_det_jacobian(x, **kwargs):\n",
    "            Computes forward operation by subtracting the clean signal from x and returns a zero log determinant Jacobian.\n",
    "    \"\"\"\n",
    "    def __init__(self, device='cpu', name='noise_extraction'):\n",
    "        \"\"\"\n",
    "        Initializes the NoiseExtraction module with specified parameters.\n",
    "\n",
    "        Args:\n",
    "            device (str): Device to run computations on (default: 'cpu').\n",
    "            name (str): Name of the module (default: 'noise_extraction').\n",
    "        \"\"\"\n",
    "        super(NoiseExtraction, self).__init__()\n",
    "        self.name = name\n",
    "        self.device = device \n",
    "\n",
    "    def _inverse(self, z, **kwargs):\n",
    "        \"\"\"\n",
    "        Computes the inverse operation by adding the clean signal to z.\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): Input tensor of shape (batch_size, ...).\n",
    "            **kwargs: Additional keyword arguments, expected 'clean' as a tensor of the same shape as z.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor after adding the clean signal to z.\n",
    "        \"\"\"\n",
    "        x = z + kwargs['clean']\n",
    "        return x\n",
    "\n",
    "    def _forward_and_log_det_jacobian(self, x, **kwargs):\n",
    "        \"\"\"\n",
    "        Computes forward operation by subtracting the clean signal from x and returns a zero log determinant Jacobian.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, ...).\n",
    "            **kwargs: Additional keyword arguments, expected 'clean' as a tensor of the same shape as x.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor after subtracting the clean signal from x.\n",
    "            torch.Tensor: Log determinant Jacobian (ldj), which is zero in this case.\n",
    "        \"\"\"\n",
    "        z = x - kwargs['clean']\n",
    "        ldj = torch.zeros(x.shape[0], device=self.device)\n",
    "        return z, ldj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[[[0.9044, 0.5942],\n",
      "          [0.6439, 0.8483]]],\n",
      "\n",
      "\n",
      "        [[[0.7072, 0.7334],\n",
      "          [0.7445, 0.8308]]]], device='cuda:0')\n",
      "clean: tensor([[[[0.3914, 0.9923],\n",
      "          [0.3723, 0.7225]]],\n",
      "\n",
      "\n",
      "        [[[0.9459, 0.6627],\n",
      "          [0.8506, 0.3440]]]], device='cuda:0')\n",
      "\n",
      "\n",
      " z: tensor([[[[ 0.5130, -0.3981],\n",
      "          [ 0.2717,  0.1258]]],\n",
      "\n",
      "\n",
      "        [[[-0.2387,  0.0707],\n",
      "          [-0.1061,  0.4868]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "x = torch.rand(batch_size, channels, height, width).to(device)\n",
    "print('x:', x)\n",
    "\n",
    "kwargs = {\n",
    "        'exposure-time': torch.tensor([50], dtype=torch.float32).to(device),\n",
    "        'optical-setup': torch.tensor([0], dtype=torch.float32).to(device),\n",
    "        'clean': torch.rand(batch_size, channels, height, width).to(device),\n",
    "    }\n",
    "\n",
    "print('clean:', kwargs['clean'])\n",
    "\n",
    "layer = NoiseExtraction(device=device)\n",
    "\n",
    "z, _ = layer._forward_and_log_det_jacobian(x, **kwargs)\n",
    "print('\\n\\n z:', z)\n",
    "\n",
    "assert z.device == x.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise Flow Layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# class Gain(Flow):\n",
    "#     \"\"\"\n",
    "#     Gain & Offset flow layer\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, shape):\n",
    "#         \"\"\"Constructor\n",
    "\n",
    "        \n",
    "#         \"\"\"\n",
    "#         super().__init__()\n",
    "#         self.shape = shape\n",
    "#         self.gain = AffineConstFlow(self.shape)\n",
    "\n",
    "#     def forward(self, z, **kwargs):\n",
    "#         return self.gain(z)\n",
    "\n",
    "#     def inverse(self, z, **kwargs):\n",
    "#         return self.gain.inverse(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channels = 1\n",
    "# hidden_channels = 16\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# x = torch_randn(1, channels, 16, 16).to(device)\n",
    "# print(x.device)\n",
    "\n",
    "# # tst =  AffineSdn(x.shape[1:]).to(device)\n",
    "# tst = Unconditional(channels=x.shape[1],hidden_channels = 16,split_mode='channel' if x.shape[1] != 1 else 'checkerboard').to(device)\n",
    "# # tst = Gain(x.shape[1:]).to(device)  \n",
    "# print(tst)\n",
    "# kwargs = {}; kwargs['clean'] = x\n",
    "# y, _ = tst(x,**kwargs)\n",
    "# test_eq(y.shape, x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
