{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: networks\n",
    "output-file: nets.html\n",
    "title: Networks\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "from torch import randn as torch_randn\n",
    "from fastai.vision.all import test_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/networks.py#L28){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### get_network_class\n",
       "\n",
       ">      get_network_class (model_name:str)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/networks.py#L28){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### get_network_class\n",
       "\n",
       ">      get_network_class (model_name:str)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(get_network_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/networks.py#L21){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### regist_network\n",
       "\n",
       ">      regist_network (model_class)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/networks.py#L21){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### regist_network\n",
       "\n",
       ">      regist_network (model_class)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(regist_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "x = torch_randn(16, 1, 32, 64, 64)\n",
    "xdim = len(x.shape)-2\n",
    "\n",
    "tst = ConvLayer(1, 1, ndim=xdim)\n",
    "test_eq(tst(x).shape, [16, 1, 32, 64, 64])\n",
    "tst = MaxPool(2, ndim=xdim)\n",
    "test_eq(tst(x).shape, [16, 1, 16, 32, 32])\n",
    "tst = Lambda(lambda x: x+np.float32(1e-3))\n",
    "test_eq(tst(x).shape, [16, 1, 32, 64, 64])\n",
    "test_eq(torch_cat((x, tst(x)), 1).shape, [16, 2, 32, 64, 64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DnCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/networks.py#L34){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DnCNN\n",
       "\n",
       ">      DnCNN (channels, num_of_layers=18, features=64)\n",
       "\n",
       "Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/networks.py#L34){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DnCNN\n",
       "\n",
       ">      DnCNN (channels, num_of_layers=18, features=64)\n",
       "\n",
       "Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(DnCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DnCNN(\n",
      "  (dncnn): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (10): ReLU(inplace=True)\n",
      "    (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (28): ReLU(inplace=True)\n",
      "    (29): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (30): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (31): ReLU(inplace=True)\n",
      "    (32): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (33): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (34): ReLU(inplace=True)\n",
      "    (35): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (36): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (37): ReLU(inplace=True)\n",
      "    (38): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (39): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (40): ReLU(inplace=True)\n",
      "    (41): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (42): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (43): ReLU(inplace=True)\n",
      "    (44): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (45): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (46): ReLU(inplace=True)\n",
      "    (47): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (48): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (49): ReLU(inplace=True)\n",
      "    (50): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "x = torch_randn(16, 1, 32, 64)\n",
    "\n",
    "tst = DnCNN(1)\n",
    "test_eq(tst(x).shape, [16, 1, 32, 64])\n",
    "print(tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/networks.py#L81){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SubNetConv\n",
       "\n",
       ">      SubNetConv (ks=3, stride=1, padding=None, bias=None, ndim=2,\n",
       ">                  norm_type=<NormType.Batch: 1>, bn_1st=True, act_cls=<class\n",
       ">                  'torch.nn.modules.activation.ReLU'>, transpose=False,\n",
       ">                  init='auto', xtra=None, bias_std=0.01, dropout=0.0)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/networks.py#L81){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SubNetConv\n",
       "\n",
       ">      SubNetConv (ks=3, stride=1, padding=None, bias=None, ndim=2,\n",
       ">                  norm_type=<NormType.Batch: 1>, bn_1st=True, act_cls=<class\n",
       ">                  'torch.nn.modules.activation.ReLU'>, transpose=False,\n",
       ">                  init='auto', xtra=None, bias_std=0.01, dropout=0.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(SubNetConv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): ConvLayer(\n",
      "      (0): Conv3d(1, 2, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (1): BatchNorm3d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): ConvLayer(\n",
      "      (0): Conv3d(2, 2, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (1): BatchNorm3d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "ConvLayer(\n",
      "  (0): ConvTranspose3d(2, 1, kernel_size=(4, 4, 4), stride=(4, 4, 4), bias=False)\n",
      "  (1): BatchNorm3d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "x = torch_randn(16, 1, 32, 64, 64)\n",
    "xdim = len(x.shape)-2\n",
    "\n",
    "# reduce\n",
    "tst = SubNetConv(3, padding=1, stride=2, ndim=xdim,\n",
    "                 norm_type=NormType.Batch, dropout=.1)(1, 2, 2)\n",
    "y = tst(x)\n",
    "test_eq(y.shape, [16, 2, 8, 16, 16])\n",
    "print(tst)\n",
    "# upsample\n",
    "tst = SubNetConv(ks=4, padding=0, stride=4, ndim=xdim, norm_type=NormType.Batch,\n",
    "                 transpose=True)(2, 1)  # to double the size, the kernel cannot be odd\n",
    "test_eq(tst(y).shape, [16, 1, 32, 64, 64])\n",
    "print(tst)\n",
    "del y\n",
    "# ConvLayer(2*n_out_channels, n_out_channels, ks=ks, transpose=True, padding=(ks-1)//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/networks.py#L174){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MyUNet\n",
       "\n",
       ">      MyUNet (depth=4, mult_chan=32, in_channels=1, out_channels=1,\n",
       ">              last_activation=None, kernel_size=3, ndim=2, n_conv_per_depth=2,\n",
       ">              activation='ReLU', norm_type=<NormType.Batch: 1>, dropout=0.0,\n",
       ">              pool=<function MaxPool>, pool_size=2, residual=False,\n",
       ">              prob_out=False, eps_scale=0.001)\n",
       "\n",
       "Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| depth | int | 4 | depth of the UNet network |\n",
       "| mult_chan | int | 32 | number of filters at first layer |\n",
       "| in_channels | int | 1 | number of input channels |\n",
       "| out_channels | int | 1 | number of output channels |\n",
       "| last_activation | NoneType | None | last activation before final result |\n",
       "| kernel_size | int | 3 | kernel size of convolutional layers |\n",
       "| ndim | int | 2 | number of spatial dimensions of the input data |\n",
       "| n_conv_per_depth | int | 2 | number of convolutions per layer |\n",
       "| activation | str | ReLU | activation function used in convolutional layers |\n",
       "| norm_type | NormType | NormType.Batch | normalization type for layers |\n",
       "| dropout | float | 0.0 | dropout rate |\n",
       "| pool | function | MaxPool | pooling layer type |\n",
       "| pool_size | int | 2 | pooling size |\n",
       "| residual | bool | False | use residual connection |\n",
       "| prob_out | bool | False | output probability scale |\n",
       "| eps_scale | float | 0.001 | epsilon for scale output |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/networks.py#L174){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MyUNet\n",
       "\n",
       ">      MyUNet (depth=4, mult_chan=32, in_channels=1, out_channels=1,\n",
       ">              last_activation=None, kernel_size=3, ndim=2, n_conv_per_depth=2,\n",
       ">              activation='ReLU', norm_type=<NormType.Batch: 1>, dropout=0.0,\n",
       ">              pool=<function MaxPool>, pool_size=2, residual=False,\n",
       ">              prob_out=False, eps_scale=0.001)\n",
       "\n",
       "Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| depth | int | 4 | depth of the UNet network |\n",
       "| mult_chan | int | 32 | number of filters at first layer |\n",
       "| in_channels | int | 1 | number of input channels |\n",
       "| out_channels | int | 1 | number of output channels |\n",
       "| last_activation | NoneType | None | last activation before final result |\n",
       "| kernel_size | int | 3 | kernel size of convolutional layers |\n",
       "| ndim | int | 2 | number of spatial dimensions of the input data |\n",
       "| n_conv_per_depth | int | 2 | number of convolutions per layer |\n",
       "| activation | str | ReLU | activation function used in convolutional layers |\n",
       "| norm_type | NormType | NormType.Batch | normalization type for layers |\n",
       "| dropout | float | 0.0 | dropout rate |\n",
       "| pool | function | MaxPool | pooling layer type |\n",
       "| pool_size | int | 2 | pooling size |\n",
       "| residual | bool | False | use residual connection |\n",
       "| prob_out | bool | False | output probability scale |\n",
       "| eps_scale | float | 0.001 | epsilon for scale output |"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(MyUNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# show_doc(UNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[_Net_recurse(\n",
      "  (sub_conv_more): ConvLayer(\n",
      "    (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (sub_u): Sequential(\n",
      "    (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (1): _Net_recurse(\n",
      "      (sub_conv_more): ConvLayer(\n",
      "        (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (2): Upsample(scale_factor=2.0, mode='nearest')\n",
      "  )\n",
      "  (sub_conv_less): ConvLayer(\n",
      "    (0): Conv3d(96, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "), ConvLayer(\n",
      "  (0): Conv3d(32, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "x = torch_randn(16, 1, 32, 64, 64)\n",
    "xdim = len(x.shape)-2\n",
    "\n",
    "tst = MyUNet(depth=1, ndim=xdim, n_conv_per_depth=1, residual=True)\n",
    "mods = list(tst.children())\n",
    "print(mods)\n",
    "test_eq(tst(x).shape, [16, 1, 32, 64, 64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/networks.py#L331){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### UNetUpBlock\n",
       "\n",
       ">      UNetUpBlock (in_size, out_size, up_mode, padding, batch_norm)\n",
       "\n",
       "Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/networks.py#L331){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### UNetUpBlock\n",
       "\n",
       ">      UNetUpBlock (in_size, out_size, up_mode, padding, batch_norm)\n",
       "\n",
       "Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(UNetUpBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/networks.py#L307){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### UNetConvBlock\n",
       "\n",
       ">      UNetConvBlock (in_size, out_size, padding, batch_norm, drop_p=0.15)\n",
       "\n",
       "Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/networks.py#L307){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### UNetConvBlock\n",
       "\n",
       ">      UNetConvBlock (in_size, out_size, padding, batch_norm, drop_p=0.15)\n",
       "\n",
       "Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(UNetConvBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/networks.py#L229){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### UNet\n",
       "\n",
       ">      UNet (in_channels=1, n_classes=1, depth=5, wf=6, padding=True,\n",
       ">            batch_norm=True, up_mode='upconv', residual=True, drop_p=0.15)\n",
       "\n",
       "Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/networks.py#L229){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### UNet\n",
       "\n",
       ">      UNet (in_channels=1, n_classes=1, depth=5, wf=6, padding=True,\n",
       ">            batch_norm=True, up_mode='upconv', residual=True, drop_p=0.15)\n",
       "\n",
       "Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(UNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ModuleList(\n",
      "  (0): UNetConvBlock(\n",
      "    (block): Sequential(\n",
      "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): ReLU()\n",
      "      (5): Dropout2d(p=0.15, inplace=False)\n",
      "      (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "), ModuleList(), Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))]\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "x = torch_randn(16, 1, 64, 64, device=device)\n",
    "xdim = len(x.shape)-2\n",
    "\n",
    "tst = UNet(depth=1).to(device)\n",
    "mods = list(tst.children())\n",
    "print(mods)\n",
    "test_eq(tst(x).shape, [16, 1, 64, 64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/networks.py#L361){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ResidualBlock\n",
       "\n",
       ">      ResidualBlock (features, context_features, activation=<function relu>,\n",
       ">                     dropout_probability=0.0, use_batch_norm=False,\n",
       ">                     zero_initialization=True)\n",
       "\n",
       "A general-purpose residual block. Works only with 1-dim inputs."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/networks.py#L361){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ResidualBlock\n",
       "\n",
       ">      ResidualBlock (features, context_features, activation=<function relu>,\n",
       ">                     dropout_probability=0.0, use_batch_norm=False,\n",
       ">                     zero_initialization=True)\n",
       "\n",
       "A general-purpose residual block. Works only with 1-dim inputs."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(ResidualBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/networks.py#L420){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ResidualNet\n",
       "\n",
       ">      ResidualNet (in_features, out_features, hidden_features,\n",
       ">                   context_features=None, num_blocks=2, activation=<function\n",
       ">                   relu>, dropout_probability=0.0, use_batch_norm=False)\n",
       "\n",
       "A general-purpose residual network. Works only with 1-dim inputs."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/networks.py#L420){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ResidualNet\n",
       "\n",
       ">      ResidualNet (in_features, out_features, hidden_features,\n",
       ">                   context_features=None, num_blocks=2, activation=<function\n",
       ">                   relu>, dropout_probability=0.0, use_batch_norm=False)\n",
       "\n",
       "A general-purpose residual network. Works only with 1-dim inputs."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(ResidualNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Linear(in_features=1, out_features=1, bias=True), ModuleList(\n",
      "  (0-1): 2 x ResidualBlock(\n",
      "    (linear_layers): ModuleList(\n",
      "      (0-1): 2 x Linear(in_features=1, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "), Linear(in_features=1, out_features=1, bias=True)]\n"
     ]
    }
   ],
   "source": [
    "x = torch_randn(16, 1, 1, 1)\n",
    "xdim = len(x.shape)-2\n",
    "\n",
    "tst = ResidualNet(1,1,1)\n",
    "mods = list(tst.children())\n",
    "print(mods)\n",
    "assert tst(x).shape == x.size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
