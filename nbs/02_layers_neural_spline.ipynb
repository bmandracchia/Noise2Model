{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NoiseFlow Layers: Neural Spline\n",
    "\n",
    "> noiseflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp layers.neural_spline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "\n",
    "# from IPython.display import clear_output, DisplayHandle\n",
    "# def update_patch(self, obj):\n",
    "#     clear_output(wait=True)\n",
    "#     self.display(obj)\n",
    "# DisplayHandle.update = update_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bm/miniconda3/envs/n2m/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "from fastai.vision.all import nn, torch, np\n",
    "from torch.nn import functional as F, init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "DEFAULT_MIN_BIN_WIDTH = 1e-2\n",
    "DEFAULT_MIN_BIN_HEIGHT = 1e-2\n",
    "DEFAULT_MIN_DERIVATIVE = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class NeuralSpline(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        x_shape,\n",
    "        transform_net,\n",
    "        min_bin_width=DEFAULT_MIN_BIN_WIDTH,\n",
    "        min_bin_height=DEFAULT_MIN_BIN_HEIGHT,\n",
    "        min_derivative=DEFAULT_MIN_DERIVATIVE,\n",
    "        num_bins=10,\n",
    "        tails=\"linear\",\n",
    "        tail_bound=1.0,\n",
    "        name=\"neural_spline\",\n",
    "        device='cpu'\n",
    "        ):\n",
    "        super(NeuralSpline, self).__init__()\n",
    "\n",
    "        self.ic, self.i0, self.i1 = x_shape\n",
    "        self.name = name\n",
    "        self.num_bins = num_bins\n",
    "        self.tails = tails\n",
    "        self.tail_bound = tail_bound\n",
    "        self.min_bin_width = min_bin_width\n",
    "        self.min_bin_height = min_bin_height\n",
    "        self.min_derivative = min_derivative\n",
    "        self._transform_net = transform_net(\n",
    "            x_shape[0]  // 2,\n",
    "            (self.ic - self.ic // 2) * self._transform_dim_multiplier()\n",
    "        )\n",
    "\n",
    "    def _transform_dim_multiplier(self):\n",
    "        if self.tails == \"linear\":\n",
    "            return self.num_bins * 3 - 1\n",
    "        else:\n",
    "            return self.num_bins * 3 + 1\n",
    "\n",
    "    def _inverse(self, z, **kwargs):\n",
    "        identity_split = z[:, :self.ic // 2, ...]\n",
    "        transform_split = z[:, self.ic // 2:, ...]\n",
    "\n",
    "        b, c, h, w = transform_split.shape\n",
    "        transform_params = self._transform_net(identity_split)\n",
    "        transform_params = transform_params.reshape(b, c, -1, h, w).permute(\n",
    "                0, 1, 3, 4, 2\n",
    "            )\n",
    "        unnormalized_widths = transform_params[..., : self.num_bins]\n",
    "        unnormalized_heights = transform_params[..., self.num_bins : 2 * self.num_bins]\n",
    "        unnormalized_derivatives = transform_params[..., 2 * self.num_bins :]\n",
    "\n",
    "        if hasattr(self._transform_net, 'width'):\n",
    "            unnormalized_widths /= np.sqrt(self._transform_net.width)\n",
    "            unnormalized_heights /= np.sqrt(self._transform_net.width)\n",
    "        elif hasattr(self._transform_net, 'hidden_channels'):\n",
    "            unnormalized_widths /= np.sqrt(self._transform_net.hidden_channels)\n",
    "            unnormalized_heights /= np.sqrt(self._transform_net.hidden_channels)\n",
    "        else:\n",
    "            warnings.warn('Inputs to the softmax are not scaled down: initialization might be bad.')\n",
    "\n",
    "        if self.tails is None:\n",
    "            spline_fn = rational_quadratic_spline\n",
    "            spline_kwargs = {}\n",
    "        else:\n",
    "            spline_fn = unconstrained_rational_quadratic_spline\n",
    "            spline_kwargs = {\"tails\": self.tails, \"tail_bound\": self.tail_bound}\n",
    "\n",
    "        transform_split, logabsdet = spline_fn(\n",
    "            inputs=transform_split,\n",
    "            unnormalized_widths=unnormalized_widths,\n",
    "            unnormalized_heights=unnormalized_heights,\n",
    "            unnormalized_derivatives=unnormalized_derivatives,\n",
    "            inverse=True,\n",
    "            min_bin_width=self.min_bin_width,\n",
    "            min_bin_height=self.min_bin_height,\n",
    "            min_derivative=self.min_derivative,\n",
    "            **spline_kwargs\n",
    "        )\n",
    "\n",
    "        logabsdet = sum_except_batch(logabsdet)\n",
    "\n",
    "        outputs = torch.cat([identity_split, transform_split], dim=1)\n",
    "        return outputs\n",
    "\n",
    "    def _forward_and_log_det_jacobian(self, x, **kwargs):\n",
    "        identity_split = x[:, :self.ic // 2, ...]\n",
    "        transform_split = x[:, self.ic // 2:, ...]\n",
    "\n",
    "        b, c, h, w = transform_split.shape\n",
    "        transform_params = self._transform_net(identity_split)\n",
    "        transform_params = transform_params.reshape(b, c, -1, h, w).permute(\n",
    "                0, 1, 3, 4, 2\n",
    "            )\n",
    "        unnormalized_widths = transform_params[..., : self.num_bins]\n",
    "        unnormalized_heights = transform_params[..., self.num_bins : 2 * self.num_bins]\n",
    "        unnormalized_derivatives = transform_params[..., 2 * self.num_bins :]\n",
    "\n",
    "        if hasattr(self._transform_net, 'width'):\n",
    "            unnormalized_widths /= np.sqrt(self._transform_net.width)\n",
    "            unnormalized_heights /= np.sqrt(self._transform_net.width)\n",
    "        elif hasattr(self._transform_net, 'hidden_channels'):\n",
    "            unnormalized_widths /= np.sqrt(self._transform_net.hidden_channels)\n",
    "            unnormalized_heights /= np.sqrt(self._transform_net.hidden_channels)\n",
    "        else:\n",
    "            warnings.warn('Inputs to the softmax are not scaled down: initialization might be bad.')\n",
    "\n",
    "        if self.tails is None:\n",
    "            spline_fn = rational_quadratic_spline\n",
    "            spline_kwargs = {}\n",
    "        else:\n",
    "            spline_fn = unconstrained_rational_quadratic_spline\n",
    "            spline_kwargs = {\"tails\": self.tails, \"tail_bound\": self.tail_bound}\n",
    "\n",
    "\n",
    "        transform_split, logabsdet = spline_fn(\n",
    "            inputs=transform_split,\n",
    "            unnormalized_widths=unnormalized_widths,\n",
    "            unnormalized_heights=unnormalized_heights,\n",
    "            unnormalized_derivatives=unnormalized_derivatives,\n",
    "            inverse=False,\n",
    "            min_bin_width=self.min_bin_width,\n",
    "            min_bin_height=self.min_bin_height,\n",
    "            min_derivative=self.min_derivative,\n",
    "            **spline_kwargs\n",
    "        )\n",
    "\n",
    "        logabsdet = sum_except_batch(logabsdet)\n",
    "\n",
    "        outputs = torch.cat([identity_split, transform_split], dim=1)\n",
    "        return outputs, logabsdet\n",
    "\n",
    "class ConditionalNeuralSpline(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        x_shape,\n",
    "        transform_net,\n",
    "        encoder,\n",
    "        min_bin_width=DEFAULT_MIN_BIN_WIDTH,\n",
    "        min_bin_height=DEFAULT_MIN_BIN_HEIGHT,\n",
    "        min_derivative=DEFAULT_MIN_DERIVATIVE,\n",
    "        num_bins=10,\n",
    "        tails=\"linear\",\n",
    "        tail_bound=1.0,\n",
    "        name=\"conditional_neural_spline\",\n",
    "        device='cpu'\n",
    "        ):\n",
    "        super(ConditionalNeuralSpline, self).__init__()\n",
    "\n",
    "        self.ic, self.i0, self.i1 = x_shape\n",
    "        self.name = name\n",
    "        self.num_bins = num_bins\n",
    "        self.tails = tails\n",
    "        self.tail_bound = tail_bound\n",
    "        self.min_bin_width = min_bin_width\n",
    "        self.min_bin_height = min_bin_height\n",
    "        self.min_derivative = min_derivative\n",
    "        self._transform_net = transform_net(\n",
    "            x_shape[0]  // 2 + x_shape[0],\n",
    "            (self.ic - self.ic // 2) * self._transform_dim_multiplier()\n",
    "        )\n",
    "\n",
    "        self._encoder = encoder(10, 1)\n",
    "\n",
    "        self.cam_vals = torch.tensor([0, 1, 2, 3, 4], dtype=torch.float32, device=device)  # 'IP', 'GP', 'S6', 'N6', 'G4'\n",
    "        self.iso_vals = torch.tensor([100, 400, 800, 1600, 3200], dtype=torch.float32, device=device)\n",
    "\n",
    "    def _transform_dim_multiplier(self):\n",
    "        if self.tails == \"linear\":\n",
    "            return self.num_bins * 3 - 1\n",
    "        else:\n",
    "            return self.num_bins * 3 + 1\n",
    "\n",
    "    def _inverse(self, z, **kwargs):\n",
    "        gain_one_hot = self.iso_vals == torch.mean(kwargs['iso'], dim=[1, 2, 3]).unsqueeze(1)\n",
    "        gain_one_hot = torch.where(gain_one_hot, 1., 0.)\n",
    "        cam_one_hot = self.cam_vals == torch.mean(kwargs['cam'], dim=[1, 2, 3]).unsqueeze(1)\n",
    "        cam_one_hot = torch.where(cam_one_hot, 1., 0.)\n",
    "        embedding = self._encoder(torch.cat((gain_one_hot, cam_one_hot), dim=1))\n",
    "        embedding = embedding.reshape((-1, 1, 1, 1, 1))\n",
    "\n",
    "        identity_split = z[:, :self.ic // 2, ...]\n",
    "        transform_split = z[:, self.ic // 2:, ...]\n",
    "\n",
    "        b, c, h, w = transform_split.shape\n",
    "        transform_params = self._transform_net(torch.cat((identity_split, kwargs['clean']), dim=1))\n",
    "        transform_params = transform_params.reshape(b, c, -1, h, w).permute(\n",
    "                0, 1, 3, 4, 2\n",
    "            )\n",
    "        unnormalized_widths = transform_params[..., : self.num_bins]\n",
    "        unnormalized_heights = transform_params[..., self.num_bins : 2 * self.num_bins]\n",
    "        unnormalized_derivatives = transform_params[..., 2 * self.num_bins :]\n",
    "\n",
    "        if hasattr(self._transform_net, 'width'):\n",
    "            unnormalized_widths /= np.sqrt(self._transform_net.width)\n",
    "            unnormalized_heights /= np.sqrt(self._transform_net.width)\n",
    "        elif hasattr(self._transform_net, 'hidden_channels'):\n",
    "            unnormalized_widths /= np.sqrt(self._transform_net.hidden_channels)\n",
    "            unnormalized_heights /= np.sqrt(self._transform_net.hidden_channels)\n",
    "        else:\n",
    "            warnings.warn('Inputs to the softmax are not scaled down: initialization might be bad.')\n",
    "\n",
    "        unnormalized_widths *= torch.exp(embedding)\n",
    "        unnormalized_heights *= torch.exp(embedding)\n",
    "    \n",
    "        if self.tails is None:\n",
    "            spline_fn = rational_quadratic_spline\n",
    "            spline_kwargs = {}\n",
    "        else:\n",
    "            spline_fn = unconstrained_rational_quadratic_spline\n",
    "            spline_kwargs = {\"tails\": self.tails, \"tail_bound\": self.tail_bound}\n",
    "\n",
    "        transform_split, logabsdet = spline_fn(\n",
    "            inputs=transform_split,\n",
    "            unnormalized_widths=unnormalized_widths,\n",
    "            unnormalized_heights=unnormalized_heights,\n",
    "            unnormalized_derivatives=unnormalized_derivatives,\n",
    "            inverse=True,\n",
    "            min_bin_width=self.min_bin_width,\n",
    "            min_bin_height=self.min_bin_height,\n",
    "            min_derivative=self.min_derivative,\n",
    "            **spline_kwargs\n",
    "        )\n",
    "\n",
    "        logabsdet = sum_except_batch(logabsdet)\n",
    "\n",
    "        outputs = torch.cat([identity_split, transform_split], dim=1)\n",
    "        return outputs\n",
    "\n",
    "    def _forward_and_log_det_jacobian(self, x, **kwargs):\n",
    "        gain_one_hot = self.iso_vals == torch.mean(kwargs['iso'], dim=[1, 2, 3]).unsqueeze(1)\n",
    "        gain_one_hot = torch.where(gain_one_hot, 1., 0.)\n",
    "        cam_one_hot = self.cam_vals == torch.mean(kwargs['cam'], dim=[1, 2, 3]).unsqueeze(1)\n",
    "        cam_one_hot = torch.where(cam_one_hot, 1., 0.)\n",
    "        embedding = self._encoder(torch.cat((gain_one_hot, cam_one_hot), dim=1))\n",
    "        embedding = embedding.reshape((-1, 1, 1, 1, 1))\n",
    "\n",
    "        identity_split = x[:, :self.ic // 2, ...]\n",
    "        transform_split = x[:, self.ic // 2:, ...]\n",
    "\n",
    "        b, c, h, w = transform_split.shape\n",
    "        transform_params = self._transform_net(torch.cat((identity_split, kwargs['clean']), dim=1))\n",
    "        transform_params = transform_params.reshape(b, c, -1, h, w).permute(\n",
    "                0, 1, 3, 4, 2\n",
    "            )\n",
    "        unnormalized_widths = transform_params[..., : self.num_bins]\n",
    "        unnormalized_heights = transform_params[..., self.num_bins : 2 * self.num_bins]\n",
    "        unnormalized_derivatives = transform_params[..., 2 * self.num_bins :]\n",
    "\n",
    "        if hasattr(self._transform_net, 'width'):\n",
    "            unnormalized_widths /= np.sqrt(self._transform_net.width)\n",
    "            unnormalized_heights /= np.sqrt(self._transform_net.width)\n",
    "        elif hasattr(self._transform_net, 'hidden_channels'):\n",
    "            unnormalized_widths /= np.sqrt(self._transform_net.hidden_channels)\n",
    "            unnormalized_heights /= np.sqrt(self._transform_net.hidden_channels)\n",
    "        else:\n",
    "            warnings.warn('Inputs to the softmax are not scaled down: initialization might be bad.')\n",
    "\n",
    "        unnormalized_widths *= torch.exp(embedding)\n",
    "        unnormalized_heights *= torch.exp(embedding)\n",
    "\n",
    "        if self.tails is None:\n",
    "            spline_fn = rational_quadratic_spline\n",
    "            spline_kwargs = {}\n",
    "        else:\n",
    "            spline_fn = unconstrained_rational_quadratic_spline\n",
    "            spline_kwargs = {\"tails\": self.tails, \"tail_bound\": self.tail_bound}\n",
    "\n",
    "\n",
    "        transform_split, logabsdet = spline_fn(\n",
    "            inputs=transform_split,\n",
    "            unnormalized_widths=unnormalized_widths,\n",
    "            unnormalized_heights=unnormalized_heights,\n",
    "            unnormalized_derivatives=unnormalized_derivatives,\n",
    "            inverse=False,\n",
    "            min_bin_width=self.min_bin_width,\n",
    "            min_bin_height=self.min_bin_height,\n",
    "            min_derivative=self.min_derivative,\n",
    "            **spline_kwargs\n",
    "        )\n",
    "\n",
    "        logabsdet = sum_except_batch(logabsdet)\n",
    "\n",
    "        outputs = torch.cat([identity_split, transform_split], dim=1)\n",
    "        return outputs, logabsdet\n",
    "\n",
    "class TransformNet(nn.Module):\n",
    "    def __init__(self, x_shape, num_in, num_output, width=4, activation=nn.ReLU(), device='cpu'):\n",
    "        super(TransformNet, self).__init__()\n",
    "        self.width = width\n",
    "        self.activation = activation\n",
    "        self.n_channels = x_shape[0]\n",
    "        self.num_output = num_output\n",
    "        self.num_in = num_in\n",
    "\n",
    "        self.conv2d_1 = nn.Conv2d(in_channels=self.num_in, out_channels=self.width, kernel_size=3, padding=1)\n",
    "        nn.init.normal_(self.conv2d_1.weight, mean=0.0, std=self.width / 512 * 0.05)\n",
    "        self.conv2d_1.bias.data.fill_(0.0)\n",
    "\n",
    "        self.conv2d_2 = nn.Conv2d(in_channels=self.width, out_channels=self.width, kernel_size=1, padding=0)\n",
    "        nn.init.normal_(self.conv2d_2.weight, mean=0.0, std=self.width / 512 * 0.05)\n",
    "        self.conv2d_2.bias.data.fill_(0.0)\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            self.conv2d_1,\n",
    "            nn.BatchNorm2d(num_features=self.width),\n",
    "            activation,\n",
    "            self.conv2d_2,\n",
    "            nn.BatchNorm2d(num_features=self.width),\n",
    "            activation\n",
    "        )\n",
    "\n",
    "        self.padding = nn.ConstantPad3d((1, 1, 1, 1, 0, 1), 0.)\n",
    "        self.conv2d_3 = nn.Conv2d(in_channels=self.width+1, out_channels=self.num_output, kernel_size=3, padding=0)\n",
    "        self.conv2d_3.weight.data.fill_(0.0)\n",
    "        self.conv2d_3.bias.data.fill_(0.0)\n",
    "        self.logs = nn.Parameter(torch.zeros([1, self.num_output, 1, 1], device=device), requires_grad=True)\n",
    "\n",
    "    def forward(self, x, writer=None, step=None):\n",
    "        x = self.net(x)\n",
    "\n",
    "        x = self.padding(x)\n",
    "        x[:, 4, :1, :] = 1.0\n",
    "        x[:, 4, -1:, :] = 1.0\n",
    "        x[:, 4, :, :1] = 1.0\n",
    "        x[:, 4, :, -1:] = 1.0\n",
    "        x = self.conv2d_3(x)\n",
    "        x *= torch.exp(self.logs * 3)\n",
    "        return x\n",
    "\n",
    "class ConvResidualBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 channels,\n",
    "                 context_channels=None,\n",
    "                 activation=F.relu,\n",
    "                 dropout_probability=0.,\n",
    "                 use_batch_norm=False,\n",
    "                 zero_initialization=True):\n",
    "        super().__init__()\n",
    "        self.activation = activation\n",
    "\n",
    "        if context_channels is not None:\n",
    "            self.context_layer = nn.Conv2d(\n",
    "                in_channels=context_channels,\n",
    "                out_channels=channels,\n",
    "                kernel_size=1,\n",
    "                padding=0\n",
    "            )\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        if use_batch_norm:\n",
    "            self.batch_norm_layers = nn.ModuleList([\n",
    "                nn.BatchNorm2d(channels, eps=1e-3)\n",
    "                for _ in range(2)\n",
    "            ])\n",
    "        self.conv_layers = nn.ModuleList([\n",
    "            nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "            for _ in range(2)\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(p=dropout_probability)\n",
    "        if zero_initialization:\n",
    "            init.uniform_(self.conv_layers[-1].weight, -1e-3, 1e-3)\n",
    "            init.uniform_(self.conv_layers[-1].bias, -1e-3, 1e-3)\n",
    "\n",
    "    def forward(self, inputs, context=None):\n",
    "        temps = inputs\n",
    "        if self.use_batch_norm:\n",
    "            temps = self.batch_norm_layers[0](temps)\n",
    "        temps = self.activation(temps)\n",
    "        temps = self.conv_layers[0](temps)\n",
    "        if self.use_batch_norm:\n",
    "            temps = self.batch_norm_layers[1](temps)\n",
    "        temps = self.activation(temps)\n",
    "        temps = self.dropout(temps)\n",
    "        temps = self.conv_layers[1](temps)\n",
    "        if context is not None:\n",
    "            temps = F.glu(\n",
    "                torch.cat(\n",
    "                    (temps, self.context_layer(context)),\n",
    "                    dim=1\n",
    "                ),\n",
    "                dim=1\n",
    "            )\n",
    "        return inputs + temps\n",
    "\n",
    "\n",
    "class ConvResidualNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 hidden_channels,\n",
    "                 context_channels=None,\n",
    "                 num_blocks=2,\n",
    "                 activation=F.relu,\n",
    "                 dropout_probability=0.,\n",
    "                 use_batch_norm=False\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.context_channels = context_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        if context_channels is not None:\n",
    "            self.initial_layer = nn.Conv2d(\n",
    "                in_channels=in_channels + context_channels,\n",
    "                out_channels=hidden_channels,\n",
    "                kernel_size=1,\n",
    "                padding=0\n",
    "            )\n",
    "        else:\n",
    "            self.initial_layer = nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=hidden_channels,\n",
    "                kernel_size=1,\n",
    "                padding=0\n",
    "            )\n",
    "        self.blocks = nn.ModuleList([\n",
    "            ConvResidualBlock(\n",
    "                channels=hidden_channels,\n",
    "                context_channels=context_channels,\n",
    "                activation=activation,\n",
    "                dropout_probability=dropout_probability,\n",
    "                use_batch_norm=use_batch_norm,\n",
    "            ) for _ in range(num_blocks)\n",
    "        ])\n",
    "        self.final_layer = nn.Conv2d(hidden_channels, out_channels, kernel_size=1, padding=0)\n",
    "\n",
    "    def forward(self, inputs, context=None):\n",
    "        if context is None:\n",
    "            temps = self.initial_layer(inputs)\n",
    "        else:\n",
    "            temps = self.initial_layer(\n",
    "                torch.cat((inputs, context), dim=1)\n",
    "            )\n",
    "        for block in self.blocks:\n",
    "            temps = block(temps, context)\n",
    "        outputs = self.final_layer(temps)\n",
    "        return outputs\n",
    "\n",
    "def unconstrained_rational_quadratic_spline(\n",
    "    inputs,\n",
    "    unnormalized_widths,\n",
    "    unnormalized_heights,\n",
    "    unnormalized_derivatives,\n",
    "    inverse=False,\n",
    "    tails=\"linear\",\n",
    "    tail_bound=1.0,\n",
    "    min_bin_width=DEFAULT_MIN_BIN_WIDTH,\n",
    "    min_bin_height=DEFAULT_MIN_BIN_HEIGHT,\n",
    "    min_derivative=DEFAULT_MIN_DERIVATIVE,\n",
    "):\n",
    "    inside_interval_mask = (inputs >= -tail_bound) & (inputs <= tail_bound)\n",
    "    outside_interval_mask = ~inside_interval_mask\n",
    "\n",
    "    outputs = torch.zeros_like(inputs)\n",
    "    logabsdet = torch.zeros_like(inputs)\n",
    "\n",
    "    if tails == \"linear\":\n",
    "        unnormalized_derivatives = F.pad(unnormalized_derivatives, pad=(1, 1))\n",
    "        constant = np.log(np.exp(1 - min_derivative) - 1)\n",
    "        unnormalized_derivatives[..., 0] = constant\n",
    "        unnormalized_derivatives[..., -1] = constant\n",
    "\n",
    "        outputs[outside_interval_mask] = inputs[outside_interval_mask]\n",
    "        logabsdet[outside_interval_mask] = 0\n",
    "    else:\n",
    "        raise RuntimeError(\"{} tails are not implemented.\".format(tails))\n",
    "\n",
    "    if torch.any(inside_interval_mask):\n",
    "        (\n",
    "            outputs[inside_interval_mask],\n",
    "            logabsdet[inside_interval_mask],\n",
    "        ) = rational_quadratic_spline(\n",
    "            inputs=inputs[inside_interval_mask],\n",
    "            unnormalized_widths=unnormalized_widths[inside_interval_mask, :],\n",
    "            unnormalized_heights=unnormalized_heights[inside_interval_mask, :],\n",
    "            unnormalized_derivatives=unnormalized_derivatives[inside_interval_mask, :],\n",
    "            inverse=inverse,\n",
    "            left=-tail_bound,\n",
    "            right=tail_bound,\n",
    "            bottom=-tail_bound,\n",
    "            top=tail_bound,\n",
    "            min_bin_width=min_bin_width,\n",
    "            min_bin_height=min_bin_height,\n",
    "            min_derivative=min_derivative,\n",
    "            d_type=outputs.dtype\n",
    "        )\n",
    "\n",
    "    return outputs, logabsdet\n",
    "\n",
    "\n",
    "def rational_quadratic_spline(\n",
    "    inputs,\n",
    "    unnormalized_widths,\n",
    "    unnormalized_heights,\n",
    "    unnormalized_derivatives,\n",
    "    inverse=False,\n",
    "    left=0.0,\n",
    "    right=1.0,\n",
    "    bottom=0.0,\n",
    "    top=1.0,\n",
    "    min_bin_width=DEFAULT_MIN_BIN_WIDTH,\n",
    "    min_bin_height=DEFAULT_MIN_BIN_HEIGHT,\n",
    "    min_derivative=DEFAULT_MIN_DERIVATIVE,\n",
    "    d_type=torch.float\n",
    "):\n",
    "    if torch.min(inputs) < left or torch.max(inputs) > right:\n",
    "        raise InputOutsideDomain()\n",
    "\n",
    "    num_bins = unnormalized_widths.shape[-1]\n",
    "\n",
    "    if min_bin_width * num_bins > 1.0:\n",
    "        raise ValueError(\"Minimal bin width too large for the number of bins\")\n",
    "    if min_bin_height * num_bins > 1.0:\n",
    "        raise ValueError(\"Minimal bin height too large for the number of bins\")\n",
    "\n",
    "    widths = F.softmax(unnormalized_widths, dim=-1)\n",
    "    widths = min_bin_width + (1 - min_bin_width * num_bins) * widths\n",
    "    cumwidths = torch.cumsum(widths, dim=-1)\n",
    "    cumwidths = F.pad(cumwidths, pad=(1, 0), mode=\"constant\", value=0.0)\n",
    "    cumwidths = (right - left) * cumwidths + left\n",
    "    cumwidths[..., 0] = left\n",
    "    cumwidths[..., -1] = right\n",
    "    widths = cumwidths[..., 1:] - cumwidths[..., :-1]\n",
    "\n",
    "    derivatives = min_derivative + F.softplus(unnormalized_derivatives)\n",
    "\n",
    "    heights = F.softmax(unnormalized_heights, dim=-1)\n",
    "    heights = min_bin_height + (1 - min_bin_height * num_bins) * heights\n",
    "    cumheights = torch.cumsum(heights, dim=-1)\n",
    "    cumheights = F.pad(cumheights, pad=(1, 0), mode=\"constant\", value=0.0)\n",
    "    cumheights = (top - bottom) * cumheights + bottom\n",
    "    cumheights[..., 0] = bottom\n",
    "    cumheights[..., -1] = top\n",
    "    heights = cumheights[..., 1:] - cumheights[..., :-1]\n",
    "\n",
    "    if inverse:\n",
    "        bin_idx = searchsorted(cumheights, inputs)[..., None]\n",
    "    else:\n",
    "        bin_idx = searchsorted(cumwidths, inputs)[..., None]\n",
    "\n",
    "    input_cumwidths = cumwidths.gather(-1, bin_idx)[..., 0]\n",
    "    input_bin_widths = widths.gather(-1, bin_idx)[..., 0]\n",
    "\n",
    "    input_cumheights = cumheights.gather(-1, bin_idx)[..., 0]\n",
    "    delta = heights / widths\n",
    "    input_delta = delta.gather(-1, bin_idx)[..., 0]\n",
    "\n",
    "    input_derivatives = derivatives.gather(-1, bin_idx)[..., 0]\n",
    "    input_derivatives_plus_one = derivatives[..., 1:].gather(-1, bin_idx)[..., 0]\n",
    "\n",
    "    input_heights = heights.gather(-1, bin_idx)[..., 0]\n",
    "\n",
    "    if inverse:\n",
    "        a = (inputs - input_cumheights) * (\n",
    "            input_derivatives + input_derivatives_plus_one - 2 * input_delta\n",
    "        ) + input_heights * (input_delta - input_derivatives)\n",
    "        b = input_heights * input_derivatives - (inputs - input_cumheights) * (\n",
    "            input_derivatives + input_derivatives_plus_one - 2 * input_delta\n",
    "        )\n",
    "        c = -input_delta * (inputs - input_cumheights)\n",
    "\n",
    "        discriminant = b.pow(2) - 4 * a * c\n",
    "        assert (discriminant >= 0).all()\n",
    "\n",
    "        root = (2 * c) / (-b - torch.sqrt(discriminant))\n",
    "        # root = (- b + torch.sqrt(discriminant)) / (2 * a)\n",
    "        outputs = root * input_bin_widths + input_cumwidths\n",
    "\n",
    "        theta_one_minus_theta = root * (1 - root)\n",
    "        denominator = input_delta + (\n",
    "            (input_derivatives + input_derivatives_plus_one - 2 * input_delta)\n",
    "            * theta_one_minus_theta\n",
    "        )\n",
    "        derivative_numerator = input_delta.pow(2) * (\n",
    "            input_derivatives_plus_one * root.pow(2)\n",
    "            + 2 * input_delta * theta_one_minus_theta\n",
    "            + input_derivatives * (1 - root).pow(2)\n",
    "        )\n",
    "        logabsdet = torch.log(derivative_numerator) - 2 * torch.log(denominator)\n",
    "\n",
    "        return outputs, -logabsdet\n",
    "    else:\n",
    "        theta = (inputs - input_cumwidths) / input_bin_widths\n",
    "        theta_one_minus_theta = theta * (1 - theta)\n",
    "\n",
    "        numerator = input_heights * (\n",
    "            input_delta * theta.pow(2) + input_derivatives * theta_one_minus_theta\n",
    "        )\n",
    "        denominator = input_delta + (\n",
    "            (input_derivatives + input_derivatives_plus_one - 2 * input_delta)\n",
    "            * theta_one_minus_theta\n",
    "        )\n",
    "        outputs = input_cumheights + numerator / denominator\n",
    "\n",
    "        derivative_numerator = input_delta.pow(2) * (\n",
    "            input_derivatives_plus_one * theta.pow(2)\n",
    "            + 2 * input_delta * theta_one_minus_theta\n",
    "            + input_derivatives * (1 - theta).pow(2)\n",
    "        )\n",
    "        logabsdet = torch.log(derivative_numerator) - 2 * torch.log(denominator)\n",
    "\n",
    "        return outputs.to(d_type), logabsdet.to(d_type)\n",
    "    \n",
    "def searchsorted(bin_locations, inputs, eps=1e-6):\n",
    "    bin_locations[..., -1] += eps\n",
    "    return torch.sum(inputs[..., None] >= bin_locations, dim=-1) - 1\n",
    "\n",
    "def sum_except_batch(x, num_batch_dims=1):\n",
    "    \"\"\"Sums all elements of `x` except for the first `num_batch_dims` dimensions.\"\"\"\n",
    "    if not is_nonnegative_int(num_batch_dims):\n",
    "        raise TypeError(\"Number of batch dimensions must be a non-negative integer.\")\n",
    "    reduce_dims = list(range(num_batch_dims, x.ndimension()))\n",
    "    return torch.sum(x, dim=reduce_dims)\n",
    "\n",
    "def is_nonnegative_int(x):\n",
    "    return isinstance(x, int) and x >= 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
