{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "> models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from fastai.vision.all import ConvLayer, Lambda, MaxPool, NormType, np\n",
    "from torch import cat as torch_cat\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F, init\n",
    "\n",
    "from Noise2Model.utils import attributesFromDict\n",
    "\n",
    "import os\n",
    "from importlib import import_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import randn as torch_randn\n",
    "from fastai.vision.all import test_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "model_class_dict = {}\n",
    "\n",
    "def regist_model(model_class):\n",
    "    model_name = model_class.__name__.lower()\n",
    "    assert not model_name in model_class_dict, 'there is already registered model: %s in model_class_dict.' % model_name\n",
    "    model_class_dict[model_name] = model_class\n",
    "\n",
    "    return model_class\n",
    "\n",
    "def get_model_class(model_name:str):\n",
    "    model_name = model_name.lower()\n",
    "    return model_class_dict[model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch_randn(16, 1, 32, 64, 64)\n",
    "xdim = len(x.shape)-2\n",
    "\n",
    "tst = ConvLayer(1, 1, ndim=xdim)\n",
    "test_eq(tst(x).shape, [16, 1, 32, 64, 64])\n",
    "tst = MaxPool(2, ndim=xdim)\n",
    "test_eq(tst(x).shape, [16, 1, 16, 32, 32])\n",
    "tst = Lambda(lambda x: x+np.float32(1e-3))\n",
    "test_eq(tst(x).shape, [16, 1, 32, 64, 64])\n",
    "test_eq(torch_cat((x, tst(x)), 1).shape, [16, 2, 32, 64, 64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DnCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@regist_model\n",
    "class DnCNN(nn.Module):\n",
    "    def __init__(self, channels, num_of_layers=18,features=64):\n",
    "        super(DnCNN, self).__init__()\n",
    "        kernel_size = 3\n",
    "        padding = kernel_size//2\n",
    "        self.bias=True\n",
    "        self.residual=True\n",
    "        layers = list()\n",
    "        layers.append(nn.Conv2d(in_channels=channels, out_channels=features, kernel_size=kernel_size, padding=padding, bias=self.bias))\n",
    "        layers.append(nn.ReLU(inplace=True))\n",
    "        for _ in range(num_of_layers-2):\n",
    "            layers.append(nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding, bias=self.bias))\n",
    "            layers.append(nn.BatchNorm2d(features, momentum=0.9, eps=1e-04, affine=True))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "        layers.append(nn.Conv2d(in_channels=features, out_channels=channels, kernel_size=kernel_size, padding=padding, bias=self.bias))\n",
    "        self.dncnn = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, kwargs=None):\n",
    "        if self.residual:\n",
    "            out = x-self.dncnn(x)\n",
    "        else:\n",
    "            out = self.dncnn(x)\n",
    "        return out\n",
    "    \n",
    "@regist_model\n",
    "class DnCNNFlowGAN(NMFlowGANDenoiser):\n",
    "    def __init__(\n",
    "        self,\n",
    "        kwargs_dncnn,\n",
    "        kwargs_unet,\n",
    "        kwargs_flow,\n",
    "        pretrained_path,\n",
    "        num_bits=8\n",
    "        ):\n",
    "        super().__init__(\n",
    "            DnCNN(**kwargs_dncnn),\n",
    "            kwargs_flow,\n",
    "            kwargs_unet,\n",
    "            pretrained_path,\n",
    "            num_bits,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# class DnCNN(nn.Module):\n",
    "#     def __init__(self, channels, num_of_layers=9, features=64, kernel_size=3):\n",
    "#         super(DnCNN, self).__init__()\n",
    "#         padding = 1\n",
    "#         layers = []\n",
    "#         layers.append(ConvLayer(channels, features,\n",
    "#                       ks=kernel_size, padding=padding, norm_type=None))\n",
    "#         for _ in range(num_of_layers-2):\n",
    "#             layers.append(ConvLayer(features, features,\n",
    "#                           ks=kernel_size, padding=padding))\n",
    "#         layers.append(nn.Conv2d(in_channels=features, out_channels=channels,\n",
    "#                       kernel_size=kernel_size, padding=padding, bias=False))\n",
    "#         self.dncnn = nn.Sequential(*layers)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         residual = self.dncnn(x)\n",
    "#         denoised = x - residual\n",
    "#         return denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DnCNN(\n",
      "  (dncnn): Sequential(\n",
      "    (0): ConvLayer(\n",
      "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (1): ConvLayer(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (2): ConvLayer(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (3): ConvLayer(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (4): ConvLayer(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (5): ConvLayer(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (6): ConvLayer(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (7): ConvLayer(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (8): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "x = torch_randn(16, 1, 32, 64)\n",
    "\n",
    "tst = DnCNN(1)\n",
    "test_eq(tst(x).shape, [16, 1, 32, 64])\n",
    "print(tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def SubNetConv(ks=3,\n",
    "               stride=1,\n",
    "               padding=None,\n",
    "               bias=None,\n",
    "               ndim=2,\n",
    "               norm_type=NormType.Batch,\n",
    "               bn_1st=True,\n",
    "               act_cls=nn.ReLU,\n",
    "               transpose=False,\n",
    "               init='auto',\n",
    "               xtra=None,\n",
    "               bias_std=0.01,\n",
    "               dropout=0.0,\n",
    "               ):\n",
    "\n",
    "    def _conv(n_in, n_out, n_conv=1):\n",
    "        s = ConvLayer(n_in, n_out, ks=ks, stride=stride, padding=padding, bias=bias, ndim=ndim, norm_type=norm_type, bn_1st=bn_1st,\n",
    "                      act_cls=act_cls, transpose=transpose, init=init, xtra=xtra, bias_std=bias_std)\n",
    "        if dropout is not None and dropout > 0:\n",
    "            s = nn.Sequential(s, nn.Dropout(dropout))\n",
    "        for _ in range(n_conv-1):\n",
    "            t = ConvLayer(n_out, n_out, ks=ks, stride=stride, padding=padding, bias=bias, ndim=ndim, norm_type=norm_type, bn_1st=bn_1st,\n",
    "                          act_cls=act_cls, transpose=transpose, init=init, xtra=xtra, bias_std=bias_std)\n",
    "            if dropout is not None and dropout > 0:\n",
    "                t = nn.Sequential(t, nn.Dropout(dropout))\n",
    "            s = nn.Sequential(s, t)\n",
    "        return s\n",
    "\n",
    "    return _conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): ConvLayer(\n",
      "      (0): Conv3d(1, 2, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (1): BatchNorm3d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): ConvLayer(\n",
      "      (0): Conv3d(2, 2, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (1): BatchNorm3d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "ConvLayer(\n",
      "  (0): ConvTranspose3d(2, 1, kernel_size=(4, 4, 4), stride=(4, 4, 4), bias=False)\n",
      "  (1): BatchNorm3d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "x = torch_randn(16, 1, 32, 64, 64)\n",
    "xdim = len(x.shape)-2\n",
    "\n",
    "# reduce\n",
    "tst = SubNetConv(3, padding=1, stride=2, ndim=xdim,\n",
    "                 norm_type=NormType.Batch, dropout=.1)(1, 2, 2)\n",
    "y = tst(x)\n",
    "test_eq(y.shape, [16, 2, 8, 16, 16])\n",
    "print(tst)\n",
    "# upsample\n",
    "tst = SubNetConv(ks=4, padding=0, stride=4, ndim=xdim, norm_type=NormType.Batch,\n",
    "                 transpose=True)(2, 1)  # to double the size, the kernel cannot be odd\n",
    "test_eq(tst(y).shape, [16, 1, 32, 64, 64])\n",
    "print(tst)\n",
    "del y\n",
    "# ConvLayer(2*n_out_channels, n_out_channels, ks=ks, transpose=True, padding=(ks-1)//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class _Net_recurse(nn.Module):\n",
    "    def __init__(self,\n",
    "                 depth=4,\t\t\t\t\t\t# depth of the UNet network\n",
    "                 mult_chan=32,\t\t\t\t\t# number of filters at first layer\n",
    "                 in_channels=1,\t\t\t\t\t# number of input channels\n",
    "                 kernel_size=3,\t\t\t\t\t# kernel size of convolutional layers\n",
    "                 ndim=2,\t\t\t\t\t\t\t# number of spatial dimensions of the input data\n",
    "                 n_conv_per_depth=2,\t\t\t\t# number of convolutions per layer\n",
    "                 activation=nn.ReLU,\t\t\t\t# activation function used in convolutional layers\n",
    "                 norm_type=NormType.Batch,\n",
    "                 dropout=0.0,\n",
    "                 pool=MaxPool,\n",
    "                 pool_size=2,\n",
    "                 ):\n",
    "        \"\"\"Class for recursive definition of U-network.p\n",
    "\n",
    "        Parameters:\n",
    "        in_channels - (int) number of channels for input.\n",
    "        mult_chan - (int) factor to determine number of output channels\n",
    "        depth - (int) if 0, this subnet will only be convolutions that double the channel count.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Parameters\n",
    "        self.depth = depth\n",
    "        n_out = in_channels*mult_chan\n",
    "\n",
    "        # Layer types\n",
    "        Pooling = pool(ks=pool_size, ndim=ndim)\n",
    "        UpSample = nn.Upsample(scale_factor=pool_size, mode='nearest')\n",
    "        SubNet_Conv = SubNetConv(ks=kernel_size, stride=1, padding=None, bias=None, ndim=ndim, norm_type=norm_type,\n",
    "                                 bn_1st=True, act_cls=activation, transpose=False, dropout=dropout)\n",
    "\n",
    "        # Blocks\n",
    "        self.sub_conv_more = SubNet_Conv(in_channels, n_out, n_conv_per_depth)\n",
    "        if self.depth > 0:\n",
    "            in_channels = n_out\n",
    "            mult_chan = 2\n",
    "            depth = (self.depth - 1)\n",
    "            self.sub_u = nn.Sequential(Pooling,                                                         # layer reducing the image size (usually a pooling layer)\n",
    "                                       _Net_recurse(depth, mult_chan, in_channels, kernel_size,\n",
    "                                                    ndim, n_conv_per_depth, activation, norm_type,\n",
    "                                                    dropout, pool, pool_size),                          # lower unet level\n",
    "                                       # layer increasing the image size (usually an upsampling layer)\n",
    "                                       UpSample,\n",
    "                                       )\n",
    "            self.sub_conv_less = SubNet_Conv(3*n_out, n_out, n_conv_per_depth)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.depth == 0:\n",
    "            return self.sub_conv_more(x)\n",
    "        else:  # depth > 0\n",
    "            # convolutions with increasing number of channels\n",
    "            x_conv_more = self.sub_conv_more(x)\n",
    "            x_from_sub_u = self.sub_u(x_conv_more)\n",
    "            # concatenate the upsampled outputs of the lower level with the outputs of the next level in size\n",
    "            x_cat = torch_cat((x_from_sub_u, x_conv_more), 1)\n",
    "            # convolutions with decreasing number of channels\n",
    "            x_conv_less = self.sub_conv_less(x_cat)\n",
    "        return x_conv_less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 depth=4,\t\t\t\t\t\t# depth of the UNet network\n",
    "                 mult_chan=32,\t\t\t\t\t# number of filters at first layer\n",
    "                 in_channels=1,\t\t\t\t\t# number of input channels\n",
    "                 out_channels=1,\t\t\t\t\t# number of output channels\n",
    "                 last_activation=None,\t\t\t# last activation before final result\n",
    "                 kernel_size=3,\t\t\t\t\t# kernel size of convolutional layers\n",
    "                 ndim=2,\t\t\t\t\t\t\t# number of spatial dimensions of the input data\n",
    "                 n_conv_per_depth=2,\t\t\t\t# number of convolutions per layer\n",
    "                 activation='ReLU',\t\t\t\t# activation function used in convolutional layers\n",
    "                 norm_type=NormType.Batch,\n",
    "                 dropout=0.0,\n",
    "                 pool=MaxPool,\n",
    "                 pool_size=2,\n",
    "                 residual=False,\n",
    "                 prob_out=False,\n",
    "                 eps_scale=1e-3,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        last_activation = getattr(F, f\"{activation.lower()}\") if last_activation == None else getattr(\n",
    "            F, f\"{last_activation.lower()}\")\n",
    "        activation = getattr(nn, f\"{activation}\")\n",
    "        attributesFromDict(locals())\t\t# stores all the input parameters in self\n",
    "\n",
    "        self.net_recurse = _Net_recurse(depth, mult_chan, in_channels, kernel_size, ndim,\n",
    "                                        n_conv_per_depth, activation, norm_type, dropout, pool, pool_size)\n",
    "        self.conv_out = ConvLayer(mult_chan*in_channels, out_channels, ndim=ndim,\n",
    "                                  ks=kernel_size, norm_type=None, act_cls=None, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_rec = self.net_recurse(x)\n",
    "        final = self.conv_out(x_rec)\n",
    "\n",
    "        if self.residual:\n",
    "            if not (self.out_channels == self.in_channels):\n",
    "                raise ValueError(\n",
    "                    \"number of input and output channels must be the same for a residual net.\")\n",
    "            final = final + x\n",
    "        final = self.last_activation(final)\n",
    "\n",
    "        if self.prob_out:\n",
    "            scale = ConvLayer(self.out_channels, self.out_channels,\n",
    "                              ndim=self.ndim, ks=1, norm_type=None, act_cls=nn.Softplus)(x_rec)\n",
    "            scale = Lambda(lambda x: x+np.float32(self.eps_scale))(scale)\n",
    "            final = torch_cat((final, scale), 1)\n",
    "\n",
    "        return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/models.py#L125){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### UNet\n",
       "\n",
       ">      UNet (depth=4, mult_chan=32, in_channels=1, out_channels=1,\n",
       ">            last_activation=None, kernel_size=3, ndim=2, n_conv_per_depth=2,\n",
       ">            activation='ReLU', norm_type=<NormType.Batch: 1>, dropout=0.0,\n",
       ">            pool=<function MaxPool>, pool_size=2, residual=False,\n",
       ">            prob_out=False, eps_scale=0.001)\n",
       "\n",
       "Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| depth | int | 4 | depth of the UNet network |\n",
       "| mult_chan | int | 32 | number of filters at first layer |\n",
       "| in_channels | int | 1 | number of input channels |\n",
       "| out_channels | int | 1 | number of output channels |\n",
       "| last_activation | NoneType | None | last activation before final result |\n",
       "| kernel_size | int | 3 | kernel size of convolutional layers |\n",
       "| ndim | int | 2 | number of spatial dimensions of the input data |\n",
       "| n_conv_per_depth | int | 2 | number of convolutions per layer |\n",
       "| activation | str | ReLU | activation function used in convolutional layers |\n",
       "| norm_type | NormType | NormType.Batch |  |\n",
       "| dropout | float | 0.0 |  |\n",
       "| pool | function | MaxPool |  |\n",
       "| pool_size | int | 2 |  |\n",
       "| residual | bool | False |  |\n",
       "| prob_out | bool | False |  |\n",
       "| eps_scale | float | 0.001 |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/bmandracchia/Noise2Model/blob/main/Noise2Model/models.py#L125){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### UNet\n",
       "\n",
       ">      UNet (depth=4, mult_chan=32, in_channels=1, out_channels=1,\n",
       ">            last_activation=None, kernel_size=3, ndim=2, n_conv_per_depth=2,\n",
       ">            activation='ReLU', norm_type=<NormType.Batch: 1>, dropout=0.0,\n",
       ">            pool=<function MaxPool>, pool_size=2, residual=False,\n",
       ">            prob_out=False, eps_scale=0.001)\n",
       "\n",
       "Base class for all neural network modules.\n",
       "\n",
       "Your models should also subclass this class.\n",
       "\n",
       "Modules can also contain other Modules, allowing to nest them in\n",
       "a tree structure. You can assign the submodules as regular attributes::\n",
       "\n",
       "    import torch.nn as nn\n",
       "    import torch.nn.functional as F\n",
       "\n",
       "    class Model(nn.Module):\n",
       "        def __init__(self):\n",
       "            super().__init__()\n",
       "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
       "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
       "\n",
       "        def forward(self, x):\n",
       "            x = F.relu(self.conv1(x))\n",
       "            return F.relu(self.conv2(x))\n",
       "\n",
       "Submodules assigned in this way will be registered, and will have their\n",
       "parameters converted too when you call :meth:`to`, etc.\n",
       "\n",
       ".. note::\n",
       "    As per the example above, an ``__init__()`` call to the parent class\n",
       "    must be made before assignment on the child.\n",
       "\n",
       ":ivar training: Boolean represents whether this module is in training or\n",
       "                evaluation mode.\n",
       ":vartype training: bool\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| depth | int | 4 | depth of the UNet network |\n",
       "| mult_chan | int | 32 | number of filters at first layer |\n",
       "| in_channels | int | 1 | number of input channels |\n",
       "| out_channels | int | 1 | number of output channels |\n",
       "| last_activation | NoneType | None | last activation before final result |\n",
       "| kernel_size | int | 3 | kernel size of convolutional layers |\n",
       "| ndim | int | 2 | number of spatial dimensions of the input data |\n",
       "| n_conv_per_depth | int | 2 | number of convolutions per layer |\n",
       "| activation | str | ReLU | activation function used in convolutional layers |\n",
       "| norm_type | NormType | NormType.Batch |  |\n",
       "| dropout | float | 0.0 |  |\n",
       "| pool | function | MaxPool |  |\n",
       "| pool_size | int | 2 |  |\n",
       "| residual | bool | False |  |\n",
       "| prob_out | bool | False |  |\n",
       "| eps_scale | float | 0.001 |  |"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(UNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[_Net_recurse(\n",
      "  (sub_conv_more): ConvLayer(\n",
      "    (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (sub_u): Sequential(\n",
      "    (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (1): _Net_recurse(\n",
      "      (sub_conv_more): ConvLayer(\n",
      "        (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "  )\n",
      "  (sub_conv_less): ConvLayer(\n",
      "    (0): Conv3d(96, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "), ConvLayer(\n",
      "  (0): Conv3d(32, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "x = torch_randn(16, 1, 32, 64, 64)\n",
    "xdim = len(x.shape)-2\n",
    "\n",
    "tst = UNet(depth=1, ndim=xdim, n_conv_per_depth=1, residual=True)\n",
    "mods = list(tst.children())\n",
    "print(mods)\n",
    "test_eq(tst(x).shape, [16, 1, 32, 64, 64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"A general-purpose residual block. Works only with 1-dim inputs.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 features,\n",
    "                 context_features,\n",
    "                 activation=F.relu,\n",
    "                 dropout_probability=0.,\n",
    "                 use_batch_norm=False,\n",
    "                 zero_initialization=True):\n",
    "        super().__init__()\n",
    "        self.activation = activation\n",
    "\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        if use_batch_norm:\n",
    "            self.batch_norm_layers = nn.ModuleList([\n",
    "                #nn.BatchNorm1d(features, eps=1e-3, track_running_stats=False)\n",
    "                nn.BatchNorm1d(features, eps=1e-3)\n",
    "                for _ in range(2)\n",
    "            ])\n",
    "        if context_features is not None:\n",
    "            self.context_layer = nn.Linear(context_features, features)\n",
    "        self.linear_layers = nn.ModuleList([\n",
    "            nn.Linear(features, features)\n",
    "            for _ in range(2)\n",
    "        ])\n",
    "        if dropout_probability > 0.:\n",
    "            self.dropout = nn.Dropout(p=dropout_probability)\n",
    "        else:\n",
    "            self.dropout = None\n",
    "        if zero_initialization:\n",
    "            init.uniform_(self.linear_layers[-1].weight, -1e-3, 1e-3)\n",
    "            init.uniform_(self.linear_layers[-1].bias, -1e-3, 1e-3)\n",
    "\n",
    "    def forward(self, inputs, context=None):\n",
    "        temps = inputs\n",
    "        if self.use_batch_norm:\n",
    "            temps = self.batch_norm_layers[0](temps)\n",
    "        temps = self.activation(temps)\n",
    "        temps = self.linear_layers[0](temps)\n",
    "        if self.use_batch_norm:\n",
    "            temps = self.batch_norm_layers[1](temps)\n",
    "        temps = self.activation(temps)\n",
    "        if self.dropout:\n",
    "            temps = self.dropout(temps)\n",
    "        temps = self.linear_layers[1](temps)\n",
    "        if context is not None:\n",
    "            temps = F.glu(\n",
    "                torch.cat(\n",
    "                    (temps, self.context_layer(context)),\n",
    "                    dim=1\n",
    "                ),\n",
    "                dim=1\n",
    "            )\n",
    "        return inputs + temps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class ResidualNet(nn.Module):\n",
    "    \"\"\"A general-purpose residual network. Works only with 1-dim inputs.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_features,\n",
    "                 out_features,\n",
    "                 hidden_features,\n",
    "                 context_features=None,\n",
    "                 num_blocks=2,\n",
    "                 activation=F.relu,\n",
    "                 dropout_probability=0.,\n",
    "                 use_batch_norm=False):\n",
    "        super().__init__()\n",
    "        self.hidden_features = hidden_features\n",
    "        self.context_features = context_features\n",
    "        if context_features is not None:\n",
    "            self.initial_layer = nn.Linear(in_features + context_features, hidden_features)\n",
    "        else:\n",
    "            self.initial_layer = nn.Linear(in_features, hidden_features)\n",
    "        self.blocks = nn.ModuleList([\n",
    "            ResidualBlock(\n",
    "                features=hidden_features,\n",
    "                context_features=context_features,\n",
    "                activation=activation,\n",
    "                dropout_probability=dropout_probability,\n",
    "                use_batch_norm=use_batch_norm,\n",
    "            ) for _ in range(num_blocks)\n",
    "        ])\n",
    "        self.final_layer = nn.Linear(hidden_features, out_features)\n",
    "\n",
    "    def forward(self, inputs, context=None):\n",
    "        if context is None:\n",
    "            temps = self.initial_layer(inputs)\n",
    "        else:\n",
    "            temps = self.initial_layer(\n",
    "                torch.cat((inputs, context), dim=1)\n",
    "            )\n",
    "        for block in self.blocks:\n",
    "            temps = block(temps, context=context)\n",
    "        outputs = self.final_layer(temps)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
