{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "> models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mmerlin                    \u001b[m  Fri Jun 14 20:51:39 2024  \u001b[1m\u001b[30m525.147.05\u001b[m\n",
      "\u001b[36m[0]\u001b[m \u001b[34mNVIDIA GeForce RTX 4090\u001b[m |\u001b[31m 48°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    6\u001b[m / \u001b[33m24564\u001b[m MB |\n",
      "\u001b[36m[1]\u001b[m \u001b[34mNVIDIA GeForce RTX 4090\u001b[m |\u001b[31m 48°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m  229\u001b[m / \u001b[33m24564\u001b[m MB |\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import os\n",
    "\n",
    "from typing import Iterator\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "from Noise2Model.layers import get_flow_layer\n",
    "from Noise2Model.networks import get_network_class, UNet, DnCNN\n",
    "from Noise2Model.utils import StandardNormal, attributesFromDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# from torch import randn as torch_randn\n",
    "# from fastai.vision.all import test_eq\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "model_class_dict = {}\n",
    "\n",
    "def regist_model(model_class):\n",
    "    model_name = model_class.__name__.lower()\n",
    "    assert not model_name in model_class_dict, 'there is already registered model: %s in model_class_dict.' % model_name\n",
    "    model_class_dict[model_name] = model_class\n",
    "\n",
    "    return model_class\n",
    "\n",
    "def get_model_class(model_name:str):\n",
    "    model_name = model_name.lower()\n",
    "    return model_class_dict[model_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMFlow\n",
    "\n",
    "### Noise Modeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@regist_model\n",
    "class NMFlow(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_ch=1,\n",
    "        ch_exp_coef = 1.,\n",
    "        width_exp_coef = 2.,\n",
    "        num_bits=16,\n",
    "        conv_net_feats=16,\n",
    "        pre_arch=\"UD\",\n",
    "        arch=\"NE|SAL|SDL|CL2|SAL|SDL|CL2\",\n",
    "        device='cpu',\n",
    "        codes=None\n",
    "    ):\n",
    "        super(NMFlow, self).__init__()\n",
    "        attributesFromDict(locals()) # stores all the input parameters in self\n",
    "        \n",
    "        if codes==None:\n",
    "            self.codes= {\n",
    "                'camera': torch.tensor([2], dtype=torch.float32).to(device)\n",
    "            }\n",
    "        \n",
    "        self.pre_bijectors = list()\n",
    "        pre_arch_lyrs = pre_arch.split('|')\n",
    "        for lyr in pre_arch_lyrs:\n",
    "            self.pre_bijectors.append(self.get_flow_layer(lyr))\n",
    "        self.pre_bijectors = nn.Sequential(*self.pre_bijectors)\n",
    "\n",
    "        self.bijectors = list()\n",
    "        arch_lyrs = arch.split('|')\n",
    "        for lyr in arch_lyrs:\n",
    "            self.bijectors.append(self.get_flow_layer(lyr))\n",
    "        self.bijectors = nn.Sequential(*self.bijectors)\n",
    "        self.dist = StandardNormal()\n",
    "\n",
    "    def internal_channels(self):\n",
    "        return int(self.in_ch * self.ch_exp_coef)\n",
    "    \n",
    "    def internal_widths(self):\n",
    "        return int(self.in_ch * self.width_exp_coef)\n",
    "\n",
    "    def get_flow_layer(self, name):\n",
    "        match name:\n",
    "            case \"UD\":\n",
    "                return get_flow_layer(\"UniformDequantization\")(device=self.device, num_bits=self.num_bits)\n",
    "            \n",
    "            case \"NE\":\n",
    "                return get_flow_layer(\"NoiseExtraction\")(device=self.device)    \n",
    "            \n",
    "            case \"CL2\":\n",
    "                return get_flow_layer(\"ConditionalLinearExp2\")(\n",
    "                    in_ch=self.internal_channels(),\n",
    "                    device=self.device,\n",
    "                    codes=self.codes,\n",
    "                )\n",
    "                \n",
    "            case \"SDL\":\n",
    "                return get_flow_layer(\"SignalDependentConditionalLinear\")(\n",
    "                    meta_encoder=lambda in_features, out_features: get_network_class(\"ResidualNet\")(\n",
    "                        in_features=in_features,\n",
    "                        out_features=out_features,\n",
    "                        hidden_features=5,\n",
    "                        num_blocks=3,\n",
    "                        use_batch_norm=True,\n",
    "                        dropout_probability=0.0\n",
    "                    ),\n",
    "                    scale_and_bias=lambda in_features, out_features: get_flow_layer(\"PointwiseConvs\")(\n",
    "                        in_features=in_features,\n",
    "                        out_features=out_features,\n",
    "                        feats=self.conv_net_feats\n",
    "                    ),\n",
    "                    in_ch=self.internal_channels(),\n",
    "                    device=self.device,\n",
    "                    codes=self.codes,\n",
    "                )\n",
    "                \n",
    "            case \"SAL\":\n",
    "                return get_flow_layer(\"StructureAwareConditionalLinearLayer\")(\n",
    "                    meta_encoder=lambda in_features, out_features: get_network_class(\"ResidualNet\")(\n",
    "                        in_features=in_features,\n",
    "                        out_features=out_features,\n",
    "                        hidden_features=5,\n",
    "                        num_blocks=3,\n",
    "                        use_batch_norm=True,\n",
    "                        dropout_probability=0.0\n",
    "                    ),\n",
    "                    structure_encoder=lambda in_features, out_features: get_flow_layer(\"SpatialConvs\")(\n",
    "                        in_features=in_features,\n",
    "                        out_features=out_features,\n",
    "                        receptive_field=9,\n",
    "                        feats=self.conv_net_feats\n",
    "                    ),\n",
    "                    in_ch=self.internal_channels(),\n",
    "                    codes=self.codes,\n",
    "                    device=self.device\n",
    "                )\n",
    "            \n",
    "            case _: \n",
    "                assert False, f\"Invalid layer name : {name}\"\n",
    "\n",
    "    def forward(self, noisy, clean, kwargs=dict()):\n",
    "        x = noisy\n",
    "        kwargs['clean'] = clean.clone()\n",
    "\n",
    "        objectives = 0.\n",
    "        for bijector in self.pre_bijectors:\n",
    "            if isinstance(bijector, get_flow_layer(\"UniformDequantization\")):\n",
    "                kwargs['clean'], _ = bijector._forward_and_log_det_jacobian(kwargs['clean'])\n",
    "\n",
    "            x, ldj = bijector._forward_and_log_det_jacobian(x, **kwargs)\n",
    "            objectives += ldj\n",
    "\n",
    "        for bijector in self.bijectors:\n",
    "            x, ldj = bijector._forward_and_log_det_jacobian(x, **kwargs)\n",
    "            objectives += ldj\n",
    "        return x, objectives\n",
    "\n",
    "    def sample(self, kwargs=dict()):\n",
    "        for bijector in self.pre_bijectors:\n",
    "            if isinstance(bijector, get_flow_layer(\"UniformDequantization\")):\n",
    "                kwargs['clean'], _ = bijector._forward_and_log_det_jacobian(kwargs['clean'], **kwargs)\n",
    "\n",
    "        b,_,h,w = kwargs['clean'].shape\n",
    "        x = self.dist.sample((b,self.internal_channels(),h,w))\n",
    "        for bijector in reversed(self.bijectors):\n",
    "            x = bijector._inverse(x, **kwargs)\n",
    "\n",
    "        for bijector in reversed(self.pre_bijectors):\n",
    "            if isinstance(bijector, get_flow_layer(\"UniformDequantization\")):\n",
    "                kwargs['clean'] = bijector._inverse(kwargs['clean'], **kwargs)\n",
    "            x = bijector._inverse(x, **kwargs)\n",
    "        x = torch.clip(x, 0, 2**self.num_bits)\n",
    "        return x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMFlow(\n",
       "  (pre_bijectors): Sequential(\n",
       "    (0): UniformDequantization()\n",
       "  )\n",
       "  (bijectors): Sequential(\n",
       "    (0): NoiseExtraction()\n",
       "    (1): StructureAwareConditionalLinearLayer(\n",
       "      (meta_encoder): ResidualNet(\n",
       "        (initial_layer): Linear(in_features=1, out_features=5, bias=True)\n",
       "        (blocks): ModuleList(\n",
       "          (0-2): 3 x ResidualBlock(\n",
       "            (batch_norm_layers): ModuleList(\n",
       "              (0-1): 2 x BatchNorm1d(5, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (linear_layers): ModuleList(\n",
       "              (0-1): 2 x Linear(in_features=5, out_features=5, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (final_layer): Linear(in_features=5, out_features=2, bias=True)\n",
       "      )\n",
       "      (structure_encoder): SpatialConvs(\n",
       "        (body): Sequential(\n",
       "          (conv_in): Conv2d(1, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu_in): ReLU(inplace=True)\n",
       "          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv_out): Conv2d(16, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (tanh_out): Tanh()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SignalDependentConditionalLinear(\n",
       "      (meta_encoder): ResidualNet(\n",
       "        (initial_layer): Linear(in_features=1, out_features=5, bias=True)\n",
       "        (blocks): ModuleList(\n",
       "          (0-2): 3 x ResidualBlock(\n",
       "            (batch_norm_layers): ModuleList(\n",
       "              (0-1): 2 x BatchNorm1d(5, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (linear_layers): ModuleList(\n",
       "              (0-1): 2 x Linear(in_features=5, out_features=5, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (final_layer): Linear(in_features=5, out_features=3, bias=True)\n",
       "      )\n",
       "      (scale_and_bias): PointwiseConvs(\n",
       "        (body): Sequential(\n",
       "          (0): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): Sequential(\n",
       "            (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "            (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "            (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (3): Sequential(\n",
       "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "            (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (4): Conv2d(16, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (5): Tanh()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): ConditionalLinearExp2()\n",
       "  )\n",
       "  (dist): StandardNormal()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NMFlow(arch=\"NE|SAL|SDL|CL2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class NMFlowDenoiser(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            denoiser,\n",
    "            kwargs_flow,\n",
    "            flow_pth_path,\n",
    "            num_bits=8,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        attributesFromDict(locals()) # stores all the input parameters in self\n",
    "\n",
    "        self.noise_model = get_model_class(\"NMFlow\")(**kwargs_flow)\n",
    "        self._load_checkpoint(self.noise_model, flow_pth_path)\n",
    "\n",
    "    def _load_checkpoint(self, module, path, name='noise_model'):\n",
    "        assert os.path.exists(path), f\"{path} is not exist.\"\n",
    "        pth = torch.load(path)\n",
    "        module.load_state_dict(pth['model_weight'][name])\n",
    "        module.eval()\n",
    "    \n",
    "    def parameters(self, recurse: bool = True) -> Iterator[Parameter]:\n",
    "        return self.denoiser.parameters(recurse) # the parameters of denoiser will be trained only.\n",
    "        \n",
    "    def forward(self, x, kwargs=dict()):\n",
    "        # x: clean image\n",
    "        x_scaled = x / (2**self.num_bits) # x_scaled: 0 ~ 1\n",
    "        x_scaled = x_scaled * (2**self.noise_model.num_bits) # x_scaled: 0 ~ noise model's max GL.\n",
    "        \n",
    "        kwargs['clean'] = x_scaled\n",
    "        with torch.no_grad(): \n",
    "            n = self.noise_model.sample(kwargs) # noisy image\n",
    "\n",
    "        n_scaled = n / (2**self.noise_model.num_bits) # n_scaled: 0 ~ 1\n",
    "        n_scaled = torch.clip(n_scaled, 0., 1.)\n",
    "        y = self.denoiser(n_scaled)\n",
    "        y = y * (2**self.num_bits) # y: 0 ~ denoiser's max GL.\n",
    "        return y\n",
    "    \n",
    "    def denoise(self, x, kwargs=None):\n",
    "        # x: noisy image\n",
    "        if kwargs is None or 'num_bits' not in kwargs: num_bits = self.num_bits\n",
    "        else: num_bits = kwargs['num_bits']\n",
    "\n",
    "        x_scaled = x / (2**num_bits) # x_scaled: 0 ~ 1\n",
    "        y =  self.denoiser(x_scaled) \n",
    "        y = torch.clip(y, 0., 1.)\n",
    "        y *= (2**num_bits) # x_scaled: 0 ~ denoiser's max GL.\n",
    "        return y\n",
    "    \n",
    "    def sample(self, x, kwargs=None):\n",
    "        # x: clean image\n",
    "        if kwargs is None or 'num_bits' not in kwargs: num_bits = self.num_bits\n",
    "        else: num_bits = kwargs['num_bits']\n",
    "\n",
    "        x_scaled = x / (2**num_bits) # x_scaled: 0 ~ 1\n",
    "        x_scaled = x_scaled * (2**self.noise_model.num_bits) # x_scaled: 0 ~ noise model's max GL.\n",
    "\n",
    "        kwargs = dict()\n",
    "        kwargs['clean'] = x_scaled\n",
    "        n = self.noise_model.sample(kwargs) # n: 0 ~ noise model's max GL.\n",
    "        \n",
    "        n_scaled = n / (2**self.noise_model.num_bits) # n_scaled: 0 ~ 1\n",
    "        n_scaled = n_scaled * (2**num_bits) # n_scaled: 0 ~ denoiser's max GL.\n",
    "        return n_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMFlowGAN\n",
    "\n",
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "debug mode"
    ]
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@regist_model\n",
    "class NMFlowGANGenerator(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        kwargs_unet,\n",
    "        kwargs_flow,\n",
    "    ):\n",
    "        super(NMFlowGANGenerator, self).__init__()\n",
    "        self._flow_init(\n",
    "            **kwargs_flow\n",
    "        )\n",
    "        self.generator = UNet(\n",
    "             **kwargs_unet\n",
    "        )  \n",
    "         \n",
    "    def _flow_init(\n",
    "        self,\n",
    "        in_ch=1,\n",
    "        ch_exp_coef = 1.,\n",
    "        width_exp_coef = 2.,\n",
    "        num_bits=16,\n",
    "        conv_net_feats=16,\n",
    "        pre_arch=\"UD\",\n",
    "        arch=\"NE|SAL|SDL|CL2|SAL|SDL|CL2\",\n",
    "        device='cpu',\n",
    "        codes=None\n",
    "    ):\n",
    "        attributesFromDict(locals()) # stores all the input parameters in self\n",
    "        \n",
    "        if codes==None:\n",
    "            self.codes= {\n",
    "                'camera': torch.tensor([2], dtype=torch.float32).to(device)\n",
    "            }\n",
    "        \n",
    "        self.pre_bijectors = list()\n",
    "        pre_arch_lyrs = pre_arch.split('|')\n",
    "        for lyr in pre_arch_lyrs:\n",
    "            self.pre_bijectors.append(self.get_flow_layer(lyr))\n",
    "        self.pre_bijectors = nn.Sequential(*self.pre_bijectors)\n",
    "\n",
    "        self.bijectors = list()\n",
    "        arch_lyrs = arch.split('|')\n",
    "        for lyr in arch_lyrs:\n",
    "            self.bijectors.append(self.get_flow_layer(lyr))\n",
    "        self.bijectors = nn.Sequential(*self.bijectors)\n",
    "        self.dist = StandardNormal()\n",
    "\n",
    "    def internal_channels(self):\n",
    "        return int(self.in_ch * self.ch_exp_coef)\n",
    "    \n",
    "    def internal_widths(self):\n",
    "        return int(self.in_ch * self.width_exp_coef)\n",
    "\n",
    "    def get_flow_layer(self, name):\n",
    "        match name:\n",
    "            case \"UD\":\n",
    "                return get_flow_layer(\"UniformDequantization\")(device=self.device, num_bits=self.num_bits)\n",
    "            \n",
    "            case \"NE\":\n",
    "                return get_flow_layer(\"NoiseExtraction\")(device=self.device)    \n",
    "            \n",
    "            case \"CL2\":\n",
    "                return get_flow_layer(\"ConditionalLinearExp2\")(\n",
    "                    in_ch=self.internal_channels(),\n",
    "                    device=self.device,\n",
    "                    codes=self.codes,\n",
    "                )\n",
    "                \n",
    "            case \"SDL\":\n",
    "                return get_flow_layer(\"SignalDependentConditionalLinear\")(\n",
    "                    meta_encoder=lambda in_features, out_features: get_network_class(\"ResidualNet\")(\n",
    "                        in_features=in_features,\n",
    "                        out_features=out_features,\n",
    "                        hidden_features=5,\n",
    "                        num_blocks=3,\n",
    "                        use_batch_norm=True,\n",
    "                        dropout_probability=0.0\n",
    "                    ),\n",
    "                    scale_and_bias=lambda in_features, out_features: get_flow_layer(\"PointwiseConvs\")(\n",
    "                        in_features=in_features,\n",
    "                        out_features=out_features,\n",
    "                        feats=self.conv_net_feats\n",
    "                    ),\n",
    "                    in_ch=self.internal_channels(),\n",
    "                    device=self.device,\n",
    "                    codes=self.codes,\n",
    "                )\n",
    "                \n",
    "            case \"SAL\":\n",
    "                return get_flow_layer(\"StructureAwareConditionalLinearLayer\")(\n",
    "                    meta_encoder=lambda in_features, out_features: get_network_class(\"ResidualNet\")(\n",
    "                        in_features=in_features,\n",
    "                        out_features=out_features,\n",
    "                        hidden_features=5,\n",
    "                        num_blocks=3,\n",
    "                        use_batch_norm=True,\n",
    "                        dropout_probability=0.0\n",
    "                    ),\n",
    "                    structure_encoder=lambda in_features, out_features: get_flow_layer(\"SpatialConvs\")(\n",
    "                        in_features=in_features,\n",
    "                        out_features=out_features,\n",
    "                        receptive_field=9,\n",
    "                        feats=self.conv_net_feats\n",
    "                    ),\n",
    "                    in_ch=self.internal_channels(),\n",
    "                    codes=self.codes,\n",
    "                    device=self.device\n",
    "                )\n",
    "            \n",
    "            case _: \n",
    "                assert False, f\"Invalid layer name : {name}\"\n",
    "\n",
    "    def _flow_forward(self, noisy, clean, kwargs=dict()):\n",
    "        x = noisy\n",
    "        kwargs['clean'] = clean.clone()\n",
    "\n",
    "        objectives = 0.\n",
    "        for bijector in self.pre_bijectors:\n",
    "            if isinstance(bijector, get_flow_layer(\"UniformDequantization\")):\n",
    "                kwargs['clean'], _ = bijector._forward_and_log_det_jacobian(kwargs['clean'])\n",
    "\n",
    "            x, ldj = bijector._forward_and_log_det_jacobian(x, **kwargs)\n",
    "            objectives += ldj\n",
    "\n",
    "        for bijector in self.bijectors:\n",
    "            x, ldj = bijector._forward_and_log_det_jacobian(x, **kwargs)\n",
    "            objectives += ldj\n",
    "        return x, objectives\n",
    "\n",
    "    def _flow_sample(self, kwargs=dict()):\n",
    "        for bijector in self.pre_bijectors:\n",
    "            if isinstance(bijector, get_flow_layer(\"UniformDequantization\")):\n",
    "                kwargs['clean'], _ = bijector._forward_and_log_det_jacobian(kwargs['clean'], **kwargs)\n",
    "\n",
    "        b,_,h,w = kwargs['clean'].shape\n",
    "        x = self.dist.sample((b,self.internal_channels(),h,w))\n",
    "        for bijector in reversed(self.bijectors):\n",
    "            x = bijector._inverse(x, **kwargs)\n",
    "\n",
    "        for bijector in reversed(self.pre_bijectors):\n",
    "            if isinstance(bijector, get_flow_layer(\"UniformDequantization\")):\n",
    "                kwargs['clean'] = bijector._inverse(kwargs['clean'], **kwargs)\n",
    "            x = bijector._inverse(x, **kwargs)\n",
    "        x = torch.clip(x, 0, 2**self.num_bits)\n",
    "        return x \n",
    "\n",
    "    def forward(self, noisy, clean, kwargs=dict()):\n",
    "        z, objectives = self._flow_forward(noisy, clean, kwargs)\n",
    "        kwargs['clean']=clean\n",
    "        with torch.no_grad():\n",
    "            x = self._flow_sample(kwargs) - kwargs['clean'] \n",
    "        x_scaled = x / (2**self.num_bits) # x_scaled: -1 ~ 1\n",
    "        y = (self.generator(x_scaled) * (2**self.num_bits) + kwargs['clean']).requires_grad_(True)\n",
    "        return z, objectives, y, x\n",
    "    \n",
    "    def sample(self, kwargs=dict()):\n",
    "        x = self._flow_sample(kwargs) - kwargs['clean'] # pixelwise noise\n",
    "        x_scaled = x / (2**self.num_bits) # x_scaled: -1 ~ 1\n",
    "        y = self.generator(x_scaled) * (2**self.num_bits) + kwargs['clean']\n",
    "        y = torch.clip(y, 0, 2**self.num_bits)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "test"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'depth': 1}\n"
     ]
    }
   ],
   "source": [
    "kwargs_unet = {\n",
    "        'depth': 1,\n",
    "}\n",
    "print(kwargs_unet)\n",
    "model = NMFlowGANGenerator(kwargs_unet,dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "test"
    ]
   },
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "noisy = torch.randint(256,[5, 1, 2, 2])\n",
    "clean = torch.randint(256,[5, 1, 2, 2])\n",
    "kwargs = dict()\n",
    "kwargs['camera'] = torch.tensor([2], dtype=torch.float32, device=device)\n",
    "\n",
    "output = model.forward(noisy,clean, kwargs=kwargs)\n",
    "assert len(output) == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@regist_model\n",
    "class NMFlowGANCritic(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_ch=1,\n",
    "            nc=64,\n",
    "            num_bits=8\n",
    "    ):\n",
    "        super(NMFlowGANCritic, self).__init__()\n",
    "        self.num_bits = num_bits\n",
    "        self.critic = Discriminator_96(in_ch, nc)\n",
    "\n",
    "    def forward(self, x):\n",
    "         x_scaled = x / (2**self.num_bits)\n",
    "         return self.critic(x_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class Discriminator_96(nn.Module):\n",
    "    \"\"\"Discriminator with 96x96 input, refer to Kai Zhang, https://github.com/cszn/KAIR\"\"\"\n",
    "    def __init__(self, in_nc=3, nc=64):\n",
    "        super(Discriminator_96, self).__init__()\n",
    "        conv0 = nn.Conv2d(in_nc, nc, kernel_size=7, padding=3)\n",
    "        conv1 = self._get_basic_module(nc, nc, kernel_size=4, stride=2)\n",
    "        # 48, 64\n",
    "        conv2 = self._get_basic_module(nc, nc*2, kernel_size=3, stride=1)\n",
    "        conv3 = self._get_basic_module(nc*2, nc*2, kernel_size=4, stride=2)\n",
    "        # 24, 128\n",
    "        conv4 = self._get_basic_module(nc*2, nc*4, kernel_size=3, stride=1)\n",
    "        conv5 = self._get_basic_module(nc*4, nc*4, kernel_size=4, stride=2)\n",
    "        # 12, 256\n",
    "        conv6 = self._get_basic_module(nc*4, nc*8, kernel_size=3, stride=1)\n",
    "        conv7 = self._get_basic_module(nc*8, nc*8, kernel_size=4, stride=2)\n",
    "        # 6, 512\n",
    "        conv8 = self._get_basic_module(nc*8, nc*8, kernel_size=3, stride=1)\n",
    "        conv9 = self._get_basic_module(nc*8, nc*8, kernel_size=4, stride=2)\n",
    "        # 3, 512\n",
    "        self.features = nn.Sequential(*[conv0, conv1, conv2, conv3, conv4,\n",
    "                                     conv5, conv6, conv7, conv8, conv9])\n",
    "\n",
    "        # classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 3 * 3, 100), nn.LeakyReLU(0.2, True), nn.Linear(100, 1))\n",
    "\n",
    "    def _get_basic_module(self, in_ch, out_ch, kernel_size=1, stride=1, padding=1, negative_slope=0.2):\n",
    "            return nn.Sequential(\n",
    "                    nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "                    nn.InstanceNorm2d(out_ch, affine=True), #batch normalization?\n",
    "                    nn.LeakyReLU(negative_slope, inplace=True)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN Denoiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class NMFlowGANDenoiser(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            denoiser,\n",
    "            kwargs_flow,\n",
    "            kwargs_unet,\n",
    "            pretrained_path,\n",
    "            num_bits=8,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.denoiser = denoiser\n",
    "        self.kwargs_flow = kwargs_flow\n",
    "        self.pretrained_path = pretrained_path\n",
    "        self.num_bits = num_bits\n",
    "        self.noise_model = get_model_class(\"NMFlowGANGenerator\")(kwargs_unet, kwargs_flow)\n",
    "        self._load_checkpoint(self.noise_model, self.pretrained_path)\n",
    "\n",
    "    def parameters(self, recurse: bool = True) -> Iterator[Parameter]:\n",
    "        return self.denoiser.parameters(recurse) # the parameters of denoiser will be trained only.\n",
    "    \n",
    "    def _load_checkpoint(self, module, path):\n",
    "        if not os.path.exists(path):\n",
    "            print(os.path.exists(path), f\"WARNING: {path} is not exist.\")\n",
    "            return\n",
    "        pth = torch.load(path)\n",
    "        module.load_state_dict(pth['model_weight']['generator'])\n",
    "        module.eval()\n",
    "        \n",
    "    def forward(self, x, kwargs=dict()):\n",
    "        # x: clean image\n",
    "        x_scaled = x / (2**self.num_bits) # x_scaled: 0 ~ 1\n",
    "        x_scaled = x_scaled * (2**self.noise_model.num_bits) # x_scaled: 0 ~ noise model's max GL.\n",
    "        \n",
    "        kwargs['clean'] = x_scaled\n",
    "        with torch.no_grad(): \n",
    "            n = self.noise_model.sample(kwargs) # noisy image\n",
    "\n",
    "        n_scaled = n / (2**self.noise_model.num_bits) # n_scaled: 0 ~ 1\n",
    "        n_scaled = torch.clip(n_scaled, 0., 1.)\n",
    "        y = self.denoiser(n_scaled)\n",
    "        y = y * (2**self.num_bits) # y: 0 ~ denoiser's max GL.\n",
    "        return y\n",
    "    \n",
    "    def denoise(self, x, kwargs=None):\n",
    "        # x: noisy image\n",
    "        if kwargs is None or 'num_bits' not in kwargs: num_bits = self.num_bits\n",
    "        else: num_bits = kwargs['num_bits']\n",
    "\n",
    "        x_scaled = x / (2**num_bits) # x_scaled: 0 ~ 1\n",
    "        y =  self.denoiser(x_scaled) \n",
    "        y = torch.clip(y, 0., 1.)\n",
    "        y *= (2**num_bits) # x_scaled: 0 ~ denoiser's max GL.\n",
    "        return y\n",
    "    \n",
    "    def sample(self, x, kwargs=None):\n",
    "        # x: clean image\n",
    "        if kwargs is None or 'num_bits' not in kwargs: num_bits = self.num_bits\n",
    "        else: num_bits = kwargs['num_bits']\n",
    "\n",
    "        x_scaled = x / (2**num_bits) # x_scaled: 0 ~ 1\n",
    "        x_scaled = x_scaled * (2**self.noise_model.num_bits) # x_scaled: 0 ~ noise model's max GL.\n",
    "\n",
    "        kwargs = dict()\n",
    "        kwargs['clean'] = x_scaled\n",
    "        n = self.noise_model.sample(kwargs) # n: 0 ~ noise model's max GL.\n",
    "        \n",
    "        n_scaled = n / (2**self.noise_model.num_bits) # n_scaled: 0 ~ 1\n",
    "        n_scaled = torch.clip(n_scaled, 0., 1.)\n",
    "        n_scaled = n_scaled * (2**num_bits) # n_scaled: 0 ~ denoiser's max GL.\n",
    "        return n_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@regist_model\n",
    "class DnCNNFlowGAN(NMFlowGANDenoiser):\n",
    "    def __init__(\n",
    "        self,\n",
    "        kwargs_dncnn,\n",
    "        kwargs_unet,\n",
    "        kwargs_flow,\n",
    "        pretrained_path,\n",
    "        num_bits=8\n",
    "        ):\n",
    "        super().__init__(\n",
    "            DnCNN(**kwargs_dncnn),\n",
    "            kwargs_flow,\n",
    "            kwargs_unet,\n",
    "            pretrained_path,\n",
    "            num_bits,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "n2m",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
