{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "> models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mmerlin                    \u001b[m  Fri Jun 14 21:04:04 2024  \u001b[1m\u001b[30m525.147.05\u001b[m\n",
      "\u001b[36m[0]\u001b[m \u001b[34mNVIDIA GeForce RTX 4090\u001b[m |\u001b[31m 48°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m  986\u001b[m / \u001b[33m24564\u001b[m MB |\n",
      "\u001b[36m[1]\u001b[m \u001b[34mNVIDIA GeForce RTX 4090\u001b[m |\u001b[31m 48°C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m  232\u001b[m / \u001b[33m24564\u001b[m MB |\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import os\n",
    "\n",
    "from typing import Iterator\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "from Noise2Model.layers import get_flow_layer\n",
    "from Noise2Model.networks import get_network_class, UNet, DnCNN\n",
    "from Noise2Model.utils import StandardNormal, attributesFromDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# from torch import randn as torch_randn\n",
    "# from fastai.vision.all import test_eq\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "model_class_dict = {}\n",
    "\n",
    "def regist_model(model_class):\n",
    "    model_name = model_class.__name__.lower()\n",
    "    assert not model_name in model_class_dict, 'there is already registered model: %s in model_class_dict.' % model_name\n",
    "    model_class_dict[model_name] = model_class\n",
    "\n",
    "    return model_class\n",
    "\n",
    "def get_model_class(model_name:str):\n",
    "    model_name = model_name.lower()\n",
    "    return model_class_dict[model_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMFlow\n",
    "\n",
    "### Noise Modeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@regist_model\n",
    "class NMFlow(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_ch=1,\n",
    "        ch_exp_coef = 1.,\n",
    "        width_exp_coef = 2.,\n",
    "        num_bits=16,\n",
    "        conv_net_feats=16,\n",
    "        pre_arch=\"UD\",\n",
    "        arch=\"NE|SAL|SDL|CL2|SAL|SDL|CL2\",\n",
    "        device='cpu',\n",
    "        codes=None\n",
    "    ):\n",
    "        super(NMFlow, self).__init__()\n",
    "        attributesFromDict(locals()) # stores all the input parameters in self\n",
    "        \n",
    "        if codes==None:\n",
    "            self.codes= {\n",
    "                'camera': torch.tensor([2], dtype=torch.float32).to(device)\n",
    "            }\n",
    "        \n",
    "        self.pre_bijectors = list()\n",
    "        pre_arch_lyrs = pre_arch.split('|')\n",
    "        for lyr in pre_arch_lyrs:\n",
    "            self.pre_bijectors.append(self.get_flow_layer(lyr))\n",
    "        self.pre_bijectors = nn.Sequential(*self.pre_bijectors)\n",
    "\n",
    "        self.bijectors = list()\n",
    "        arch_lyrs = arch.split('|')\n",
    "        for lyr in arch_lyrs:\n",
    "            self.bijectors.append(self.get_flow_layer(lyr))\n",
    "        self.bijectors = nn.Sequential(*self.bijectors)\n",
    "        self.dist = StandardNormal()\n",
    "\n",
    "    def internal_channels(self):\n",
    "        return int(self.in_ch * self.ch_exp_coef)\n",
    "    \n",
    "    def internal_widths(self):\n",
    "        return int(self.in_ch * self.width_exp_coef)\n",
    "\n",
    "    def get_flow_layer(self, name):\n",
    "        match name:\n",
    "            case \"UD\":\n",
    "                return get_flow_layer(\"UniformDequantization\")(device=self.device, num_bits=self.num_bits)\n",
    "            \n",
    "            case \"NE\":\n",
    "                return get_flow_layer(\"NoiseExtraction\")(device=self.device)    \n",
    "            \n",
    "            case \"CL2\":\n",
    "                return get_flow_layer(\"ConditionalLinearExp2\")(\n",
    "                    in_ch=self.internal_channels(),\n",
    "                    device=self.device,\n",
    "                    codes=self.codes,\n",
    "                )\n",
    "                \n",
    "            case \"SDL\":\n",
    "                return get_flow_layer(\"SignalDependentConditionalLinear\")(\n",
    "                    meta_encoder=lambda in_features, out_features: get_network_class(\"ResidualNet\")(\n",
    "                        in_features=in_features,\n",
    "                        out_features=out_features,\n",
    "                        hidden_features=5,\n",
    "                        num_blocks=3,\n",
    "                        use_batch_norm=True,\n",
    "                        dropout_probability=0.0\n",
    "                    ),\n",
    "                    scale_and_bias=lambda in_features, out_features: get_flow_layer(\"PointwiseConvs\")(\n",
    "                        in_features=in_features,\n",
    "                        out_features=out_features,\n",
    "                        feats=self.conv_net_feats\n",
    "                    ),\n",
    "                    in_ch=self.internal_channels(),\n",
    "                    device=self.device,\n",
    "                    codes=self.codes,\n",
    "                )\n",
    "                \n",
    "            case \"SAL\":\n",
    "                return get_flow_layer(\"StructureAwareConditionalLinearLayer\")(\n",
    "                    meta_encoder=lambda in_features, out_features: get_network_class(\"ResidualNet\")(\n",
    "                        in_features=in_features,\n",
    "                        out_features=out_features,\n",
    "                        hidden_features=5,\n",
    "                        num_blocks=3,\n",
    "                        use_batch_norm=True,\n",
    "                        dropout_probability=0.0\n",
    "                    ),\n",
    "                    structure_encoder=lambda in_features, out_features: get_flow_layer(\"SpatialConvs\")(\n",
    "                        in_features=in_features,\n",
    "                        out_features=out_features,\n",
    "                        receptive_field=9,\n",
    "                        feats=self.conv_net_feats\n",
    "                    ),\n",
    "                    in_ch=self.internal_channels(),\n",
    "                    codes=self.codes,\n",
    "                    device=self.device\n",
    "                )\n",
    "            \n",
    "            case _: \n",
    "                assert False, f\"Invalid layer name : {name}\"\n",
    "\n",
    "    def forward(self, noisy, clean, kwargs=dict()):\n",
    "        x = noisy\n",
    "        kwargs['clean'] = clean.clone()\n",
    "\n",
    "        objectives = 0.\n",
    "        for bijector in self.pre_bijectors:\n",
    "            if isinstance(bijector, get_flow_layer(\"UniformDequantization\")):\n",
    "                kwargs['clean'], _ = bijector._forward_and_log_det_jacobian(kwargs['clean'])\n",
    "\n",
    "            x, ldj = bijector._forward_and_log_det_jacobian(x, **kwargs)\n",
    "            objectives += ldj\n",
    "\n",
    "        for bijector in self.bijectors:\n",
    "            x, ldj = bijector._forward_and_log_det_jacobian(x, **kwargs)\n",
    "            objectives += ldj\n",
    "        return x, objectives\n",
    "\n",
    "    def sample(self, kwargs=dict()):\n",
    "        for bijector in self.pre_bijectors:\n",
    "            if isinstance(bijector, get_flow_layer(\"UniformDequantization\")):\n",
    "                kwargs['clean'], _ = bijector._forward_and_log_det_jacobian(kwargs['clean'], **kwargs)\n",
    "\n",
    "        b,_,h,w = kwargs['clean'].shape\n",
    "        x = self.dist.sample((b,self.internal_channels(),h,w))\n",
    "        for bijector in reversed(self.bijectors):\n",
    "            x = bijector._inverse(x, **kwargs)\n",
    "\n",
    "        for bijector in reversed(self.pre_bijectors):\n",
    "            if isinstance(bijector, get_flow_layer(\"UniformDequantization\")):\n",
    "                kwargs['clean'] = bijector._inverse(kwargs['clean'], **kwargs)\n",
    "            x = bijector._inverse(x, **kwargs)\n",
    "        x = torch.clip(x, 0, 2**self.num_bits)\n",
    "        return x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMFlow(\n",
       "  (pre_bijectors): Sequential(\n",
       "    (0): UniformDequantization()\n",
       "  )\n",
       "  (bijectors): Sequential(\n",
       "    (0): NoiseExtraction()\n",
       "    (1): StructureAwareConditionalLinearLayer(\n",
       "      (meta_encoder): ResidualNet(\n",
       "        (initial_layer): Linear(in_features=1, out_features=5, bias=True)\n",
       "        (blocks): ModuleList(\n",
       "          (0-2): 3 x ResidualBlock(\n",
       "            (batch_norm_layers): ModuleList(\n",
       "              (0-1): 2 x BatchNorm1d(5, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (linear_layers): ModuleList(\n",
       "              (0-1): 2 x Linear(in_features=5, out_features=5, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (final_layer): Linear(in_features=5, out_features=2, bias=True)\n",
       "      )\n",
       "      (structure_encoder): SpatialConvs(\n",
       "        (body): Sequential(\n",
       "          (conv_in): Conv2d(1, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu_in): ReLU(inplace=True)\n",
       "          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv_out): Conv2d(16, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (tanh_out): Tanh()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): SignalDependentConditionalLinear(\n",
       "      (meta_encoder): ResidualNet(\n",
       "        (initial_layer): Linear(in_features=1, out_features=5, bias=True)\n",
       "        (blocks): ModuleList(\n",
       "          (0-2): 3 x ResidualBlock(\n",
       "            (batch_norm_layers): ModuleList(\n",
       "              (0-1): 2 x BatchNorm1d(5, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "            (linear_layers): ModuleList(\n",
       "              (0-1): 2 x Linear(in_features=5, out_features=5, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (final_layer): Linear(in_features=5, out_features=3, bias=True)\n",
       "      )\n",
       "      (scale_and_bias): PointwiseConvs(\n",
       "        (body): Sequential(\n",
       "          (0): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): Sequential(\n",
       "            (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "            (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "            (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (3): Sequential(\n",
       "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "            (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "          )\n",
       "          (4): Conv2d(16, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (5): Tanh()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): ConditionalLinearExp2()\n",
       "  )\n",
       "  (dist): StandardNormal()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NMFlow(arch=\"NE|SAL|SDL|CL2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class NMFlowDenoiser(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            denoiser,\n",
    "            kwargs_flow,\n",
    "            flow_pth_path,\n",
    "            num_bits=8,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        attributesFromDict(locals()) # stores all the input parameters in self\n",
    "\n",
    "        self.noise_model = get_model_class(\"NMFlow\")(**kwargs_flow)\n",
    "        self._load_checkpoint(self.noise_model, flow_pth_path)\n",
    "\n",
    "    def _load_checkpoint(self, module, path, name='noise_model'):\n",
    "        assert os.path.exists(path), f\"{path} is not exist.\"\n",
    "        pth = torch.load(path)\n",
    "        module.load_state_dict(pth['model_weight'][name])\n",
    "        module.eval()\n",
    "    \n",
    "    def parameters(self, recurse: bool = True) -> Iterator[Parameter]:\n",
    "        return self.denoiser.parameters(recurse) # the parameters of denoiser will be trained only.\n",
    "        \n",
    "    def forward(self, x, kwargs=dict()):\n",
    "        # x: clean image\n",
    "        x_scaled = x / (2**self.num_bits) # x_scaled: 0 ~ 1\n",
    "        x_scaled = x_scaled * (2**self.noise_model.num_bits) # x_scaled: 0 ~ noise model's max GL.\n",
    "        \n",
    "        kwargs['clean'] = x_scaled\n",
    "        with torch.no_grad(): \n",
    "            n = self.noise_model.sample(kwargs) # noisy image\n",
    "\n",
    "        n_scaled = n / (2**self.noise_model.num_bits) # n_scaled: 0 ~ 1\n",
    "        n_scaled = torch.clip(n_scaled, 0., 1.)\n",
    "        y = self.denoiser(n_scaled)\n",
    "        y = y * (2**self.num_bits) # y: 0 ~ denoiser's max GL.\n",
    "        return y\n",
    "    \n",
    "    def denoise(self, x, kwargs=None):\n",
    "        # x: noisy image\n",
    "        if kwargs is None or 'num_bits' not in kwargs: num_bits = self.num_bits\n",
    "        else: num_bits = kwargs['num_bits']\n",
    "\n",
    "        x_scaled = x / (2**num_bits) # x_scaled: 0 ~ 1\n",
    "        y =  self.denoiser(x_scaled) \n",
    "        y = torch.clip(y, 0., 1.)\n",
    "        y *= (2**num_bits) # x_scaled: 0 ~ denoiser's max GL.\n",
    "        return y\n",
    "    \n",
    "    def sample(self, x, kwargs=None):\n",
    "        # x: clean image\n",
    "        if kwargs is None or 'num_bits' not in kwargs: num_bits = self.num_bits\n",
    "        else: num_bits = kwargs['num_bits']\n",
    "\n",
    "        x_scaled = x / (2**num_bits) # x_scaled: 0 ~ 1\n",
    "        x_scaled = x_scaled * (2**self.noise_model.num_bits) # x_scaled: 0 ~ noise model's max GL.\n",
    "\n",
    "        kwargs = dict()\n",
    "        kwargs['clean'] = x_scaled\n",
    "        n = self.noise_model.sample(kwargs) # n: 0 ~ noise model's max GL.\n",
    "        \n",
    "        n_scaled = n / (2**self.noise_model.num_bits) # n_scaled: 0 ~ 1\n",
    "        n_scaled = n_scaled * (2**num_bits) # n_scaled: 0 ~ denoiser's max GL.\n",
    "        return n_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMFlowGAN\n",
    "\n",
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@regist_model\n",
    "class NMFlowGANGenerator(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        kwargs_unet,\n",
    "        kwargs_flow,\n",
    "    ):\n",
    "        super(NMFlowGANGenerator, self).__init__()\n",
    "        self._flow_init(\n",
    "            **kwargs_flow\n",
    "        )\n",
    "        self.generator = UNet(\n",
    "             **kwargs_unet\n",
    "        )  \n",
    "         \n",
    "    def _flow_init(\n",
    "        self,\n",
    "        in_ch=1,\n",
    "        ch_exp_coef = 1.,\n",
    "        width_exp_coef = 2.,\n",
    "        num_bits=16,\n",
    "        conv_net_feats=16,\n",
    "        pre_arch=\"UD\",\n",
    "        arch=\"NE|SAL|SDL|CL2|SAL|SDL|CL2\",\n",
    "        device='cpu',\n",
    "        codes=None\n",
    "    ):\n",
    "        attributesFromDict(locals()) # stores all the input parameters in self\n",
    "        \n",
    "        if codes==None:\n",
    "            self.codes= {\n",
    "                'camera': torch.tensor([2], dtype=torch.float32).to(device)\n",
    "            }\n",
    "        \n",
    "        self.pre_bijectors = list()\n",
    "        pre_arch_lyrs = pre_arch.split('|')\n",
    "        for lyr in pre_arch_lyrs:\n",
    "            self.pre_bijectors.append(self.get_flow_layer(lyr))\n",
    "        self.pre_bijectors = nn.Sequential(*self.pre_bijectors)\n",
    "\n",
    "        self.bijectors = list()\n",
    "        arch_lyrs = arch.split('|')\n",
    "        for lyr in arch_lyrs:\n",
    "            self.bijectors.append(self.get_flow_layer(lyr))\n",
    "        self.bijectors = nn.Sequential(*self.bijectors)\n",
    "        self.dist = StandardNormal()\n",
    "\n",
    "    def internal_channels(self):\n",
    "        return int(self.in_ch * self.ch_exp_coef)\n",
    "    \n",
    "    def internal_widths(self):\n",
    "        return int(self.in_ch * self.width_exp_coef)\n",
    "\n",
    "    def get_flow_layer(self, name):\n",
    "        match name:\n",
    "            case \"UD\":\n",
    "                return get_flow_layer(\"UniformDequantization\")(device=self.device, num_bits=self.num_bits)\n",
    "            \n",
    "            case \"NE\":\n",
    "                return get_flow_layer(\"NoiseExtraction\")(device=self.device)    \n",
    "            \n",
    "            case \"CL2\":\n",
    "                return get_flow_layer(\"ConditionalLinearExp2\")(\n",
    "                    in_ch=self.internal_channels(),\n",
    "                    device=self.device,\n",
    "                    codes=self.codes,\n",
    "                )\n",
    "                \n",
    "            case \"SDL\":\n",
    "                return get_flow_layer(\"SignalDependentConditionalLinear\")(\n",
    "                    meta_encoder=lambda in_features, out_features: get_network_class(\"ResidualNet\")(\n",
    "                        in_features=in_features,\n",
    "                        out_features=out_features,\n",
    "                        hidden_features=5,\n",
    "                        num_blocks=3,\n",
    "                        use_batch_norm=True,\n",
    "                        dropout_probability=0.0\n",
    "                    ),\n",
    "                    scale_and_bias=lambda in_features, out_features: get_flow_layer(\"PointwiseConvs\")(\n",
    "                        in_features=in_features,\n",
    "                        out_features=out_features,\n",
    "                        feats=self.conv_net_feats\n",
    "                    ),\n",
    "                    in_ch=self.internal_channels(),\n",
    "                    device=self.device,\n",
    "                    codes=self.codes,\n",
    "                )\n",
    "                \n",
    "            case \"SAL\":\n",
    "                return get_flow_layer(\"StructureAwareConditionalLinearLayer\")(\n",
    "                    meta_encoder=lambda in_features, out_features: get_network_class(\"ResidualNet\")(\n",
    "                        in_features=in_features,\n",
    "                        out_features=out_features,\n",
    "                        hidden_features=5,\n",
    "                        num_blocks=3,\n",
    "                        use_batch_norm=True,\n",
    "                        dropout_probability=0.0\n",
    "                    ),\n",
    "                    structure_encoder=lambda in_features, out_features: get_flow_layer(\"SpatialConvs\")(\n",
    "                        in_features=in_features,\n",
    "                        out_features=out_features,\n",
    "                        receptive_field=9,\n",
    "                        feats=self.conv_net_feats\n",
    "                    ),\n",
    "                    in_ch=self.internal_channels(),\n",
    "                    codes=self.codes,\n",
    "                    device=self.device\n",
    "                )\n",
    "            \n",
    "            case _: \n",
    "                assert False, f\"Invalid layer name : {name}\"\n",
    "\n",
    "    def _flow_forward(self, noisy, clean, kwargs=dict()):\n",
    "        x = noisy\n",
    "        kwargs['clean'] = clean.clone()\n",
    "\n",
    "        objectives = 0.\n",
    "        for bijector in self.pre_bijectors:\n",
    "            if isinstance(bijector, get_flow_layer(\"UniformDequantization\")):\n",
    "                kwargs['clean'], _ = bijector._forward_and_log_det_jacobian(kwargs['clean'])\n",
    "\n",
    "            x, ldj = bijector._forward_and_log_det_jacobian(x, **kwargs)\n",
    "            objectives += ldj\n",
    "\n",
    "        for bijector in self.bijectors:\n",
    "            x, ldj = bijector._forward_and_log_det_jacobian(x, **kwargs)\n",
    "            objectives += ldj\n",
    "        return x, objectives\n",
    "\n",
    "    def _flow_sample(self, kwargs=dict()):\n",
    "        for bijector in self.pre_bijectors:\n",
    "            if isinstance(bijector, get_flow_layer(\"UniformDequantization\")):\n",
    "                kwargs['clean'], _ = bijector._forward_and_log_det_jacobian(kwargs['clean'], **kwargs)\n",
    "\n",
    "        b,_,h,w = kwargs['clean'].shape\n",
    "        x = self.dist.sample((b,self.internal_channels(),h,w))\n",
    "        for bijector in reversed(self.bijectors):\n",
    "            x = bijector._inverse(x, **kwargs)\n",
    "\n",
    "        for bijector in reversed(self.pre_bijectors):\n",
    "            if isinstance(bijector, get_flow_layer(\"UniformDequantization\")):\n",
    "                kwargs['clean'] = bijector._inverse(kwargs['clean'], **kwargs)\n",
    "            x = bijector._inverse(x, **kwargs)\n",
    "        x = torch.clip(x, 0, 2**self.num_bits)\n",
    "        return x \n",
    "\n",
    "    def forward(self, noisy, clean, kwargs=dict()):\n",
    "        z, objectives = self._flow_forward(noisy, clean, kwargs)\n",
    "        kwargs['clean']=clean\n",
    "        with torch.no_grad():\n",
    "            x = self._flow_sample(kwargs) - kwargs['clean'] \n",
    "        x_scaled = x / (2**self.num_bits) # x_scaled: -1 ~ 1\n",
    "        y = (self.generator(x_scaled) * (2**self.num_bits) + kwargs['clean']).requires_grad_(True)\n",
    "        return z, objectives, y, x\n",
    "    \n",
    "    def sample(self, kwargs=dict()):\n",
    "        x = self._flow_sample(kwargs) - kwargs['clean'] # pixelwise noise\n",
    "        x_scaled = x / (2**self.num_bits) # x_scaled: -1 ~ 1\n",
    "        y = self.generator(x_scaled) * (2**self.num_bits) + kwargs['clean']\n",
    "        y = torch.clip(y, 0, 2**self.num_bits)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "test"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'depth': 1}\n",
      "{'device': 'cuda'}\n"
     ]
    }
   ],
   "source": [
    "kwargs_unet = {\n",
    "        'depth': 1,\n",
    "}\n",
    "print(kwargs_unet)\n",
    "kwargs_flow = {\n",
    "        'device': 'cuda',\n",
    "}\n",
    "print(kwargs_flow)\n",
    "model = NMFlowGANGenerator(kwargs_unet,kwargs_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": [
     "test"
    ]
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m      4\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcamera\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m2\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39mkwargs_flow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 6\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy\u001b[49m\u001b[43m,\u001b[49m\u001b[43mclean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(output) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m\n",
      "Cell \u001b[0;32mIn[9], line 150\u001b[0m, in \u001b[0;36mNMFlowGANGenerator.forward\u001b[0;34m(self, noisy, clean, kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, noisy, clean, kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m()):\n\u001b[0;32m--> 150\u001b[0m     z, objectives \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flow_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclean\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mclean\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "Cell \u001b[0;32mIn[9], line 128\u001b[0m, in \u001b[0;36mNMFlowGANGenerator._flow_forward\u001b[0;34m(self, noisy, clean, kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     objectives \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ldj\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bijector \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbijectors:\n\u001b[0;32m--> 128\u001b[0m     x, ldj \u001b[38;5;241m=\u001b[39m \u001b[43mbijector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_and_log_det_jacobian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m     objectives \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ldj\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x, objectives\n",
      "File \u001b[0;32m~/Code/Noise2Model/Noise2Model/layers.py:643\u001b[0m, in \u001b[0;36mStructureAwareConditionalLinearLayer._forward_and_log_det_jacobian\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_and_log_det_jacobian\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    632\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;124;03m    Applies the forward transformation to the input tensor x and computes the log determinant of the Jacobian.\u001b[39;00m\n\u001b[1;32m    634\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;124;03m        tensor: The log determinant of the Jacobian of the transformation.\u001b[39;00m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 643\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    645\u001b[0m     log_scale \u001b[38;5;241m=\u001b[39m embedding[:, :\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_ch, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n\u001b[1;32m    646\u001b[0m     bias \u001b[38;5;241m=\u001b[39m embedding[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_ch:, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\n",
      "File \u001b[0;32m~/Code/Noise2Model/Noise2Model/layers.py:605\u001b[0m, in \u001b[0;36mStructureAwareConditionalLinearLayer._get_embeddings\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    602\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Generate embeddings using the meta encoder\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m meta_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmeta_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_computeOneHot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    606\u001b[0m meta_embedding \u001b[38;5;241m=\u001b[39m meta_embedding\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_ch \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    608\u001b[0m \u001b[38;5;66;03m# Generate structure embeddings and combine with meta embeddings\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/n2m/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/n2m/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/Noise2Model/Noise2Model/networks.py:448\u001b[0m, in \u001b[0;36mResidualNet.forward\u001b[0;34m(self, inputs, context)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 448\u001b[0m         temps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitial_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    450\u001b[0m         temps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_layer(\n\u001b[1;32m    451\u001b[0m             torch\u001b[38;5;241m.\u001b[39mcat((inputs, context), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    452\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/n2m/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/n2m/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/n2m/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "noisy = torch.randint(256,[5, 1, 2, 2])\n",
    "clean = torch.randint(256,[5, 1, 2, 2])\n",
    "kwargs = dict()\n",
    "kwargs['camera'] = torch.tensor([2], dtype=torch.float32, device=kwargs_flow['device'])\n",
    "\n",
    "output = model.forward(noisy,clean, kwargs=kwargs)\n",
    "assert len(output) == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@regist_model\n",
    "class NMFlowGANCritic(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_ch=1,\n",
    "            nc=64,\n",
    "            num_bits=8\n",
    "    ):\n",
    "        super(NMFlowGANCritic, self).__init__()\n",
    "        self.num_bits = num_bits\n",
    "        self.critic = Discriminator_96(in_ch, nc)\n",
    "\n",
    "    def forward(self, x):\n",
    "         x_scaled = x / (2**self.num_bits)\n",
    "         return self.critic(x_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class Discriminator_96(nn.Module):\n",
    "    \"\"\"Discriminator with 96x96 input, refer to Kai Zhang, https://github.com/cszn/KAIR\"\"\"\n",
    "    def __init__(self, in_nc=3, nc=64):\n",
    "        super(Discriminator_96, self).__init__()\n",
    "        conv0 = nn.Conv2d(in_nc, nc, kernel_size=7, padding=3)\n",
    "        conv1 = self._get_basic_module(nc, nc, kernel_size=4, stride=2)\n",
    "        # 48, 64\n",
    "        conv2 = self._get_basic_module(nc, nc*2, kernel_size=3, stride=1)\n",
    "        conv3 = self._get_basic_module(nc*2, nc*2, kernel_size=4, stride=2)\n",
    "        # 24, 128\n",
    "        conv4 = self._get_basic_module(nc*2, nc*4, kernel_size=3, stride=1)\n",
    "        conv5 = self._get_basic_module(nc*4, nc*4, kernel_size=4, stride=2)\n",
    "        # 12, 256\n",
    "        conv6 = self._get_basic_module(nc*4, nc*8, kernel_size=3, stride=1)\n",
    "        conv7 = self._get_basic_module(nc*8, nc*8, kernel_size=4, stride=2)\n",
    "        # 6, 512\n",
    "        conv8 = self._get_basic_module(nc*8, nc*8, kernel_size=3, stride=1)\n",
    "        conv9 = self._get_basic_module(nc*8, nc*8, kernel_size=4, stride=2)\n",
    "        # 3, 512\n",
    "        self.features = nn.Sequential(*[conv0, conv1, conv2, conv3, conv4,\n",
    "                                     conv5, conv6, conv7, conv8, conv9])\n",
    "\n",
    "        # classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 3 * 3, 100), nn.LeakyReLU(0.2, True), nn.Linear(100, 1))\n",
    "\n",
    "    def _get_basic_module(self, in_ch, out_ch, kernel_size=1, stride=1, padding=1, negative_slope=0.2):\n",
    "            return nn.Sequential(\n",
    "                    nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "                    nn.InstanceNorm2d(out_ch, affine=True), #batch normalization?\n",
    "                    nn.LeakyReLU(negative_slope, inplace=True)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN Denoiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class NMFlowGANDenoiser(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            denoiser,\n",
    "            kwargs_flow,\n",
    "            kwargs_unet,\n",
    "            pretrained_path,\n",
    "            num_bits=8,\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.denoiser = denoiser\n",
    "        self.kwargs_flow = kwargs_flow\n",
    "        self.pretrained_path = pretrained_path\n",
    "        self.num_bits = num_bits\n",
    "        self.noise_model = get_model_class(\"NMFlowGANGenerator\")(kwargs_unet, kwargs_flow)\n",
    "        self._load_checkpoint(self.noise_model, self.pretrained_path)\n",
    "\n",
    "    def parameters(self, recurse: bool = True) -> Iterator[Parameter]:\n",
    "        return self.denoiser.parameters(recurse) # the parameters of denoiser will be trained only.\n",
    "    \n",
    "    def _load_checkpoint(self, module, path):\n",
    "        if not os.path.exists(path):\n",
    "            print(os.path.exists(path), f\"WARNING: {path} is not exist.\")\n",
    "            return\n",
    "        pth = torch.load(path)\n",
    "        module.load_state_dict(pth['model_weight']['generator'])\n",
    "        module.eval()\n",
    "        \n",
    "    def forward(self, x, kwargs=dict()):\n",
    "        # x: clean image\n",
    "        x_scaled = x / (2**self.num_bits) # x_scaled: 0 ~ 1\n",
    "        x_scaled = x_scaled * (2**self.noise_model.num_bits) # x_scaled: 0 ~ noise model's max GL.\n",
    "        \n",
    "        kwargs['clean'] = x_scaled\n",
    "        with torch.no_grad(): \n",
    "            n = self.noise_model.sample(kwargs) # noisy image\n",
    "\n",
    "        n_scaled = n / (2**self.noise_model.num_bits) # n_scaled: 0 ~ 1\n",
    "        n_scaled = torch.clip(n_scaled, 0., 1.)\n",
    "        y = self.denoiser(n_scaled)\n",
    "        y = y * (2**self.num_bits) # y: 0 ~ denoiser's max GL.\n",
    "        return y\n",
    "    \n",
    "    def denoise(self, x, kwargs=None):\n",
    "        # x: noisy image\n",
    "        if kwargs is None or 'num_bits' not in kwargs: num_bits = self.num_bits\n",
    "        else: num_bits = kwargs['num_bits']\n",
    "\n",
    "        x_scaled = x / (2**num_bits) # x_scaled: 0 ~ 1\n",
    "        y =  self.denoiser(x_scaled) \n",
    "        y = torch.clip(y, 0., 1.)\n",
    "        y *= (2**num_bits) # x_scaled: 0 ~ denoiser's max GL.\n",
    "        return y\n",
    "    \n",
    "    def sample(self, x, kwargs=None):\n",
    "        # x: clean image\n",
    "        if kwargs is None or 'num_bits' not in kwargs: num_bits = self.num_bits\n",
    "        else: num_bits = kwargs['num_bits']\n",
    "\n",
    "        x_scaled = x / (2**num_bits) # x_scaled: 0 ~ 1\n",
    "        x_scaled = x_scaled * (2**self.noise_model.num_bits) # x_scaled: 0 ~ noise model's max GL.\n",
    "\n",
    "        kwargs = dict()\n",
    "        kwargs['clean'] = x_scaled\n",
    "        n = self.noise_model.sample(kwargs) # n: 0 ~ noise model's max GL.\n",
    "        \n",
    "        n_scaled = n / (2**self.noise_model.num_bits) # n_scaled: 0 ~ 1\n",
    "        n_scaled = torch.clip(n_scaled, 0., 1.)\n",
    "        n_scaled = n_scaled * (2**num_bits) # n_scaled: 0 ~ denoiser's max GL.\n",
    "        return n_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@regist_model\n",
    "class DnCNNFlowGAN(NMFlowGANDenoiser):\n",
    "    def __init__(\n",
    "        self,\n",
    "        kwargs_dncnn,\n",
    "        kwargs_unet,\n",
    "        kwargs_flow,\n",
    "        pretrained_path,\n",
    "        num_bits=8\n",
    "        ):\n",
    "        super().__init__(\n",
    "            DnCNN(**kwargs_dncnn),\n",
    "            kwargs_flow,\n",
    "            kwargs_unet,\n",
    "            pretrained_path,\n",
    "            num_bits,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "n2m",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
