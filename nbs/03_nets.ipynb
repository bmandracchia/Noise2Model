{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Networks\n",
    "\n",
    "> networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from fastai.vision.all import ConvLayer, Lambda, MaxPool, NormType, np\n",
    "from torch import cat as torch_cat\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F, init\n",
    "\n",
    "from Noise2Model.utils import attributesFromDict\n",
    "\n",
    "import os\n",
    "from importlib import import_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import randn as torch_randn\n",
    "from fastai.vision.all import test_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "network_class_dict = {}\n",
    "\n",
    "def regist_network(model_class):\n",
    "    model_name = model_class.__name__.lower()\n",
    "    assert not model_name in network_class_dict, 'there is already registered model: %s in network_class_dict.' % model_name\n",
    "    network_class_dict[model_name] = model_class\n",
    "\n",
    "    return model_class\n",
    "\n",
    "def get_network_class(model_name:str):\n",
    "    model_name = model_name.lower()\n",
    "    return network_class_dict[model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch_randn(16, 1, 32, 64, 64)\n",
    "xdim = len(x.shape)-2\n",
    "\n",
    "tst = ConvLayer(1, 1, ndim=xdim)\n",
    "test_eq(tst(x).shape, [16, 1, 32, 64, 64])\n",
    "tst = MaxPool(2, ndim=xdim)\n",
    "test_eq(tst(x).shape, [16, 1, 16, 32, 32])\n",
    "tst = Lambda(lambda x: x+np.float32(1e-3))\n",
    "test_eq(tst(x).shape, [16, 1, 32, 64, 64])\n",
    "test_eq(torch_cat((x, tst(x)), 1).shape, [16, 2, 32, 64, 64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DnCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@regist_network\n",
    "class DnCNN(nn.Module):\n",
    "    def __init__(self, channels, num_of_layers=18,features=64):\n",
    "        super(DnCNN, self).__init__()\n",
    "        kernel_size = 3\n",
    "        padding = kernel_size//2\n",
    "        self.bias=True\n",
    "        self.residual=True\n",
    "        layers = list()\n",
    "        layers.append(nn.Conv2d(in_channels=channels, out_channels=features, kernel_size=kernel_size, padding=padding, bias=self.bias))\n",
    "        layers.append(nn.ReLU(inplace=True))\n",
    "        for _ in range(num_of_layers-2):\n",
    "            layers.append(nn.Conv2d(in_channels=features, out_channels=features, kernel_size=kernel_size, padding=padding, bias=self.bias))\n",
    "            layers.append(nn.BatchNorm2d(features, momentum=0.9, eps=1e-04, affine=True))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "        layers.append(nn.Conv2d(in_channels=features, out_channels=channels, kernel_size=kernel_size, padding=padding, bias=self.bias))\n",
    "        self.dncnn = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, kwargs=None):\n",
    "        if self.residual:\n",
    "            out = x-self.dncnn(x)\n",
    "        else:\n",
    "            out = self.dncnn(x)\n",
    "        return out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# class MyDnCNN(nn.Module):\n",
    "#     def __init__(self, channels, num_of_layers=9, features=64, kernel_size=3):\n",
    "#         super(DnCNN, self).__init__()\n",
    "#         padding = 1\n",
    "#         layers = []\n",
    "#         layers.append(ConvLayer(channels, features,\n",
    "#                       ks=kernel_size, padding=padding, norm_type=None))\n",
    "#         for _ in range(num_of_layers-2):\n",
    "#             layers.append(ConvLayer(features, features,\n",
    "#                           ks=kernel_size, padding=padding))\n",
    "#         layers.append(nn.Conv2d(in_channels=features, out_channels=channels,\n",
    "#                       kernel_size=kernel_size, padding=padding, bias=False))\n",
    "#         self.dncnn = nn.Sequential(*layers)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         residual = self.dncnn(x)\n",
    "#         denoised = x - residual\n",
    "#         return denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DnCNN(\n",
      "  (dncnn): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (10): ReLU(inplace=True)\n",
      "    (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (28): ReLU(inplace=True)\n",
      "    (29): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (30): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (31): ReLU(inplace=True)\n",
      "    (32): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (33): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (34): ReLU(inplace=True)\n",
      "    (35): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (36): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (37): ReLU(inplace=True)\n",
      "    (38): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (39): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (40): ReLU(inplace=True)\n",
      "    (41): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (42): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (43): ReLU(inplace=True)\n",
      "    (44): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (45): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (46): ReLU(inplace=True)\n",
      "    (47): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (48): BatchNorm2d(64, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
      "    (49): ReLU(inplace=True)\n",
      "    (50): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "x = torch_randn(16, 1, 32, 64)\n",
    "\n",
    "tst = DnCNN(1)\n",
    "test_eq(tst(x).shape, [16, 1, 32, 64])\n",
    "print(tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def SubNetConv(ks=3,\n",
    "               stride=1,\n",
    "               padding=None,\n",
    "               bias=None,\n",
    "               ndim=2,\n",
    "               norm_type=NormType.Batch,\n",
    "               bn_1st=True,\n",
    "               act_cls=nn.ReLU,\n",
    "               transpose=False,\n",
    "               init='auto',\n",
    "               xtra=None,\n",
    "               bias_std=0.01,\n",
    "               dropout=0.0,\n",
    "               ):\n",
    "\n",
    "    def _conv(n_in, n_out, n_conv=1):\n",
    "        s = ConvLayer(n_in, n_out, ks=ks, stride=stride, padding=padding, bias=bias, ndim=ndim, norm_type=norm_type, bn_1st=bn_1st,\n",
    "                      act_cls=act_cls, transpose=transpose, init=init, xtra=xtra, bias_std=bias_std)\n",
    "        if dropout is not None and dropout > 0:\n",
    "            s = nn.Sequential(s, nn.Dropout(dropout))\n",
    "        for _ in range(n_conv-1):\n",
    "            t = ConvLayer(n_out, n_out, ks=ks, stride=stride, padding=padding, bias=bias, ndim=ndim, norm_type=norm_type, bn_1st=bn_1st,\n",
    "                          act_cls=act_cls, transpose=transpose, init=init, xtra=xtra, bias_std=bias_std)\n",
    "            if dropout is not None and dropout > 0:\n",
    "                t = nn.Sequential(t, nn.Dropout(dropout))\n",
    "            s = nn.Sequential(s, t)\n",
    "        return s\n",
    "\n",
    "    return _conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): ConvLayer(\n",
      "      (0): Conv3d(1, 2, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (1): BatchNorm3d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): ConvLayer(\n",
      "      (0): Conv3d(2, 2, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (1): BatchNorm3d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (1): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "ConvLayer(\n",
      "  (0): ConvTranspose3d(2, 1, kernel_size=(4, 4, 4), stride=(4, 4, 4), bias=False)\n",
      "  (1): BatchNorm3d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "x = torch_randn(16, 1, 32, 64, 64)\n",
    "xdim = len(x.shape)-2\n",
    "\n",
    "# reduce\n",
    "tst = SubNetConv(3, padding=1, stride=2, ndim=xdim,\n",
    "                 norm_type=NormType.Batch, dropout=.1)(1, 2, 2)\n",
    "y = tst(x)\n",
    "test_eq(y.shape, [16, 2, 8, 16, 16])\n",
    "print(tst)\n",
    "# upsample\n",
    "tst = SubNetConv(ks=4, padding=0, stride=4, ndim=xdim, norm_type=NormType.Batch,\n",
    "                 transpose=True)(2, 1)  # to double the size, the kernel cannot be odd\n",
    "test_eq(tst(y).shape, [16, 1, 32, 64, 64])\n",
    "print(tst)\n",
    "del y\n",
    "# ConvLayer(2*n_out_channels, n_out_channels, ks=ks, transpose=True, padding=(ks-1)//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class _Net_recurse(nn.Module):\n",
    "    def __init__(self,\n",
    "                 depth=4,\t\t\t\t\t\t# depth of the UNet network\n",
    "                 mult_chan=32,\t\t\t\t\t# number of filters at first layer\n",
    "                 in_channels=1,\t\t\t\t\t# number of input channels\n",
    "                 kernel_size=3,\t\t\t\t\t# kernel size of convolutional layers\n",
    "                 ndim=2,\t\t\t\t\t\t\t# number of spatial dimensions of the input data\n",
    "                 n_conv_per_depth=2,\t\t\t\t# number of convolutions per layer\n",
    "                 activation=nn.ReLU,\t\t\t\t# activation function used in convolutional layers\n",
    "                 norm_type=NormType.Batch,\n",
    "                 dropout=0.0,\n",
    "                 pool=MaxPool,\n",
    "                 pool_size=2,\n",
    "                 ):\n",
    "        \"\"\"Class for recursive definition of U-network.p\n",
    "\n",
    "        Parameters:\n",
    "        in_channels - (int) number of channels for input.\n",
    "        mult_chan - (int) factor to determine number of output channels\n",
    "        depth - (int) if 0, this subnet will only be convolutions that double the channel count.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Parameters\n",
    "        self.depth = depth\n",
    "        n_out = in_channels*mult_chan\n",
    "\n",
    "        # Layer types\n",
    "        Pooling = pool(ks=pool_size, ndim=ndim)\n",
    "        UpSample = nn.Upsample(scale_factor=pool_size, mode='nearest')\n",
    "        SubNet_Conv = SubNetConv(ks=kernel_size, stride=1, padding=None, bias=None, ndim=ndim, norm_type=norm_type,\n",
    "                                 bn_1st=True, act_cls=activation, transpose=False, dropout=dropout)\n",
    "\n",
    "        # Blocks\n",
    "        self.sub_conv_more = SubNet_Conv(in_channels, n_out, n_conv_per_depth)\n",
    "        if self.depth > 0:\n",
    "            in_channels = n_out\n",
    "            mult_chan = 2\n",
    "            depth = (self.depth - 1)\n",
    "            self.sub_u = nn.Sequential(Pooling,                                                         # layer reducing the image size (usually a pooling layer)\n",
    "                                       _Net_recurse(depth, mult_chan, in_channels, kernel_size,\n",
    "                                                    ndim, n_conv_per_depth, activation, norm_type,\n",
    "                                                    dropout, pool, pool_size),                          # lower unet level\n",
    "                                       # layer increasing the image size (usually an upsampling layer)\n",
    "                                       UpSample,\n",
    "                                       )\n",
    "            self.sub_conv_less = SubNet_Conv(3*n_out, n_out, n_conv_per_depth)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.depth == 0:\n",
    "            return self.sub_conv_more(x)\n",
    "        else:  # depth > 0\n",
    "            # convolutions with increasing number of channels\n",
    "            x_conv_more = self.sub_conv_more(x)\n",
    "            x_from_sub_u = self.sub_u(x_conv_more)\n",
    "            # concatenate the upsampled outputs of the lower level with the outputs of the next level in size\n",
    "            x_cat = torch_cat((x_from_sub_u, x_conv_more), 1)\n",
    "            # convolutions with decreasing number of channels\n",
    "            x_conv_less = self.sub_conv_less(x_cat)\n",
    "        return x_conv_less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@regist_network\n",
    "class MyUNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 depth=4,\t\t\t\t\t\t# depth of the UNet network\n",
    "                 mult_chan=32,\t\t\t\t\t# number of filters at first layer\n",
    "                 in_channels=1,\t\t\t\t\t# number of input channels\n",
    "                 out_channels=1,\t\t\t\t\t# number of output channels\n",
    "                 last_activation=None,\t\t\t# last activation before final result\n",
    "                 kernel_size=3,\t\t\t\t\t# kernel size of convolutional layers\n",
    "                 ndim=2,\t\t\t\t\t\t\t# number of spatial dimensions of the input data\n",
    "                 n_conv_per_depth=2,\t\t\t\t# number of convolutions per layer\n",
    "                 activation='ReLU',\t\t\t\t# activation function used in convolutional layers\n",
    "                 norm_type=NormType.Batch,\n",
    "                 dropout=0.0,\n",
    "                 pool=MaxPool,\n",
    "                 pool_size=2,\n",
    "                 residual=False,\n",
    "                 prob_out=False,\n",
    "                 eps_scale=1e-3,\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        last_activation = getattr(F, f\"{activation.lower()}\") if last_activation == None else getattr(\n",
    "            F, f\"{last_activation.lower()}\")\n",
    "        activation = getattr(nn, f\"{activation}\")\n",
    "        attributesFromDict(locals())\t\t# stores all the input parameters in self\n",
    "\n",
    "        self.net_recurse = _Net_recurse(depth, mult_chan, in_channels, kernel_size, ndim,\n",
    "                                        n_conv_per_depth, activation, norm_type, dropout, pool, pool_size)\n",
    "        self.conv_out = ConvLayer(mult_chan*in_channels, out_channels, ndim=ndim,\n",
    "                                  ks=kernel_size, norm_type=None, act_cls=None, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_rec = self.net_recurse(x)\n",
    "        final = self.conv_out(x_rec)\n",
    "\n",
    "        if self.residual:\n",
    "            if not (self.out_channels == self.in_channels):\n",
    "                raise ValueError(\n",
    "                    \"number of input and output channels must be the same for a residual net.\")\n",
    "            final = final + x\n",
    "        final = self.last_activation(final)\n",
    "\n",
    "        if self.prob_out:\n",
    "            scale = ConvLayer(self.out_channels, self.out_channels,\n",
    "                              ndim=self.ndim, ks=1, norm_type=None, act_cls=nn.Softplus)(x_rec)\n",
    "            scale = Lambda(lambda x: x+np.float32(self.eps_scale))(scale)\n",
    "            final = torch_cat((final, scale), 1)\n",
    "\n",
    "        return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(UNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[_Net_recurse(\n",
      "  (sub_conv_more): ConvLayer(\n",
      "    (0): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (sub_u): Sequential(\n",
      "    (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (1): _Net_recurse(\n",
      "      (sub_conv_more): ConvLayer(\n",
      "        (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (2): Upsample(scale_factor=2.0, mode='nearest')\n",
      "  )\n",
      "  (sub_conv_less): ConvLayer(\n",
      "    (0): Conv3d(96, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "    (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "), ConvLayer(\n",
      "  (0): Conv3d(32, 1, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "x = torch_randn(16, 1, 32, 64, 64)\n",
    "xdim = len(x.shape)-2\n",
    "\n",
    "tst = MyUNet(depth=1, ndim=xdim, n_conv_per_depth=1, residual=True)\n",
    "mods = list(tst.children())\n",
    "print(mods)\n",
    "test_eq(tst(x).shape, [16, 1, 32, 64, 64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@regist_network\n",
    "class UNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels=1,\n",
    "        n_classes=1,\n",
    "        depth=5,\n",
    "        wf=6,\n",
    "        padding=True,\n",
    "        batch_norm=True,\n",
    "        up_mode='upconv',\n",
    "        residual=True,\n",
    "        drop_p=0.15\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Implementation of\n",
    "        U-Net: Convolutional Networks for Biomedical Image Segmentation\n",
    "        (Ronneberger et al., 2015)\n",
    "        https://arxiv.org/abs/1505.04597\n",
    "        Using the default arguments will yield the exact version used\n",
    "        in the original paper\n",
    "        Args:\n",
    "            in_channels (int): number of input channels\n",
    "            n_classes (int): number of output channels\n",
    "            depth (int): depth of the network\n",
    "            wf (int): number of filters in the first layer is 2**wf\n",
    "            padding (bool): if True, apply padding such that the input shape\n",
    "                            is the same as the output.\n",
    "                            This may introduce artifacts\n",
    "            batch_norm (bool): Use BatchNorm after layers with an\n",
    "                               activation function\n",
    "            up_mode (str): one of 'upconv' or 'upsample'.\n",
    "                           'upconv' will use transposed convolutions for\n",
    "                           learned upsampling.\n",
    "                           'upsample' will use bilinear upsampling.\n",
    "        \"\"\"\n",
    "        super(UNet, self).__init__()\n",
    "        assert up_mode in ('upconv', 'upsample')\n",
    "        self.padding = padding\n",
    "        self.depth = depth\n",
    "        prev_channels = in_channels\n",
    "        self.residual = residual\n",
    "        self.n_classes = n_classes\n",
    "        self.down_path = nn.ModuleList()\n",
    "        for i in range(depth):\n",
    "            self.down_path.append(\n",
    "                UNetConvBlock(prev_channels, 2 ** (wf + i), padding, batch_norm, drop_p)\n",
    "            )\n",
    "            prev_channels = 2 ** (wf + i)\n",
    "\n",
    "        self.up_path = nn.ModuleList()\n",
    "        for i in reversed(range(depth - 1)):\n",
    "            self.up_path.append(\n",
    "                UNetUpBlock(prev_channels, 2 ** (wf + i), up_mode, padding, batch_norm)\n",
    "            )\n",
    "            prev_channels = 2 ** (wf + i)\n",
    "\n",
    "        self.last = nn.Conv2d(prev_channels, n_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x, kwargs=None):\n",
    "        x_in = x.clone()\n",
    "        blocks = []\n",
    "        for i, down in enumerate(self.down_path):\n",
    "            x = down(x)\n",
    "            if i != len(self.down_path) - 1:\n",
    "                blocks.append(x)\n",
    "                x = F.max_pool2d(x, 2)\n",
    "\n",
    "        for i, up in enumerate(self.up_path):\n",
    "            x = up(x, blocks[-i - 1])\n",
    "\n",
    "        if self.residual:\n",
    "            output = self.last(x) + x_in[:, -self.n_classes:, ...]\n",
    "        else:\n",
    "            output = self.last(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class UNetConvBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size, padding, batch_norm, drop_p=0.15):\n",
    "        super(UNetConvBlock, self).__init__()\n",
    "        block = []\n",
    "\n",
    "        block.append(nn.Conv2d(in_size, out_size, kernel_size=3, padding=int(padding)))\n",
    "        block.append(nn.ReLU())\n",
    "        if batch_norm:\n",
    "            block.append(nn.BatchNorm2d(out_size))\n",
    "\n",
    "        block.append(nn.Conv2d(out_size, out_size, kernel_size=3, padding=int(padding)))\n",
    "        block.append(nn.ReLU())\n",
    "        if drop_p > 1e-5:\n",
    "            block.append(nn.Dropout2d(p=drop_p))\n",
    "        if batch_norm:\n",
    "            block.append(nn.BatchNorm2d(out_size))\n",
    "\n",
    "        self.block = nn.Sequential(*block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class UNetUpBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size, up_mode, padding, batch_norm):\n",
    "        super(UNetUpBlock, self).__init__()\n",
    "        if up_mode == 'upconv':\n",
    "            self.up = nn.ConvTranspose2d(in_size, out_size, kernel_size=2, stride=2)\n",
    "        elif up_mode == 'upsample':\n",
    "            self.up = nn.Sequential(\n",
    "                nn.Upsample(mode='bilinear', scale_factor=2),\n",
    "                nn.Conv2d(in_size, out_size, kernel_size=1),\n",
    "            )\n",
    "\n",
    "        self.conv_block = UNetConvBlock(in_size, out_size, padding, batch_norm)\n",
    "\n",
    "    def center_crop(self, layer, target_size):\n",
    "        _, _, layer_height, layer_width = layer.size()\n",
    "        diff_y = (layer_height - target_size[0]) // 2\n",
    "        diff_x = (layer_width - target_size[1]) // 2\n",
    "        return layer[\n",
    "            :, :, diff_y : (diff_y + target_size[0]), diff_x : (diff_x + target_size[1])\n",
    "        ]\n",
    "\n",
    "    def forward(self, x, bridge):\n",
    "        up = self.up(x)\n",
    "        crop1 = self.center_crop(bridge, up.shape[2:])\n",
    "        out = torch.cat([up, crop1], 1)\n",
    "        out = self.conv_block(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"A general-purpose residual block. Works only with 1-dim inputs.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 features,\n",
    "                 context_features,\n",
    "                 activation=F.relu,\n",
    "                 dropout_probability=0.,\n",
    "                 use_batch_norm=False,\n",
    "                 zero_initialization=True):\n",
    "        super().__init__()\n",
    "        self.activation = activation\n",
    "\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        if use_batch_norm:\n",
    "            self.batch_norm_layers = nn.ModuleList([\n",
    "                #nn.BatchNorm1d(features, eps=1e-3, track_running_stats=False)\n",
    "                nn.BatchNorm1d(features, eps=1e-3)\n",
    "                for _ in range(2)\n",
    "            ])\n",
    "        if context_features is not None:\n",
    "            self.context_layer = nn.Linear(context_features, features)\n",
    "        self.linear_layers = nn.ModuleList([\n",
    "            nn.Linear(features, features)\n",
    "            for _ in range(2)\n",
    "        ])\n",
    "        if dropout_probability > 0.:\n",
    "            self.dropout = nn.Dropout(p=dropout_probability)\n",
    "        else:\n",
    "            self.dropout = None\n",
    "        if zero_initialization:\n",
    "            init.uniform_(self.linear_layers[-1].weight, -1e-3, 1e-3)\n",
    "            init.uniform_(self.linear_layers[-1].bias, -1e-3, 1e-3)\n",
    "\n",
    "    def forward(self, inputs, context=None):\n",
    "        temps = inputs\n",
    "        if self.use_batch_norm:\n",
    "            temps = self.batch_norm_layers[0](temps)\n",
    "        temps = self.activation(temps)\n",
    "        temps = self.linear_layers[0](temps)\n",
    "        if self.use_batch_norm:\n",
    "            temps = self.batch_norm_layers[1](temps)\n",
    "        temps = self.activation(temps)\n",
    "        if self.dropout:\n",
    "            temps = self.dropout(temps)\n",
    "        temps = self.linear_layers[1](temps)\n",
    "        if context is not None:\n",
    "            temps = F.glu(\n",
    "                torch.cat(\n",
    "                    (temps, self.context_layer(context)),\n",
    "                    dim=1\n",
    "                ),\n",
    "                dim=1\n",
    "            )\n",
    "        return inputs + temps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@regist_network\n",
    "class ResidualNet(nn.Module):\n",
    "    \"\"\"A general-purpose residual network. Works only with 1-dim inputs.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_features,\n",
    "                 out_features,\n",
    "                 hidden_features,\n",
    "                 context_features=None,\n",
    "                 num_blocks=2,\n",
    "                 activation=F.relu,\n",
    "                 dropout_probability=0.,\n",
    "                 use_batch_norm=False):\n",
    "        super().__init__()\n",
    "        self.hidden_features = hidden_features\n",
    "        self.context_features = context_features\n",
    "        if context_features is not None:\n",
    "            self.initial_layer = nn.Linear(in_features + context_features, hidden_features)\n",
    "        else:\n",
    "            self.initial_layer = nn.Linear(in_features, hidden_features)\n",
    "        self.blocks = nn.ModuleList([\n",
    "            ResidualBlock(\n",
    "                features=hidden_features,\n",
    "                context_features=context_features,\n",
    "                activation=activation,\n",
    "                dropout_probability=dropout_probability,\n",
    "                use_batch_norm=use_batch_norm,\n",
    "            ) for _ in range(num_blocks)\n",
    "        ])\n",
    "        self.final_layer = nn.Linear(hidden_features, out_features)\n",
    "\n",
    "    def forward(self, inputs, context=None):\n",
    "        if context is None:\n",
    "            temps = self.initial_layer(inputs)\n",
    "        else:\n",
    "            temps = self.initial_layer(\n",
    "                torch.cat((inputs, context), dim=1)\n",
    "            )\n",
    "        for block in self.blocks:\n",
    "            temps = block(temps, context=context)\n",
    "        outputs = self.final_layer(temps)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
