{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "> models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from IPython.display import clear_output, DisplayHandle\n",
    "\n",
    "def update_patch(self, obj):\n",
    "    clear_output(wait=True)\n",
    "    self.display(obj)\n",
    "DisplayHandle.update = update_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "from fastai.vision.all import ConvLayer, nn\n",
    "from torch import cat as torch_cat\n",
    "from Noise2Model.utils import attributesFromDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class DnCNN(nn.Module):\n",
    "    def __init__(self, channels, num_of_layers=9, features=64, kernel_size=3):\n",
    "        super(DnCNN, self).__init__()\n",
    "        padding = 1\n",
    "        layers = []\n",
    "        layers.append(ConvLayer(channels, features, ks=kernel_size, padding=padding, norm_type=None))\n",
    "        for _ in range(num_of_layers-2):\n",
    "            layers.append(ConvLayer(features, features, ks=kernel_size, padding=padding))\n",
    "        layers.append(nn.Conv2d(in_channels=features, out_channels=channels, kernel_size=kernel_size, padding=padding, bias=False))\n",
    "        self.dncnn = nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        residual = self.dncnn(x)\n",
    "        denoised = x - residual\n",
    "        return denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "class UNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 depth=4,\n",
    "                 mult_chan=32,\n",
    "                 in_channels=1,\n",
    "                 out_channels=1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        attributesFromDict(locals( ))\n",
    "        \n",
    "        self.net_recurse = _Net_recurse(n_in_channels=self.in_channels, mult_chan=self.mult_chan, depth=self.depth)\n",
    "        self.conv_out = nn.Conv3d(self.mult_chan, self.out_channels, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_rec = self.net_recurse(x)\n",
    "        return self.conv_out(x_rec)\n",
    "\n",
    "\n",
    "class _Net_recurse(nn.Module):\n",
    "    def __init__(self, n_in_channels, mult_chan=2, depth=0):\n",
    "        \"\"\"Class for recursive definition of U-network.p\n",
    "\n",
    "        Parameters:\n",
    "        in_channels - (int) number of channels for input.\n",
    "        mult_chan - (int) factor to determine number of output channels\n",
    "        depth - (int) if 0, this subnet will only be convolutions that double the channel count.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.depth = depth\n",
    "        n_out_channels = n_in_channels*mult_chan\n",
    "        self.sub_2conv_more = SubNet2Conv(n_in_channels, n_out_channels)\n",
    "        \n",
    "        if depth > 0:\n",
    "            ks = 3\n",
    "            self.sub_2conv_less = SubNet2Conv(2*n_out_channels, n_out_channels)\n",
    "            self.conv_down = ConvLayer(n_out_channels, n_out_channels, ks=ks)\n",
    "            self.convt = ConvLayer(2*n_out_channels, n_out_channels, ks=ks, transpose=True, padding=(ks-1)//2)\n",
    "            self.sub_u = _Net_recurse(n_out_channels, mult_chan=2, depth=(depth - 1))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        if self.depth == 0:\n",
    "            return self.sub_2conv_more(x)\n",
    "        else:  # depth > 0\n",
    "            x_2conv_more = self.sub_2conv_more(x)\n",
    "            x_conv_down = self.conv_down(x_2conv_more)\n",
    "            x_sub_u = self.sub_u(x_conv_down)\n",
    "            x_convt = self.convt(x_sub_u)\n",
    "            x_cat = torch_cat((x_2conv_more, x_convt), 1)  # concatenate\n",
    "            x_2conv_less = self.sub_2conv_less(x_cat)\n",
    "        return x_2conv_less\n",
    "\n",
    "\n",
    "class SubNet2Conv(nn.Module):\n",
    "    def __init__(self, n_in, n_out):\n",
    "        super().__init__()\n",
    "\n",
    "        self.C1 = ConvLayer(n_in, n_out, ks=3, padding=1)\n",
    "        self.C2 = ConvLayer(n_out, n_out, ks=3, padding=1)\n",
    "        \n",
    "    def forward(self, x): return self.C2(self.C1(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can use fastai unet builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = unet_learner(dls, models.resnet18, loss_func=F.l1_loss, n_in=1, n_out=1, pretrained=False, cut=None)\n",
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
