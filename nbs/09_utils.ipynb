{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\n",
    "\n",
    "> Utility functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "\n",
    "from IPython.display import clear_output, DisplayHandle\n",
    "\n",
    "def update_patch(self, obj):\n",
    "    clear_output(wait=True)\n",
    "    self.display(obj)\n",
    "DisplayHandle.update = update_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bm/miniconda3/envs/n2m/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "from fastai.vision.all import torch, nn\n",
    "import numpy as np\n",
    "from torchmetrics.functional.image import structural_similarity_index_measure as structural_similarity\n",
    "from torchmetrics.functional.image import peak_signal_noise_ratio\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def attributesFromDict(d):\n",
    "    self = d.pop('self')\n",
    "    for n, v in d.items():\n",
    "        setattr(self, n, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def gaussian_diag(mean, logsd):\n",
    "    class o(object):\n",
    "        pass\n",
    "\n",
    "    o.mean = mean\n",
    "    o.logsd = logsd\n",
    "    o.eps = torch.normal(torch.zeros(mean.shape, device=mean.device), torch.ones(mean.shape, device=mean.device))\n",
    "    o.sample = mean + torch.exp(logsd) * o.eps\n",
    "    o.sample2 = lambda eps: mean + torch.exp(logsd) * eps\n",
    "\n",
    "    o.logps = lambda x: -0.5 * (np.log(2 * np.pi) + 2. * o.logsd + (x - o.mean) ** 2 / torch.exp(2. * o.logsd))\n",
    "    o.logp = lambda x: torch.sum(o.logps(x), dim=[1, 2, 3])\n",
    "    o.get_eps = lambda x: (x - mean) / torch.exp(logsd)\n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def batch_PSNR(img, imclean, data_range):\n",
    "    Img = img.data.cpu().numpy().astype(np.float32)\n",
    "    Iclean = imclean.data.cpu().numpy().astype(np.float32)\n",
    "    PSNR = 0\n",
    "    for i in range(Img.shape[0]):\n",
    "        PSNR += peak_signal_noise_ratio(Iclean[i,:,:,:], Img[i,:,:,:], data_range=data_range)\n",
    "    return (PSNR/Img.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def weights_init_kaiming(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "    elif classname.find('Linear') != -1:\n",
    "        nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        # nn.init.uniform(m.weight.data, 1.0, 0.02)\n",
    "        m.weight.data.normal_(mean=0, std=math.sqrt(2./9./64.)).clamp_(-0.025,0.025)\n",
    "        nn.init.constant_(m.bias.data, 0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def output_psnr_mse(img_orig, img_out, data_range):\n",
    "    squared_error = torch.square(img_orig - img_out)\n",
    "    mse = torch.mean(squared_error)\n",
    "    psnr = 10 * torch.log10(data_range ** 2/ mse)\n",
    "    return psnr\n",
    "\n",
    "def mean_psnr(denoised, imclean, data_range=1.0):\n",
    "    n_blk = imclean.shape[0]\n",
    "    mean_psnr = 0\n",
    "    psnrs = np.ndarray([n_blk])\n",
    "    for b in range(n_blk):\n",
    "        ref_block = imclean[b]\n",
    "        res_block = denoised[b]\n",
    "        psnr = output_psnr_mse(ref_block, res_block, data_range)\n",
    "        mean_psnr += psnr\n",
    "        psnrs[b] = psnr\n",
    "    return mean_psnr / n_blk, psnrs\n",
    "\n",
    "\n",
    "def kldiv_simple(real_noise, sampled_noise):\n",
    "    bw = 0.2 / 64\t\n",
    "    bin_edges = np.concatenate(([-1000.0], np.arange(-0.1, 0.1 + 1e-9, bw), [1000.0]), axis=0)\n",
    "    cnt_regr = 1\t\n",
    "    real_hist = get_histogram(real_noise, bin_edges=bin_edges, cnt_regr=cnt_regr)\n",
    "    sampled_hist = get_histogram(sampled_noise, bin_edges=bin_edges, cnt_regr=cnt_regr)\n",
    "\n",
    "    kld = kl_div_forward(real_hist, sampled_hist)\n",
    "\n",
    "    return kld\n",
    "\n",
    "def get_histogram(data, bin_edges=None, cnt_regr=1):\n",
    "    n = np.prod(data.shape)\t\n",
    "    hist, _ = np.histogram(data, bin_edges)\t\n",
    "    return (hist + cnt_regr)/(n + cnt_regr * len(hist))\n",
    "\n",
    "def kl_div_forward(p, q):\n",
    "    assert (~(np.isnan(p) | np.isinf(p) | np.isnan(q) | np.isinf(q))).all()\t\n",
    "    idx = (p > 0)\n",
    "    p = p[idx]\n",
    "    q = q[idx]\n",
    "    return np.sum(p * np.log(p / q))\n",
    "\n",
    "def batch_SSIM(img, imclean, data_range):\n",
    "    Img = img.data.cpu().numpy().astype(np.float32)\n",
    "    Iclean = imclean.data.cpu().numpy().astype(np.float32)\n",
    "    SSIM = 0\n",
    "    for i in range(Img.shape[0]):\n",
    "        SSIM += structural_similarity(Iclean[i].transpose((1, 2, 0)), Img[i].transpose((1, 2, 0)), data_range=data_range,  sigma=0.8)\n",
    "    return (SSIM/Img.shape[0])\n",
    "\n",
    "def weights_init_orthogonal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.orthogonal_(m.weight.data)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        nn.init.orthogonal_(m.weight.data)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(mean=0, std=math.sqrt(2./9./64.)).clamp_(-0.025,0.025)\n",
    "        nn.init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
