{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\n",
    "\n",
    "> Utility functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastai.vision.all import torch, nn\n",
    "import numpy as np\n",
    "from torchmetrics.functional.image import structural_similarity_index_measure as structural_similarity\n",
    "from torchmetrics.functional.image import peak_signal_noise_ratio\n",
    "import torch \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def attributesFromDict(d):\n",
    "    self = d.pop('self')\n",
    "    for n, v in d.items():\n",
    "        setattr(self, n, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def batch_PSNR(img, imclean, data_range):\n",
    "    Img = img.data.cpu().numpy().astype(np.float32)\n",
    "    Iclean = imclean.data.cpu().numpy().astype(np.float32)\n",
    "    PSNR = 0\n",
    "    for i in range(Img.shape[0]):\n",
    "        PSNR += peak_signal_noise_ratio(Iclean[i,:,:,:], Img[i,:,:,:], data_range=data_range)\n",
    "    return (PSNR/Img.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class compute_index():\n",
    "    def __init__(self, codes, device='cpu') -> None:\n",
    "        attributesFromDict(locals( ))\n",
    "      \n",
    "    def _compute_index(self, b, **kwargs):\n",
    "        idx = torch.zeros([b], device=self.device, dtype=torch.float32)\n",
    "        for key, value in self.codes.items():\n",
    "            idx = idx * len(value)\n",
    "            for i, v in enumerate(value):\n",
    "                idx += torch.where(kwargs[key] == v, i, 0.0)\n",
    "\n",
    "        return idx\n",
    "    \n",
    "    def __call__(self, b, **kwargs):\n",
    "        return self._compute_index(b, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:  tensor([10.])\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "codes = {\n",
    "        'exposure-time': torch.tensor([10, 50, 100], dtype=torch.float32, device=device),\n",
    "        'optical-setup': torch.tensor([0, 1], dtype=torch.float32).to(device),\n",
    "        'camera': torch.tensor([0, 1], dtype=torch.float32).to(device)\n",
    "    }\n",
    "kwargs = {\n",
    "        'exposure-time': torch.tensor([100], dtype=torch.float32).to(device),\n",
    "        'optical-setup': torch.tensor([1], dtype=torch.float32).to(device),\n",
    "        'camera': torch.tensor([0], dtype=torch.float32).to(device)\n",
    "    }\n",
    "\n",
    "fn = compute_index(codes)\n",
    "\n",
    "print('index: ', fn(1, **kwargs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class compute_one_hot():\n",
    "    def __init__(self, codes, device='cpu') -> None:\n",
    "        attributesFromDict(locals( ))\n",
    "      \n",
    "    def _compute_one_hot(self, b, **kwargs):\n",
    "        embedding = torch.tensor([])\n",
    "        for key, value in self.codes.items():\n",
    "            idx = torch.zeros([b], device=self.device, dtype=torch.float32)\n",
    "            for i, v in enumerate(value):\n",
    "                idx += torch.where(kwargs[key] == v, i, 0.0)\n",
    "            idx_one_hot = F.one_hot(idx.to(torch.int64), num_classes=value.shape[0]).to(torch.float32)\n",
    "            print(key, ': ', idx_one_hot)\n",
    "            embedding = torch.cat((embedding, idx_one_hot), dim=1)\n",
    "\n",
    "        return embedding\n",
    "    \n",
    "    def __call__(self, b, **kwargs):\n",
    "        return self._compute_one_hot(b, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exposure-time :  tensor([[0., 0., 1.]])\n",
      "optical-setup :  tensor([[0., 1.]])\n",
      "camera :  tensor([[1., 0.]])\n",
      "one hot encoding:  tensor([[0., 0., 1., 0., 1., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "fn1hot = compute_one_hot(codes)\n",
    "\n",
    "print('one hot encoding: ', fn1hot(1, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
