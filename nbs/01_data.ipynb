{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "> Data handling functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import h5py\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_FMD_img_paths(base_path):\n",
    "    file_paths = list()\n",
    "    for full_path, _, file_names in os.walk(os.path.join(base_path, 'raw')):\n",
    "        for file_name in file_names:\n",
    "            if 'png' in file_name:\n",
    "                raw_path = os.path.join(full_path, file_name)\n",
    "                gt_path = os.path.join(full_path.replace('raw','gt'), 'avg50.png')\n",
    "                if os.path.exists(gt_path):\n",
    "                    file_paths.append({'GT':gt_path,'NOISY': raw_path})\n",
    "    return file_paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def convert_setup_code(model_name):\n",
    "    models = ['100x', '060x']\n",
    "    for idx, model in enumerate(models):\n",
    "        if model == model_name: return idx\n",
    "    assert False, \"Invalid setup code.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO: add code similar to next cell that can read info from metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def parse_dir_name(dir_name):\n",
    "    tokens = dir_name.split('_')\n",
    "    return {\n",
    "        'scene-instance-number': int(tokens[0]),\n",
    "        'scene-number': int('001'),\n",
    "        'setup-code': int(convert_setup_code('060x')),\n",
    "        'pixel-size': int('0100'), # nm\n",
    "        'exposure-time': int('00060'), # ms\n",
    "        'wavelength': int('600'), # nm\n",
    "        'photon-flux':int('0100') # photons/nm/ms\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop\n",
    "\n",
    "Crop whole image into patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def crop(img, size, overlap):\n",
    "    crops = list()\n",
    "    img = img.transpose(2,0,1)\n",
    "    _,h,w = img.shape\n",
    "    i,j = 0, 0\n",
    "    while i < h:\n",
    "        while j < w:\n",
    "            roi_x, roi_y = j, i\n",
    "            if i + size > h: roi_y = h - size \n",
    "            if j + size > w: roi_x = w - size\n",
    "            # crops.append(img[:,roi_y:roi_y+size,roi_x:roi_x+size])\n",
    "            crops.append(img[:1,roi_y:roi_y+size,roi_x:roi_x+size])\n",
    "            j+=overlap\n",
    "        j=0\n",
    "        i+=overlap\n",
    "    i=0\n",
    "    return crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def preprocessing(data_path='./data/Confocal_BPAE_B',\n",
    "                    patch_size = 96,\n",
    "                    overlap = 8,\n",
    "                    mode = 'NOISE_GEN', # ['NOISE_GEN', 'DENOISER', 'ALL']\n",
    "                    output_base_path = './data/HDF5_confocal_s96_o08',\n",
    "                    ):\n",
    "    \n",
    "    TRAIN_NOISEGEN_INDICES = [1] #[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
    "    TRAIN_DENOISER_INDICES = TRAIN_NOISEGEN_INDICES\n",
    "    TRAIN_ALL_INDICES = TRAIN_NOISEGEN_INDICES\n",
    "    TEST_INDICES = [19, 20]\n",
    "\n",
    "    img_paths = get_FMD_img_paths(data_path) #load paths\n",
    "    parse_dir_name(img_paths[0]['GT'].split('/')[-2])\n",
    "    \n",
    "    for img_idx, img_path in enumerate(tqdm(img_paths)):\n",
    "        img_gt = cv2.imread(img_path['GT'], cv2.IMREAD_COLOR) # read gt images\n",
    "        img_noisy = cv2.imread(img_path['NOISY'], cv2.IMREAD_COLOR) # read noisy images\n",
    "        config = parse_dir_name(img_path['GT'].split('/')[-2])\n",
    "        \n",
    "        img_gt_crops = crop(img_gt, patch_size, overlap)\n",
    "        img_noisy_crops = crop(img_noisy, patch_size, overlap)\n",
    "        assert len(img_gt_crops) == len(img_noisy_crops)\n",
    "\n",
    "        output_dir_path  = output_base_path\n",
    "        if mode == 'NOISE_GEN':\n",
    "            if config['scene-instance-number'] in TRAIN_NOISEGEN_INDICES:\n",
    "                output_dir_path += '/noise_gen/train/'\n",
    "            elif config['scene-instance-number'] in TEST_INDICES:\n",
    "                output_dir_path += '/noise_gen/test/'\n",
    "            else:\n",
    "                continue\n",
    "        elif mode == 'DENOISER':\n",
    "            if config['scene-instance-number'] in TRAIN_DENOISER_INDICES:\n",
    "                output_dir_path += '/denoiser/'\n",
    "            else:\n",
    "                continue\n",
    "        elif mode == 'ALL':\n",
    "            if config['scene-instance-number'] in TRAIN_ALL_INDICES:\n",
    "                output_dir_path += '/all/'\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "        os.makedirs(output_dir_path, exist_ok=True)\n",
    "        output_file_name = '%04d_%s.hdf5'%(img_idx, img_path['GT'].split('/')[-2])\n",
    "        hdf_file_path = os.path.join(output_dir_path, output_file_name)\n",
    "        with h5py.File(hdf_file_path, \"w\") as f:\n",
    "            for patch_idx, (gt, noisy) in enumerate(zip(img_gt_crops, img_noisy_crops)):\n",
    "                f.create_dataset(f'clean/{patch_idx}', data=gt)\n",
    "                f.create_dataset(f'noisy/{patch_idx}', data=noisy)\n",
    "            hdf5_config = f.create_group('config')\n",
    "            for key in config:\n",
    "                hdf5_config.attrs[key] = config[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def find_support_scene(img_paths, current_path):\n",
    "    random.shuffle(img_paths) # shuffling\n",
    "    current_config = parse_dir_name(current_path['GT'].split('/')[-2])\n",
    "    for img_path in img_paths:\n",
    "        target_config = parse_dir_name(img_path['GT'].split('/')[-2])\n",
    "        if target_config['setup-code'] == current_config['setup-code'] and \\\n",
    "        target_config['pixel-size'] == current_config['pixel-size'] and \\\n",
    "        target_config['scene-instance-number'] != current_config['scene-instance-number']:\n",
    "            return img_path\n",
    "    assert False, \"There is no matching scene.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def load_and_display_hdf5_image(file_path, dataset_name='clean'):\n",
    "    with h5py.File(file_path, 'r') as file:\n",
    "        image_data = file[dataset_name + '/20'][:] \n",
    "        print(image_data.shape)\n",
    "    plt.imshow(image_data[0], cmap='gray')  # Adjust cmap as per your image format\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "file_path = output_base_path + '/noise_gen/test/0100_20.hdf5'\n",
    "print(file_path)\n",
    "load_and_display_hdf5_image(file_path, dataset_name='noisy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
