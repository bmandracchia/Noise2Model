{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\n",
    "\n",
    "> Utility functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import cv2\n",
    "from math import log10, exp, log, pi\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch \n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchmetrics.functional.image import structural_similarity_index_measure as structural_similarity\n",
    "from torchmetrics.functional.image import peak_signal_noise_ratio\n",
    "\n",
    "from fastai.vision.all import store_attr\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute attribute index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ComputeIndex:\n",
    "    def __init__(self, codes) -> None:\n",
    "        self.codes = codes\n",
    "\n",
    "    def _compute_index(self, b, **kwargs):\n",
    "        # Dynamically detect device from any input tensor\n",
    "        device = next(iter(kwargs.values())).device\n",
    "\n",
    "        idx = torch.zeros([b], device=device, dtype=torch.float32)\n",
    "        for key, value in self.codes.items():\n",
    "            idx = idx * len(value)\n",
    "            for i, v in enumerate(value):\n",
    "                idx += torch.where(kwargs[key] == v, i, 0.0)\n",
    "        return idx\n",
    "\n",
    "    def __call__(self, b, **kwargs):\n",
    "        return self._compute_index(b, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:  tensor([10.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "codes = {\n",
    "        'exposure-time': torch.tensor([10, 50, 100], dtype=torch.float32, device=device),\n",
    "        'optical-setup': torch.tensor([0, 1], dtype=torch.float32).to(device),\n",
    "        'camera': torch.tensor([0, 1], dtype=torch.float32).to(device)\n",
    "    }\n",
    "kwargs = {\n",
    "        'exposure-time': torch.tensor([100], dtype=torch.float32).to(device),\n",
    "        'optical-setup': torch.tensor([1], dtype=torch.float32).to(device),\n",
    "        'camera': torch.tensor([0], dtype=torch.float32).to(device)\n",
    "    }\n",
    "\n",
    "fn = ComputeIndex(codes)\n",
    "\n",
    "print('index: ', fn(1, **kwargs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class ComputeOneHot:\n",
    "    def __init__(self, codes) -> None:\n",
    "        self.codes = codes\n",
    "\n",
    "    def _compute_one_hot(self, b, **kwargs):\n",
    "        # get device dynamically\n",
    "        device = next(iter(kwargs.values())).device\n",
    "\n",
    "        embedding = torch.tensor([], device=device)\n",
    "        for key, value in self.codes.items():\n",
    "            idx = torch.zeros([b], device=device, dtype=torch.float32)\n",
    "            for i, v in enumerate(value):\n",
    "                idx += torch.where(kwargs[key] == v, i, 0.0)\n",
    "            idx_one_hot = F.one_hot(idx.to(torch.int64), num_classes=len(value)).to(torch.float32)\n",
    "            embedding = torch.cat((embedding, idx_one_hot), dim=1)\n",
    "        return embedding\n",
    "\n",
    "    def __call__(self, b, **kwargs):\n",
    "        return self._compute_one_hot(b, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one hot encoding:  tensor([[0., 0., 1., 0., 1., 1., 0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "fn1hot = ComputeOneHot(codes)\n",
    "\n",
    "print('one hot encoding: ', fn1hot(1, **kwargs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class StandardNormal(nn.Module):\n",
    "    \"\"\"A multivariate Normal with zero mean and unit covariance.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(StandardNormal, self).__init__()\n",
    "        self.register_buffer('buffer', torch.zeros(1))\n",
    "\n",
    "    def log_prob(self, x):\n",
    "        # https://www.statlect.com/fundamentals-of-statistics/normal-distribution-maximum-likelihood\n",
    "        log_base =  - 0.5 * log(2 * pi)\n",
    "        log_inner = - 0.5 * x**2\n",
    "        return sum_except_batch(log_base+log_inner)\n",
    "\n",
    "    def sample(self, shape):\n",
    "        return torch.randn(*shape, device=self.buffer.device, dtype=self.buffer.dtype)\n",
    "        # return torch.rand(*shape, device=self.buffer.device, dtype=self.buffer.dtype)\n",
    "\n",
    "def sum_except_batch(x, num_dims=1):\n",
    "    '''\n",
    "    Sums all dimensions except the first.\n",
    "    Args:\n",
    "        x: Tensor, shape (batch_size, ...)\n",
    "        num_dims: int, number of batch dims (default=1)\n",
    "    Returns:\n",
    "        x_sum: Tensor, shape (batch_size,)\n",
    "    '''\n",
    "    return x.reshape(*x.shape[:num_dims], -1).sum(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def np2tensor(n:np.array):\n",
    "    '''\n",
    "    transform numpy array (image) to torch Tensor\n",
    "    BGR -> RGB\n",
    "    (h,w,c) -> (c,h,w)\n",
    "    '''\n",
    "    # gray\n",
    "    if len(n.shape) == 2:\n",
    "        n = np.expand_dims(n, axis=2)\n",
    "        return torch.from_numpy(np.ascontiguousarray(np.transpose(n, (2,0,1))))\n",
    "    # RGB -> BGR\n",
    "    elif len(n.shape) == 3:\n",
    "        return torch.from_numpy(np.ascontiguousarray(np.transpose(np.flip(n, axis=2), (2,0,1))))\n",
    "    else:\n",
    "        raise RuntimeError('wrong numpy dimensions : %s'%(n.shape,))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(4, 4)\n",
    "assert np2tensor(a).type() == 'torch.DoubleTensor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(0, high=255, size=(4,4))\n",
    "assert np2tensor(a).type() == 'torch.LongTensor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def np2tensor_multi(n:np.array):\n",
    "    t = None\n",
    "    if len(n) <= 1: # single stacked image\n",
    "        t = np2tensor(n[0].astype(np.float32)).unsqueeze(0).float()\n",
    "    else: # multi stacked image\n",
    "        for mat in n:\n",
    "            if t is None: t = np2tensor(mat.astype(np.float32)).unsqueeze(0).float()\n",
    "            else: t = torch.cat([t, np2tensor(mat.astype(np.float32)).unsqueeze(0).float()], dim=0)\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def tensor2np(t:torch.Tensor):\n",
    "    '''\n",
    "    transform torch Tensor to numpy having opencv image form.\n",
    "    RGB -> BGR\n",
    "    (c,h,w) -> (h,w,c)\n",
    "    '''\n",
    "    t = t.cpu().detach()\n",
    "\n",
    "    # gray\n",
    "    if len(t.shape) == 2:\n",
    "        return t.permute(1,2,0).numpy()\n",
    "    # RGB -> BGR\n",
    "    elif len(t.shape) == 3:\n",
    "        return np.flip(t.permute(1,2,0).numpy(), axis=2)\n",
    "    # image batch\n",
    "    elif len(t.shape) == 4:\n",
    "        return np.flip(t.permute(0,2,3,1).numpy(), axis=3)\n",
    "    else:\n",
    "        raise RuntimeError('wrong tensor dimensions : %s'%(t.shape,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def imwrite_tensor(t, name='test.png'):\n",
    "    cv2.imwrite('./%s'%name, tensor2np(t.cpu()))\n",
    "\n",
    "def imread_tensor(name='test'):\n",
    "    return np2tensor(cv2.imread('./%s'%name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def rot_hflip_img(img:torch.Tensor, rot_times:int=0, hflip:int=0):\n",
    "    '''\n",
    "    rotate '90 x times degree' & horizontal flip image \n",
    "    (shape of img: b,c,h,w or c,h,w)\n",
    "    '''\n",
    "    b=0 if len(img.shape)==3 else 1\n",
    "    # no flip\n",
    "    if hflip % 2 == 0:\n",
    "        # 0 degrees\n",
    "        if rot_times % 4 == 0:    \n",
    "            return img\n",
    "        # 90 degrees\n",
    "        elif rot_times % 4 == 1:  \n",
    "            return img.flip(b+1).transpose(b+1,b+2)\n",
    "        # 180 degrees\n",
    "        elif rot_times % 4 == 2:  \n",
    "            return img.flip(b+2).flip(b+1)\n",
    "        # 270 degrees\n",
    "        else:               \n",
    "            return img.flip(b+2).transpose(b+1,b+2)\n",
    "    # horizontal flip\n",
    "    else:\n",
    "        # 0 degrees\n",
    "        if rot_times % 4 == 0:    \n",
    "            return img.flip(b+2)\n",
    "        # 90 degrees\n",
    "        elif rot_times % 4 == 1:  \n",
    "            return img.flip(b+1).flip(b+2).transpose(b+1,b+2)\n",
    "        # 180 degrees\n",
    "        elif rot_times % 4 == 2:  \n",
    "            return img.flip(b+1)\n",
    "        # 270 degrees\n",
    "        else:               \n",
    "            return img.transpose(b+1,b+2)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "     \n",
    "def psnr(x, y, mask=None, max_val=1.):\n",
    "    if max_val is None : max_val = 1.\n",
    "    if mask is None:\n",
    "        mse = torch.mean((x - y) ** 2)\n",
    "    else:\n",
    "        mse = torch.sum(((x - y) ** 2) * mask) / mask.sum() \n",
    "    return 10 * log10(max_val**2 / mse.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def ssim(img1, img2, data_range):\n",
    "    '''\n",
    "    image value range : [0 - data_range]\n",
    "    clipping for model output\n",
    "    '''\n",
    "    if len(img1.shape) == 4:\n",
    "        img1 = img1[0]\n",
    "    if len(img2.shape) == 4:\n",
    "        img2 = img2[0]\n",
    "\n",
    "    # tensor to numpy\n",
    "    if isinstance(img1, torch.Tensor):\n",
    "        img1 = tensor2np(img1)\n",
    "    if isinstance(img2, torch.Tensor):\n",
    "        img2 = tensor2np(img2)\n",
    "\n",
    "    # numpy value cliping\n",
    "    img2 = np.clip(img2, 0, data_range)\n",
    "    img1 = np.clip(img1, 0, data_range)\n",
    "\n",
    "    # https://forum.image.sc/t/how-to-calculate-ssim-of-muti-channel-images-since-the-function-structural-similarity-deprecate-the-parameter-multichannel/79693\n",
    "    return structural_similarity(img1, img2, channel_axis=-1, data_range=data_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"\n",
    "    Computes and stores the average and current value.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def setup_determinism(seed):\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_gaussian_2d_filter(window_size, sigma, channel=1, device=torch.device('cpu')):\n",
    "    '''\n",
    "    return 2d gaussian filter window as tensor form\n",
    "    Arg:\n",
    "        window_size : filter window size\n",
    "        sigma : standard deviation\n",
    "    '''\n",
    "    gauss = torch.ones(window_size, device=device)\n",
    "    for x in range(window_size): gauss[x] = exp(-(x - window_size//2)**2/float(2*sigma**2))\n",
    "    gauss = gauss.unsqueeze(1)\n",
    "    #gauss = torch.Tensor([exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)], device=device).unsqueeze(1)\n",
    "    filter2d = gauss.mm(gauss.t()).float()\n",
    "    filter2d = (filter2d/filter2d.sum()).unsqueeze(0).unsqueeze(0)\n",
    "    return filter2d.expand(channel, 1, window_size, window_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_mean_2d_filter(window_size, channel=1, device=torch.device('cpu')):\n",
    "    '''\n",
    "    return 2d mean filter as tensor form\n",
    "    Args:\n",
    "        window_size : filter window size\n",
    "    '''\n",
    "    window = torch.ones((window_size, window_size), device=device)\n",
    "    window = (window/window.sum()).unsqueeze(0).unsqueeze(0)\n",
    "    return window.expand(channel, 1, window_size, window_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def mean_conv2d(x, window_size=None, window=None, filter_type='gau', sigma=None, keep_sigma=False, padd=True):\n",
    "    '''\n",
    "    color channel-wise 2d mean or gaussian convolution\n",
    "    Args:\n",
    "        x : input image\n",
    "        window_size : filter window size\n",
    "        filter_type(opt) : 'gau' or 'mean'\n",
    "        sigma : standard deviation of gaussian filter\n",
    "    '''\n",
    "    b_x = x.unsqueeze(0) if len(x.shape) == 3 else x\n",
    "\n",
    "    if window is None:\n",
    "        if sigma is None: sigma = (window_size-1)/6\n",
    "        if filter_type == 'gau':\n",
    "            window = get_gaussian_2d_filter(window_size, sigma=sigma, channel=b_x.shape[1], device=x.device)\n",
    "        else:\n",
    "            window = get_mean_2d_filter(window_size, channel=b_x.shape[1], device=x.device)\n",
    "    else:\n",
    "        window_size = window.shape[-1]\n",
    "\n",
    "    if padd:\n",
    "        pl = (window_size-1)//2\n",
    "        b_x = F.pad(b_x, (pl,pl,pl,pl), 'reflect')\n",
    "\n",
    "    m_b_x = F.conv2d(b_x, window, groups=b_x.shape[1])\n",
    "\n",
    "    if keep_sigma:\n",
    "        m_b_x /= (window**2).sum().sqrt()\n",
    "\n",
    "    if len(x.shape) == 4:\n",
    "        return m_b_x\n",
    "    elif len(x.shape) == 3:\n",
    "        return m_b_x.squeeze(0)\n",
    "    else:\n",
    "        raise ValueError('input image shape is not correct')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_file_name_from_path(path):\n",
    "    if '/' in path : name = path.split('/')[-1].split('.')[:-1]\n",
    "    elif '\\\\' in path: name = path.split('\\\\')[-1].split('.')[:-1]\n",
    "    else: assert False, f'Invalid path: {path}'\n",
    "\n",
    "    if isinstance(name, list):\n",
    "        merged = \"\"\n",
    "        for token in name[:-1]: \n",
    "            merged += token + '.'\n",
    "        merged += name[-1]\n",
    "        name = merged\n",
    "    return name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_histogram(data, bin_edges=None, cnt_regr=1):\n",
    "    n = np.prod(data.shape)\t\n",
    "    hist, _ = np.histogram(data, bin_edges)\t\n",
    "    return (hist + cnt_regr)/(n + cnt_regr * len(hist))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def kl_div_forward(p, q):\n",
    "    assert (~(np.isnan(p) | np.isinf(p) | np.isnan(q) | np.isinf(q))).all()\t\n",
    "    idx = (p > 0)\n",
    "    p = p[idx]\n",
    "    q = q[idx]\n",
    "    return np.sum(p * np.log(p / q))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def kl_div_3_data(real_noise, gen_noise, bin_edges=None, left_edge=0.0, right_edge=1.0):\n",
    "    # Kousha, Shayan, et al. \"Modeling srgb camera noise with normalizing flows.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022.\n",
    "    # ref) https://github.com/SamsungLabs/Noise2NoiseFlow\n",
    "    noise_pats = (gen_noise, real_noise)\t\n",
    "\n",
    "    # histograms\n",
    "    bw = 4\n",
    "    bin_edges = np.arange(left_edge, right_edge, bw)\n",
    "\n",
    "    cnt_regr = 1\n",
    "    hists = [None] * len(noise_pats)\t\n",
    "    klds = np.ndarray([len(noise_pats)])\t\n",
    "    klds[:] = 0.0\n",
    "\n",
    "    for h in reversed(range(len(noise_pats))):\n",
    "        hists[h] = get_histogram(noise_pats[h], bin_edges=bin_edges, cnt_regr=cnt_regr)\n",
    "        klds[h] = kl_div_forward(hists[-1], hists[h])\t\n",
    "\n",
    "    return klds[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def load_numpy_from_raw(path, dtype='float32'):\n",
    "    fid = open(path, \"rb\")\n",
    "    return np.fromfile(fid, dtype=dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def make_predefiend_1d_to_2d(arr):\n",
    "    predefined_sizes = [(3072,2560), (3072,3072), (9216,3072), (6144,3072)] # H, W\n",
    "    assert len(arr.shape) == 1\n",
    "    for predefined_size in predefined_sizes:\n",
    "        if arr.shape[0] == (predefined_size[0] * predefined_size[1]):\n",
    "            arr = np.reshape(arr, predefined_size)\n",
    "    assert len(arr.shape) == 2, \"Error: No matching predefined size exists.\"\n",
    "    return arr \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def save_img(dir_name, file_name, img):\n",
    "    path = os.path.join(dir_name, file_name)\n",
    "    if 'raw' in path[-3:]:\n",
    "        os.makedirs(dir_name, exist_ok=True)\n",
    "        with open(path, 'w') as fid:\n",
    "            img.tofile(fid)\n",
    "    else:\n",
    "        if len(img.shape) == 3 and img.shape[-1] != 3 and img.shape[-1] > 1:\n",
    "            cv2.imwritemulti(path, img.transpose([2,0,1])) # multi stack image, convert to CHW\n",
    "        elif len(img.shape) == 4 and img.shape[0] > 1: # batch image, only grey image is available\n",
    "            img = img.squeeze(-1)\n",
    "            cv2.imwritemulti(path, img) \n",
    "        elif len(img.shape) == 4 and img.shape[0] <= 1: # single batch image\n",
    "            img = img.squeeze(0)\n",
    "            cv2.imwrite(path, img)\n",
    "        else:\n",
    "            cv2.imwrite(path, img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class FileManager:\n",
    "    def __init__(self, session_name, output_path=None):\n",
    "        if output_path is None:\n",
    "            self.output_folder = \"./output\"\n",
    "        else:\n",
    "            self.output_folder = output_path\n",
    "            \n",
    "        if not os.path.isdir(self.output_folder):\n",
    "            os.makedirs(self.output_folder)\n",
    "            print(\"[WARNING] output folder does not exist, creating a new one\")\n",
    "\n",
    "        # init session\n",
    "        self.session_name = session_name\n",
    "        os.makedirs(os.path.join(self.output_folder, self.session_name), exist_ok=True)\n",
    "\n",
    "        # mkdir\n",
    "        for directory in ['checkpoint', 'img']:\n",
    "            self.make_dir(directory)\n",
    "\n",
    "    def is_dir_exist(self, dir_name:str) -> bool:\n",
    "        return os.path.isdir(os.path.join(self.output_folder, self.session_name, dir_name))\n",
    "\n",
    "    def make_dir(self, dir_name:str) -> str:\n",
    "        os.makedirs(os.path.join(self.output_folder, self.session_name, dir_name), exist_ok=True) \n",
    "\n",
    "    def get_dir(self, dir_name:str) -> str:\n",
    "        # -> './output/<session_name>/dir_name'\n",
    "        return os.path.join(self.output_folder, self.session_name, dir_name)\n",
    "\n",
    "    def save_img_tensor(self, dir_name:str, file_name:str, img:torch.Tensor, ext='png'):\n",
    "        self.save_img_numpy(dir_name, file_name, tensor2np(img), ext)\n",
    "\n",
    "    def save_img_numpy(self, dir_name:str, file_name:str, img:np.array, ext='png'):\n",
    "        if np.shape(img)[2] == 1:\n",
    "            save_img(self.get_dir(dir_name), '%s.%s'%(file_name, ext), np.squeeze(img, 2))\n",
    "        else:\n",
    "            save_img(self.get_dir(dir_name), '%s.%s'%(file_name, ext), img)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progress Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class ProgressMsg():\n",
    "    def __init__(self, max_iter, min_time_interval=0.1):\n",
    "        '''\n",
    "        Args:\n",
    "            max_iter : (max_epoch, max_data_length, ...)\n",
    "            min_time_interval (second)\n",
    "        '''\n",
    "        self.max_iter = max_iter\n",
    "        self.min_time_interval = min_time_interval\n",
    "\n",
    "        self.start_time = time.time()\n",
    "        self.progress_time = self.start_time\n",
    "\n",
    "    def start(self, start_iter):\n",
    "\n",
    "        assert len(self.max_iter) == len(start_iter), 'start_iter should have same length with max variable.'\n",
    "\n",
    "        self.start_iter = start_iter\n",
    "        self.current_iter = start_iter\n",
    "        self.start_time = time.time()\n",
    "        self.progress_time = self.start_time\n",
    "\n",
    "    def calculate_progress(self, current_iter):\n",
    "        self.progress_time = time.time()\n",
    "\n",
    "        assert len(self.max_iter) == len(current_iter), 'current should have same length with max variable.'\n",
    "\n",
    "        for i in range(len(self.max_iter)):\n",
    "            assert current_iter[i] <= self.max_iter[i], 'current value should be less than max value.'\n",
    "\n",
    "        start_per = 0\n",
    "        for i in reversed(range(len(self.max_iter))):\n",
    "            start_per += self.start_iter[i]\n",
    "            start_per /= self.max_iter[i]\n",
    "        start_per *= 100\n",
    "\n",
    "        pg_per = 0\n",
    "        for i in reversed(range(len(self.max_iter))):\n",
    "            pg_per += current_iter[i]\n",
    "            pg_per /= self.max_iter[i]\n",
    "        pg_per *= 100\n",
    "\n",
    "        pg_per = (pg_per-start_per) / (100-start_per) * 100\n",
    "\n",
    "        if pg_per != 0:\n",
    "            elapsed = time.time() - self.start_time\n",
    "            total = 100*elapsed/pg_per\n",
    "            remain = total - elapsed\n",
    "            elapsed_str = str(datetime.timedelta(seconds=int(elapsed)))\n",
    "            remain_str = str(datetime.timedelta(seconds=int(remain)))\n",
    "            total_str = str(datetime.timedelta(seconds=int(total)))\n",
    "        else:\n",
    "            elapsed = time.time() - self.start_time\n",
    "            elapsed_str = str(datetime.timedelta(seconds=int(elapsed)))\n",
    "            remain_str = 'INF'\n",
    "            total_str = 'INF'\n",
    "\n",
    "        return pg_per, elapsed_str, remain_str, total_str\n",
    "\n",
    "    def print_prog_msg(self, current_iter):\n",
    "        if time.time() - self.progress_time >= self.min_time_interval:\n",
    "            pg_per, elapsed_str, remain_str, total_str = self.calculate_progress(current_iter)\n",
    "\n",
    "            txt = '\\033[K>>> progress : %.2f%%, elapsed: %s, remaining: %s, total: %s \\t\\t\\t\\t\\t' % (pg_per, elapsed_str, remain_str, total_str)\n",
    "\n",
    "            print(txt, end='\\r')\n",
    "\n",
    "            return txt.replace('\\t', '')\n",
    "        return\n",
    "\n",
    "    def get_start_msg(self):\n",
    "        return 'Start >>>'\n",
    "\n",
    "    def get_finish_msg(self):\n",
    "        total = time.time() - self.start_time\n",
    "        total_str = str(datetime.timedelta(seconds=int(total)))\n",
    "        txt = 'Finish >>> (total elapsed time : %s)' % total_str\n",
    "        return txt\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ttt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K>>> progress : 0.00%, elapsed: 0:00:00, remaining: INF, total: INF \t\t\t\t\t\r"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(\n",
    "        format='%(message)s',\n",
    "        level=logging.INFO,\n",
    "        handlers=[logging.StreamHandler()]\n",
    "        )\n",
    "\n",
    "min_time = 1\n",
    "max_iter = 1\n",
    "\n",
    "pp = ProgressMsg((max_iter,min_time))\n",
    "ss = (0, 0)\n",
    "\n",
    "pp.start(ss)\n",
    "\n",
    "for i in range(0, max_iter):\n",
    "    for j in range(max_iter):\n",
    "        for k in range(max_iter):\n",
    "            time.sleep(0.5)\n",
    "            pp.print_prog_msg((i, j))\n",
    "        logging.info('ttt')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class Logger(ProgressMsg):\n",
    "    def __init__(self, max_iter:tuple=None, log_dir:str=None, log_file_option:str='w', log_lvl:str='note', log_file_lvl:str='info', log_include_time:bool=True):\n",
    "        '''\n",
    "        Args:\n",
    "            session_name (str)\n",
    "            max_iter (tuple) : max iteration for progress\n",
    "            log_dir (str) : if None, no file out for logging\n",
    "            log_file_option (str) : 'w' or 'a'\n",
    "            log_lvl (str) : 'debug' < 'note' < 'info' < 'highlight' < 'val'\n",
    "            log_include_time (bool)\n",
    "        '''\n",
    "        self.lvl_list = ['debug', 'note', 'info', 'highlight', 'val']\n",
    "        self.lvl_color = [bcolors.FAIL, None, None, bcolors.WARNING, bcolors.OKGREEN]\n",
    "\n",
    "        assert log_file_option in ['w', 'a']\n",
    "        assert log_lvl in self.lvl_list\n",
    "        assert log_file_lvl in self.lvl_list\n",
    "\n",
    "        # init progress message class\n",
    "        ProgressMsg.__init__(self, max_iter)\n",
    "\n",
    "        # log setting\n",
    "        self.log_dir = log_dir\n",
    "        self.log_lvl      = self.lvl_list.index(log_lvl)\n",
    "        self.log_file_lvl = self.lvl_list.index(log_file_lvl)\n",
    "        self.log_include_time = log_include_time\n",
    "        \n",
    "        # init logging\n",
    "        if self.log_dir is not None:\n",
    "            logfile_time = datetime.datetime.now().strftime('%m-%d-%H-%M')\n",
    "            self.log_file = open(os.path.join(log_dir, 'log_%s.log'%logfile_time), log_file_option, encoding='utf-8')\n",
    "            self.val_file = open(os.path.join(log_dir, 'validation_%s.log'%logfile_time), log_file_option, encoding='utf-8')\n",
    "\n",
    "    def _print(self, txt, lvl_n, end):\n",
    "        txt = str(txt)\n",
    "        if self.log_lvl <= lvl_n:\n",
    "            if self.lvl_color[lvl_n] is not None:\n",
    "                print('\\033[K'+ self.lvl_color[lvl_n] + txt + bcolors.ENDC, end=end)\n",
    "            else:\n",
    "                print('\\033[K'+txt, end=end)\n",
    "        if self.log_file_lvl <= lvl_n:\n",
    "            self.write_file(txt)\n",
    "\n",
    "    def debug(self, txt, end=None):\n",
    "        self._print(txt, self.lvl_list.index('debug'), end)\n",
    "    \n",
    "    def note(self, txt, end=None):\n",
    "        self._print(txt, self.lvl_list.index('note'), end)\n",
    "\n",
    "    def info(self, txt, end=None):\n",
    "        self._print(txt, self.lvl_list.index('info'), end)\n",
    "\n",
    "    def highlight(self, txt, end=None):\n",
    "        self._print(txt, self.lvl_list.index('highlight'), end)\n",
    "\n",
    "    def val(self, txt, end=None):\n",
    "        self._print(txt, self.lvl_list.index('val'), end)\n",
    "        if self.log_dir is not None:\n",
    "            self.val_file.write(txt+'\\n')\n",
    "            self.val_file.flush()\n",
    "\n",
    "    def write_file(self, txt):\n",
    "        if self.log_dir is not None:\n",
    "            if self.log_include_time:\n",
    "                time = datetime.datetime.now().strftime('%H:%M:%S')\n",
    "                txt = \"[%s] \"%time + txt\n",
    "            self.log_file.write(txt+'\\n')\n",
    "            self.log_file.flush()\n",
    "\n",
    "    def clear_screen(self):\n",
    "        if os.name == 'nt': \n",
    "            os.system('cls') \n",
    "        else: \n",
    "            os.system('clear') \n",
    "\n",
    "# https://stackoverflow.com/questions/287871/how-to-print-colored-text-in-python\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
