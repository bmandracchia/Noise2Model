{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers\n",
    "\n",
    "> normalizing flow layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nbdev'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#| hide\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnbdev\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mshowdoc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nbdev'"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #| export\n",
    "\n",
    "import os\n",
    "from importlib import import_module\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #| export\n",
    " \n",
    "flow_layer_class_dict = {}\n",
    "\n",
    "def regist_layer(layer_class):\n",
    "    layer_name = layer_class.__name__.lower()\n",
    "    assert not layer_name in flow_layer_class_dict, 'there is already registered layer: %s in flow_layer_class_dict.' % layer_name\n",
    "    flow_layer_class_dict[layer_name] = layer_class\n",
    "    return layer_class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flow_layer(layer_name:str):\n",
    "    layer_name = layer_name.lower()\n",
    "    return flow_layer_class_dict[layer_name]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Flows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dequantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uniform Dequantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@regist_layer\n",
    "class UniformDequantization(nn.Module):\n",
    "    def __init__(self, alpha=1e-5, num_bits=8, device='cpu', name='uniform_dequantization'):\n",
    "        \"\"\"\n",
    "        Uniform dequantization layer for flows.\n",
    "        \n",
    "        Inputs:\n",
    "            alpha - small constant used to scale the input to avoid very small and large values.\n",
    "            num_bits - Number of bits used for quantization.\n",
    "            device - Device to run computations on (default: 'cpu').\n",
    "            name - Name of the module (default: 'uniform_dequantization').\n",
    "        \"\"\"\n",
    "        super(UniformDequantization, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.num_bits = num_bits\n",
    "        self.quantization_bins = 2 ** num_bits\n",
    "        self.register_buffer(\n",
    "            'ldj_per_dim',\n",
    "            - num_bits * torch.log(torch.tensor(2.0, device=device, dtype=torch.float))\n",
    "        )\n",
    "        self.name = name\n",
    "\n",
    "    def _ldj(self, shape):\n",
    "        batch_size = shape[0]\n",
    "        num_dims = shape[1:].numel()\n",
    "        ldj = self.ldj_per_dim * num_dims\n",
    "        return ldj.repeat(batch_size)\n",
    "\n",
    "    def _inverse(self, z, **kwargs):\n",
    "        z = self._sigmoid_inverse(z)\n",
    "        z = (self.quantization_bins * z).floor().clamp(min=0, max=self.quantization_bins - 1)\n",
    "        return z\n",
    "\n",
    "    def _forward_and_log_det_jacobian(self, x, **kwargs):\n",
    "        z, ldj = self._dequant(x)\n",
    "        z, ldj = self._sigmoid(z, ldj)\n",
    "        return z, ldj\n",
    "    \n",
    "    def _sigmoid(self, z, ldj):\n",
    "        # Applies an invertible sigmoid transformation\n",
    "        ldj += (-z - 2 * F.softplus(-z)).sum(dim=[1, 2, 3])\n",
    "        z = torch.sigmoid(z)\n",
    "        # Reversing scaling for numerical stability\n",
    "        ldj -= torch.log(torch.tensor(1.0 - self.alpha, device=z.device, dtype=z.dtype)) * z.flatten(1).shape[1]\n",
    "        z = (z - 0.5 * self.alpha) / (1 - self.alpha)\n",
    "        return z, ldj\n",
    "    \n",
    "    def _sigmoid_inverse(self, z):\n",
    "        # Inverse sigmoid transformation\n",
    "        z = z * (1 - self.alpha) + 0.5 * self.alpha  # Scale to prevent boundaries 0 and 1\n",
    "        z = torch.log(z) - torch.log(1 - z)\n",
    "        return z\n",
    "    \n",
    "    def _dequant(self, x):\n",
    "        # Transform discrete values to continuous volumes\n",
    "        u = torch.rand(x.shape, device=x.device, dtype=x.dtype)\n",
    "        z = (x + u) / self.quantization_bins\n",
    "        ldj = self._ldj(z.shape)\n",
    "        return z, ldj\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variational Dequantization (TO DO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# class VariationalDequantization(UniformDequantization):\n",
    "\n",
    "#     def __init__(self, var_flows, alpha=1e-5, num_bits=8, device='cpu', name='variational_dequantization'):\n",
    "#         \"\"\"\n",
    "#         Variational dequantization layer inheriting from UniformDequantization.\n",
    "        \n",
    "#         Inputs:\n",
    "#             var_flows - A list of flow transformations to use for modeling q(u|x).\n",
    "#             alpha - Small constant used to scale the input to avoid very small and large values.\n",
    "#             num_bits - Number of bits used for quantization.\n",
    "#             device - Device to run computations on (default: 'cpu').\n",
    "#             name - Name of the module (default: 'variational_dequantization').\n",
    "#         \"\"\"\n",
    "#         super().__init__(alpha=alpha, num_bits=num_bits, device=device, name=name)\n",
    "#         self.flows = nn.ModuleList(var_flows)\n",
    "        \n",
    "#     def _dequant(self, x):\n",
    "#         # Transform discrete values to continuous volumes\n",
    "#         u = torch.rand(x.shape, device=x.device, dtype=x.dtype)\n",
    "#         img = (x / (self.quantization_bins - 1)) * 2 - 1 # We condition the flows on x, i.e. the original image\n",
    "        \n",
    "#         u = self._sigmoid_inverse(u)\n",
    "#         for flow in self.flows:\n",
    "#             u, ldj = flow(u, ldj, orig_img=img)\n",
    "#         u, ldj = self._sigmoid(u, ldj)\n",
    "        \n",
    "#         z = (x + u) / self.quantization_bins\n",
    "#         ldj = self._ldj(z.shape)\n",
    "#         return z, ldj\n",
    "\n",
    "#     # def dequant(self, z, ldj):\n",
    "#     #     z = z.to(torch.float32)\n",
    "#     #     img = (z / 255.0) * 2 - 1 # We condition the flows on x, i.e. the original image\n",
    "\n",
    "#     #     # Prior of u is a uniform distribution as before\n",
    "#     #     # As most flow transformations are defined on [-infinity,+infinity], we apply an inverse sigmoid first.\n",
    "#     #     deq_noise = torch.rand_like(z).detach()\n",
    "#     #     deq_noise, ldj = self.sigmoid(deq_noise, ldj, reverse=True)\n",
    "#     #     for flow in self.flows:\n",
    "#     #         deq_noise, ldj = flow(deq_noise, ldj, reverse=False, orig_img=img)\n",
    "#     #     deq_noise, ldj = self.sigmoid(deq_noise, ldj, reverse=False)\n",
    "\n",
    "#     #     # After the flows, apply u as in standard dequantization\n",
    "#     #     z = (z + deq_noise) / 256.0\n",
    "#     #     ldj -= np.log(256.0) * np.prod(z.shape[1:])\n",
    "#     #     return z, ldj\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@regist_layer\n",
    "class ConditionalLinear(nn.Module):\n",
    "    def __init__(self, device='cpu', name='linear_transformation'):\n",
    "        super(ConditionalLinear, self).__init__()\n",
    "        self.name = name\n",
    "\n",
    "        self.iso_vals = torch.tensor([100, 400, 800, 1600, 3200], dtype=torch.float32, device=device)\n",
    "        self.cam_vals = torch.tensor([0, 1, 2, 3, 4], dtype=torch.float32, device=device)  # 'IP', 'GP', 'S6', 'N6', 'G4'\n",
    "\n",
    "        self.log_scale = nn.Parameter(torch.zeros(25), requires_grad=True)\n",
    "        self.bias = nn.Parameter(torch.zeros(25), requires_grad=True)\n",
    "\n",
    "    def _inverse(self, z, **kwargs):\n",
    "        gain_one_hot = self.iso_vals == torch.mean(kwargs['iso'], dim=[1, 2, 3]).unsqueeze(1)\n",
    "        iso = gain_one_hot.nonzero()[:, 1]\n",
    "        cam_one_hot = self.cam_vals == torch.mean(kwargs['cam'], dim=[1, 2, 3]).unsqueeze(1)\n",
    "        cam = cam_one_hot.nonzero()[:, 1]\n",
    "        iso_cam = iso * 5 + cam\n",
    "        iso_cam = torch.arange(0, 25).cuda() == iso_cam.unsqueeze(1)\n",
    "\n",
    "        log_scale = self.log_scale.unsqueeze(0).repeat_interleave(z.shape[0], dim=0)[iso_cam]\n",
    "        bias = self.bias.unsqueeze(0).repeat_interleave(z.shape[0], dim=0)[iso_cam]\n",
    "\n",
    "        x = (z - bias.reshape((-1, 1, 1, 1))) / torch.exp(log_scale.reshape((-1, 1, 1, 1)))\n",
    "        return x\n",
    "\n",
    "    def _forward_and_log_det_jacobian(self, x, **kwargs):\n",
    "        gain_one_hot = self.iso_vals == torch.mean(kwargs['iso'], dim=[1, 2, 3]).unsqueeze(1)\n",
    "        iso = gain_one_hot.nonzero()[:, 1]\n",
    "        cam_one_hot = self.cam_vals == torch.mean(kwargs['cam'], dim=[1, 2, 3]).unsqueeze(1)\n",
    "        cam = cam_one_hot.nonzero()[:, 1]\n",
    "        iso_cam = iso * 5 + cam\n",
    "        iso_cam = torch.arange(0, 25).cuda() == iso_cam.unsqueeze(1)\n",
    "\n",
    "        log_scale = self.log_scale.unsqueeze(0).repeat_interleave(x.shape[0], dim=0)[iso_cam]\n",
    "        bias = self.bias.unsqueeze(0).repeat_interleave(x.shape[0], dim=0)[iso_cam]\n",
    "        \n",
    "        z = x * torch.exp(log_scale.reshape((-1, 1, 1, 1))) + bias.reshape((-1, 1, 1, 1))\n",
    "        log_abs_det_J_inv = log_scale * np.prod(x.shape[1:])\n",
    "\n",
    "        return z, log_abs_det_J_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Linear $e^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@regist_layer\n",
    "class ConditionalLinearExp2(nn.Module):\n",
    "    def __init__(self, in_ch=3, device='cpu', name='linear_transformation_exp2'):\n",
    "        super(ConditionalLinearExp2, self).__init__()\n",
    "        self.name = name\n",
    "        self.device = device \n",
    "\n",
    "        self.iso_vals = torch.tensor([100, 400, 800, 1600, 3200], dtype=torch.float32, device=device)\n",
    "        self.cam_vals = torch.tensor([0, 1, 2, 3, 4], dtype=torch.float32, device=device)  # 'IP', 'GP', 'S6', 'N6', 'G4'\n",
    "\n",
    "        self.log_scale = nn.Parameter(torch.zeros(25, in_ch), requires_grad=True)\n",
    "        self.bias = nn.Parameter(torch.zeros(25, in_ch), requires_grad=True)\n",
    "\n",
    "    def _inverse(self, z, **kwargs):\n",
    "        b,_,_,_ = z.shape\n",
    "\n",
    "        iso = torch.zeros([b], device=self.device, dtype=torch.float32)\n",
    "        for iso_idx, iso_val in enumerate(self.iso_vals):\n",
    "            iso += torch.where(kwargs['ISO-level'] == iso_val, iso_idx, 0.0)\n",
    "\n",
    "        cam = torch.zeros([b], device=self.device, dtype=torch.float32)\n",
    "        for cam_idx, cam_val in enumerate(self.cam_vals):\n",
    "            cam += torch.where(kwargs['smartphone-code'] == cam_val, cam_idx, 0.0)\n",
    "\n",
    "        iso_cam = iso * self.iso_vals.shape[0] + cam\n",
    "        iso_cam = torch.arange(0, self.iso_vals.shape[0] * self.cam_vals.shape[0]).cuda() == iso_cam.unsqueeze(1)\n",
    "\n",
    "        log_scale = self.log_scale.unsqueeze(0).repeat_interleave(z.shape[0], dim=0)[iso_cam]\n",
    "        bias = self.bias.unsqueeze(0).repeat_interleave(z.shape[0], dim=0)[iso_cam]\n",
    "\n",
    "        x = (z - bias.reshape((-1, z.shape[1], 1, 1))) / torch.exp(log_scale.reshape((-1, z.shape[1], 1, 1)))\n",
    "        return x\n",
    "\n",
    "    def _forward_and_log_det_jacobian(self, x, **kwargs):\n",
    "        b,_,_,_ = x.shape\n",
    "\n",
    "        iso = torch.zeros([b], device=x.device, dtype=torch.float32)\n",
    "        for iso_idx, iso_val in enumerate(self.iso_vals):\n",
    "            iso += torch.where(kwargs['ISO-level'] == iso_val, iso_idx, 0.0)\n",
    "\n",
    "        cam = torch.zeros([b], device=x.device, dtype=torch.float32)\n",
    "        for cam_idx, cam_val in enumerate(self.cam_vals):\n",
    "            cam += torch.where(kwargs['smartphone-code'] == cam_val, cam_idx, 0.0)\n",
    "\n",
    "        iso_cam = iso * self.iso_vals.shape[0] + cam\n",
    "        iso_cam = torch.arange(0, self.iso_vals.shape[0] * self.cam_vals.shape[0]).cuda() == iso_cam.unsqueeze(1)\n",
    "\n",
    "        log_scale = self.log_scale.unsqueeze(0).repeat_interleave(x.shape[0], dim=0)[iso_cam]\n",
    "        bias = self.bias.unsqueeze(0).repeat_interleave(x.shape[0], dim=0)[iso_cam]\n",
    "        z = x * torch.exp(log_scale.reshape((-1, x.shape[1], 1, 1))) + bias.reshape((-1, x.shape[1], 1, 1))\n",
    "        log_abs_det_J_inv = torch.sum(log_scale * np.prod(x.shape[2:]), dim=1)\n",
    "\n",
    "        return z, log_abs_det_J_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal Dependent Conditional Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "@regist_layer\n",
    "class SignalDependentConditionalLinear(nn.Module):\n",
    "    def __init__(self, meta_encoder, scale_and_bias, in_ch=3, device='cpu', name='signal_dependent_condition_linear'):\n",
    "        super(SignalDependentConditionalLinear, self).__init__()\n",
    "        self.name = name\n",
    "        self.device = device \n",
    "\n",
    "        self.in_ch = in_ch\n",
    "        self.iso_vals = torch.tensor([100, 400, 800, 1600, 3200], dtype=torch.float32, device=device)\n",
    "        self.cam_vals = torch.tensor([0, 1, 2, 3, 4], dtype=torch.float32, device=device)  # 'IP', 'GP', 'S6', 'N6', 'G4'\n",
    "        self.encode_ch = 3\n",
    "        self.meta_encoder = meta_encoder(10, self.encode_ch)\n",
    "        self.scale_and_bias = scale_and_bias(self.encode_ch+in_ch, in_ch*2) # scale, bias per channels\n",
    "\n",
    "    def _get_embeddings(self, x, **kwargs):\n",
    "        b,_,_,_ = x.shape\n",
    "\n",
    "        iso = torch.zeros([b], device=x.device, dtype=torch.float32)\n",
    "        for iso_idx, iso_val in enumerate(self.iso_vals):\n",
    "            iso += torch.where(kwargs['ISO-level'] == iso_val, iso_idx, 0.0)\n",
    "\n",
    "        cam = torch.zeros([b], device=x.device, dtype=torch.float32)\n",
    "        for cam_idx, cam_val in enumerate(self.cam_vals):\n",
    "            cam += torch.where(kwargs['smartphone-code'] == cam_val, cam_idx, 0.0)\n",
    "\n",
    "        iso_one_hot = F.one_hot(iso.to(torch.int64), num_classes=self.iso_vals.shape[0]).to(torch.float32)\n",
    "        cam_one_hot = F.one_hot(cam.to(torch.int64), num_classes=self.cam_vals.shape[0]).to(torch.float32)\n",
    "\n",
    "        embedding = self.meta_encoder(torch.cat((iso_one_hot, cam_one_hot), dim=1)) # [b, 10] -> [b,encode_ch]\n",
    "        embedding = embedding.reshape((-1, self.encode_ch, 1, 1))\n",
    "        embedding = torch.repeat_interleave(embedding, x.shape[-2], dim=-2)# [b, encode_ch, 1, 1] -> [b, encode_ch, h, 1]\n",
    "        embedding = torch.repeat_interleave(embedding, x.shape[-1], dim=-1)# [b, encode_ch, h, 1] -> [b, encode_ch, h, w]\n",
    "\n",
    "        embedding = torch.cat((embedding, kwargs['clean']), dim=1) # [b, encode_ch, h, w], [b, c, h, w] -> [b, c+encode_ch, h, w]\n",
    "\n",
    "        embedding = self.scale_and_bias(embedding)\n",
    "        return embedding\n",
    "    \n",
    "    def _inverse(self, z, **kwargs):\n",
    "        embedding = self._get_embeddings(z, **kwargs)\n",
    "\n",
    "        log_scale = embedding[:,:self.in_ch, ...]\n",
    "        bias = embedding[:,self.in_ch:, ...]\n",
    "        z = (z - bias)/torch.exp(log_scale)\n",
    "        return z\n",
    "\n",
    "    def _forward_and_log_det_jacobian(self, x, **kwargs):\n",
    "        embedding = self._get_embeddings(x, **kwargs)\n",
    "\n",
    "        log_scale = embedding[:,:self.in_ch, ...]\n",
    "        bias = embedding[:,self.in_ch:, ...]\n",
    "        \n",
    "        z = torch.exp(log_scale)*x + bias\n",
    "        log_abs_det_J_inv = torch.sum(log_scale, dim=[1,2,3])\n",
    "        return z, log_abs_det_J_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure-Aware Conditional Linear Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "@regist_layer\n",
    "class StructureAwareConditionalLinearLayer(nn.Module):\n",
    "    def __init__(self, meta_encoder, structure_encoder, in_ch=3, device='cpu', name='signal_dependent_condition_linear'):\n",
    "        super(StructureAwareConditionalLinearLayer, self).__init__()\n",
    "        self.in_ch = in_ch\n",
    "        self.iso_vals = torch.tensor([100, 400, 800, 1600, 3200], dtype=torch.float32, device=device)\n",
    "        self.cam_vals = torch.tensor([0, 1, 2, 3, 4], dtype=torch.float32, device=device)  # 'IP', 'GP', 'S6', 'N6', 'G4'\n",
    "\n",
    "        self.meta_encoder = meta_encoder(10, in_ch*2)\n",
    "        self.structure_encoder = structure_encoder(in_ch, in_ch*2)\n",
    "\n",
    "    def _get_embeddings(self, x, **kwargs):\n",
    "        b,_,_,_ = x.shape\n",
    "\n",
    "        iso = torch.zeros([b], device=x.device, dtype=torch.float32)\n",
    "        for iso_idx, iso_val in enumerate(self.iso_vals):\n",
    "            iso += torch.where(kwargs['ISO-level'] == iso_val, iso_idx, 0.0)\n",
    "\n",
    "        cam = torch.zeros([b], device=x.device, dtype=torch.float32)\n",
    "        for cam_idx, cam_val in enumerate(self.cam_vals):\n",
    "            cam += torch.where(kwargs['smartphone-code'] == cam_val, cam_idx, 0.0)\n",
    "\n",
    "        iso_one_hot = F.one_hot(iso.to(torch.int64), num_classes=self.iso_vals.shape[0]).to(torch.float32)\n",
    "        cam_one_hot = F.one_hot(cam.to(torch.int64), num_classes=self.cam_vals.shape[0]).to(torch.float32)\n",
    "\n",
    "        meta_embedding = self.meta_encoder(torch.cat((iso_one_hot, cam_one_hot), dim=1)) # [b, 10] -> [b,encode_ch]\n",
    "        meta_embedding = meta_embedding.reshape((-1, self.in_ch*2, 1, 1))\n",
    "        \n",
    "        structure_embedding = self.structure_encoder(kwargs['clean'])\n",
    "        embedding = structure_embedding * meta_embedding\n",
    "        return embedding\n",
    "    \n",
    "    def _inverse(self, z, **kwargs):\n",
    "        embedding = self._get_embeddings(z, **kwargs)\n",
    "\n",
    "        log_scale = embedding[:,:self.in_ch, ...]\n",
    "        bias = embedding[:,self.in_ch:, ...]\n",
    "        z = (z - bias)/torch.exp(log_scale)\n",
    "        return z\n",
    "\n",
    "    def _forward_and_log_det_jacobian(self, x, **kwargs):\n",
    "        embedding = self._get_embeddings(x, **kwargs)\n",
    "\n",
    "        log_scale = embedding[:,:self.in_ch, ...]\n",
    "        bias = embedding[:,self.in_ch:, ...]\n",
    "        \n",
    "        z = torch.exp(log_scale)*x + bias\n",
    "        log_abs_det_J_inv = torch.sum(log_scale, dim=[1,2,3])\n",
    "        return z, log_abs_det_J_inv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pointwise Convs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@regist_layer\n",
    "class PointwiseConvs(nn.Module):\n",
    "    def __init__(self, in_features=3, out_features=3, feats=32, device='cpu', name='pointwise_convs'):\n",
    "        super(PointwiseConvs, self).__init__()\n",
    "        self.name = name\n",
    "        self.device = device \n",
    "        self.body = nn.Sequential(\n",
    "            nn.Conv2d(in_features, feats, kernel_size=1, stride=1, padding=0),\n",
    "            self._get_basic_module(feats, feats*2, k_size=1, stride=1, padding=0),\n",
    "            self._get_basic_module(feats*2, feats*2, k_size=1, stride=1, padding=0),\n",
    "            self._get_basic_module(feats*2, feats, k_size=1, stride=1, padding=0),\n",
    "            nn.Conv2d(feats, out_features, kernel_size=1, stride=1, padding=0),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def _get_basic_module(self, in_ch, out_ch, k_size=1, stride=1, padding=1, negative_slope=0.2):\n",
    "            return nn.Sequential(\n",
    "                    nn.Conv2d(in_ch, out_ch, kernel_size=k_size, stride=stride, padding=padding),\n",
    "                    nn.InstanceNorm2d(out_ch, affine=True), #batch normalization?\n",
    "                    nn.LeakyReLU(negative_slope, inplace=True)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.body(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial Convs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@regist_layer\n",
    "class SpatialConvs(nn.Module):\n",
    "    def __init__(self, in_features=3, out_features=3, feats=32, receptive_field=9, device='cpu', name='pointwise_convs'):\n",
    "        super(SpatialConvs, self).__init__()\n",
    "        self.name = name\n",
    "        self.device = device \n",
    "\n",
    "        self.receptive_field = receptive_field\n",
    "\n",
    "        self.body = list()\n",
    "        self.body.append(nn.Conv2d(in_features, feats, kernel_size=1, stride=1, padding=0))\n",
    "        self.body.append(nn.ReLU(inplace=True))\n",
    "\n",
    "        for _ in range(self.receptive_field//2):\n",
    "            self.body.append(nn.Conv2d(feats, feats, kernel_size=3, stride=1, padding=1))\n",
    "            self.body.append(nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.body.append(nn.Conv2d(feats, out_features, kernel_size=1, stride=1, padding=0))\n",
    "        self.body.append(nn.Tanh())\n",
    "        self.body = nn.Sequential(*self.body)\n",
    "\n",
    "    def _get_basic_module(self, in_ch, out_ch, k_size=1, stride=1, padding=1, negative_slope=0.2):\n",
    "            return nn.Sequential(\n",
    "                    nn.Conv2d(in_ch, out_ch, kernel_size=k_size, stride=stride, padding=padding),\n",
    "                    nn.InstanceNorm2d(out_ch, affine=True), #batch normalization?\n",
    "                    nn.LeakyReLU(negative_slope, inplace=True)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.body(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@regist_layer\n",
    "class NoiseExtraction(nn.Module):\n",
    "    def __init__(self, device='cpu', name='noise_extraction'):\n",
    "        super(NoiseExtraction, self).__init__()\n",
    "        self.name = name\n",
    "        self.device = device\n",
    "\n",
    "    def _inverse(self, z, **kwargs):\n",
    "        x = z + kwargs['clean']\n",
    "        return x\n",
    "\n",
    "    def _forward_and_log_det_jacobian(self, x, **kwargs):\n",
    "        z = x - kwargs['clean']\n",
    "        ldj = torch.zeros(x.shape[0], device=self.device)\n",
    "        return z, ldj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Net (to be moved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from torch.nn import functional as F, init\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"A general-purpose residual block. Works only with 1-dim inputs.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 features,\n",
    "                 context_features,\n",
    "                 activation=F.relu,\n",
    "                 dropout_probability=0.,\n",
    "                 use_batch_norm=False,\n",
    "                 zero_initialization=True):\n",
    "        super().__init__()\n",
    "        self.activation = activation\n",
    "\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        if use_batch_norm:\n",
    "            self.batch_norm_layers = nn.ModuleList([\n",
    "                #nn.BatchNorm1d(features, eps=1e-3, track_running_stats=False)\n",
    "                nn.BatchNorm1d(features, eps=1e-3)\n",
    "                for _ in range(2)\n",
    "            ])\n",
    "        if context_features is not None:\n",
    "            self.context_layer = nn.Linear(context_features, features)\n",
    "        self.linear_layers = nn.ModuleList([\n",
    "            nn.Linear(features, features)\n",
    "            for _ in range(2)\n",
    "        ])\n",
    "        if dropout_probability > 0.:\n",
    "            self.dropout = nn.Dropout(p=dropout_probability)\n",
    "        else:\n",
    "            self.dropout = None\n",
    "        if zero_initialization:\n",
    "            init.uniform_(self.linear_layers[-1].weight, -1e-3, 1e-3)\n",
    "            init.uniform_(self.linear_layers[-1].bias, -1e-3, 1e-3)\n",
    "\n",
    "    def forward(self, inputs, context=None):\n",
    "        temps = inputs\n",
    "        if self.use_batch_norm:\n",
    "            temps = self.batch_norm_layers[0](temps)\n",
    "        temps = self.activation(temps)\n",
    "        temps = self.linear_layers[0](temps)\n",
    "        if self.use_batch_norm:\n",
    "            temps = self.batch_norm_layers[1](temps)\n",
    "        temps = self.activation(temps)\n",
    "        if self.dropout:\n",
    "            temps = self.dropout(temps)\n",
    "        temps = self.linear_layers[1](temps)\n",
    "        if context is not None:\n",
    "            temps = F.glu(\n",
    "                torch.cat(\n",
    "                    (temps, self.context_layer(context)),\n",
    "                    dim=1\n",
    "                ),\n",
    "                dim=1\n",
    "            )\n",
    "        return inputs + temps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "@regist_layer\n",
    "class ResidualNet(nn.Module):\n",
    "    \"\"\"A general-purpose residual network. Works only with 1-dim inputs.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_features,\n",
    "                 out_features,\n",
    "                 hidden_features,\n",
    "                 context_features=None,\n",
    "                 num_blocks=2,\n",
    "                 activation=F.relu,\n",
    "                 dropout_probability=0.,\n",
    "                 use_batch_norm=False):\n",
    "        super().__init__()\n",
    "        self.hidden_features = hidden_features\n",
    "        self.context_features = context_features\n",
    "        if context_features is not None:\n",
    "            self.initial_layer = nn.Linear(in_features + context_features, hidden_features)\n",
    "        else:\n",
    "            self.initial_layer = nn.Linear(in_features, hidden_features)\n",
    "        self.blocks = nn.ModuleList([\n",
    "            ResidualBlock(\n",
    "                features=hidden_features,\n",
    "                context_features=context_features,\n",
    "                activation=activation,\n",
    "                dropout_probability=dropout_probability,\n",
    "                use_batch_norm=use_batch_norm,\n",
    "            ) for _ in range(num_blocks)\n",
    "        ])\n",
    "        self.final_layer = nn.Linear(hidden_features, out_features)\n",
    "\n",
    "    def forward(self, inputs, context=None):\n",
    "        if context is None:\n",
    "            temps = self.initial_layer(inputs)\n",
    "        else:\n",
    "            temps = self.initial_layer(\n",
    "                torch.cat((inputs, context), dim=1)\n",
    "            )\n",
    "        for block in self.blocks:\n",
    "            temps = block(temps, context=context)\n",
    "        outputs = self.final_layer(temps)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise Flow Layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# class Gain(Flow):\n",
    "#     \"\"\"\n",
    "#     Gain & Offset flow layer\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, shape):\n",
    "#         \"\"\"Constructor\n",
    "\n",
    "        \n",
    "#         \"\"\"\n",
    "#         super().__init__()\n",
    "#         self.shape = shape\n",
    "#         self.gain = AffineConstFlow(self.shape)\n",
    "\n",
    "#     def forward(self, z, **kwargs):\n",
    "#         return self.gain(z)\n",
    "\n",
    "#     def inverse(self, z, **kwargs):\n",
    "#         return self.gain.inverse(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channels = 1\n",
    "# hidden_channels = 16\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# x = torch_randn(1, channels, 16, 16).to(device)\n",
    "# print(x.device)\n",
    "\n",
    "# # tst =  AffineSdn(x.shape[1:]).to(device)\n",
    "# tst = Unconditional(channels=x.shape[1],hidden_channels = 16,split_mode='channel' if x.shape[1] != 1 else 'checkerboard').to(device)\n",
    "# # tst = Gain(x.shape[1:]).to(device)  \n",
    "# print(tst)\n",
    "# kwargs = {}; kwargs['clean'] = x\n",
    "# y, _ = tst(x,**kwargs)\n",
    "# test_eq(y.shape, x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
